
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/notes_repo/drishti-do-not-forget-slicing-while-designing-last-level-cache-replacement-policies-for-many-core-systems/figs_notes/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../../assets/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>Drishti: Do Not Forget Slicing While Designing Last-Level Cache Replacement Policies for Many-Core Systems 图表详解 - BlaBlaCut</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="amber">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#drishti-do-not-forget-slicing-while-designing-last-level-cache-replacement-policies-for-many-core-systems" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="BlaBlaCut" class="md-header__button md-logo" aria-label="BlaBlaCut" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BlaBlaCut
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Drishti: Do Not Forget Slicing While Designing Last-Level Cache Replacement Policies for Many-Core Systems 图表详解
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="切换到深色模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换到深色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="切换到浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换到浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="BlaBlaCut" class="md-nav__button md-logo" aria-label="BlaBlaCut" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    BlaBlaCut
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/Recent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Recent
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/awesome-data-prefetchers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Awesome Data Prefetchers
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/micro-2025/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MICRO 2025
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/dyn-lang-acc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Dynamic Language Acceleration
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#loads-of-pcyfrom-core-30-abc-h-figure-1-mockingjay-with-per-slice-per-core-reuse-predictor-on-a-sliced-llc-based-32-core-system-each-slice-has-a-predictor-indexed-with-a-hash-of-pc-and-core-id" class="md-nav__link">
    <span class="md-ellipsis">
      
        Loads of PCyfrom core 30: A,B,C,.., H Figure 1: Mockingjay with per-slice per-core reuse predictor on a sliced LLC-based 32-core system. Each slice has a predictor, indexed with a hash of PC and core ID.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1970890555c7f00a5cf660d3b688d30bff1dc943809016e826a17962ca70f36ajpg" class="md-nav__link">
    <span class="md-ellipsis">
      
        1970890555c7f00a5cf660d3b688d30bff1dc943809016e826a17962ca70f36a.jpg
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-2-fraction-of-pcs-per-coreexcluding-those-that-bring-only-a-single-load-mapping-demand-loads-to-one-llc-slice-throughout-their-execution-for-16-core-mixes-35-homogenous-and-35-heterogenous-created-from-spec-cpu2017-and-gapthe-higher-the-better-figure-3-etr-values-corresponding-to-the-loads-of-pc-0x59cdbf-with-mockingjay-when-the-predictor-sees-global-view-myopic-view-and-the-oracle-view-of-access-pattern-on-a-16-core-system-running-a-homogeneous-mix-of-xalan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 2: Fraction of PCs per core(excluding those that bring only a single load) mapping demand loads to one LLC slice throughout their execution for 16-core mixes (35 homogenous and 35 heterogenous created from SPEC CPU2017 and GAP).The higher, the better. Figure 3: ETR values corresponding to the loads of PC 0x59cdbf with Mockingjay when the predictor sees global view, myopic view, and the oracle view of access pattern on a 16-core system running a homogeneous mix of xalan.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-4-frequency-distributionofetrs-and-rrips-in-mockingjay-and-hawkeye-for-xalan-and-pr-running-ona16-core-system" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 4: Frequency distributionofETRs and RRIPs in Mockingjay and Hawkeye for xalan and pr running ona16-core system
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-5-miss-per-kilo-accesses-mpka-per-llc-set-with-three-different-16-core-homogeneous-workloads" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 5: Miss per kilo accesses (MPKA) per LLC set with three different 16-core homogeneous workloads.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a414717151ed11725279a36c126d05e1e6488e3fe8c84436b02d3fb137d31f89jpg" class="md-nav__link">
    <span class="md-ellipsis">
      
        a414717151ed11725279a36c126d05e1e6488e3fe8c84436b02d3fb137d31f89.jpg
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-6-tracking-reuse-behavior-and-training-the-local-predictors-with-a-global-centralized-sampled-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 6: Tracking reuse behavior and training the local predictors with a global (centralized) sampled cache.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-7-tracking-reuse-behavior-and-training-the-local-predictors-with-a-global-distributed-sampled-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 7: Tracking reuse behavior and training the local predictors with a global (distributed) sampled cache.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-8-tracking-reuse-behavior-by-a-local-sampled-cache-and-using-it-to-train-the-global-centralized-predictor" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 8: Tracking reuse behavior by a local sampled cache and using it to train the global (centralized) predictor.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-9-drishtis-enhancement-tracking-reuse-behavior-and-training-the-per-core-and-yet-global-reuse-predictor-with-local-per-slice-sampled-caches" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 9: Drishti's enhancement: Tracking reuse behavior and training the per-core and yet global reuse predictor with local (per-slice) sampled caches.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-10-accesses-per-kilo-instructions-to-the-centralized-and-per-core-global-predictors-in-mockingjayaveraged-across-35-homogeneous-and-35-heterogeneous-mixes-each-bar-shows-the-training-and-prediction-lookups-to-the-predictor" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 10: Accesses per kilo instructions to the centralized and per-core global predictors in Mockingjay,averaged across 35 homogeneous and 35 heterogeneous mixes. Each bar shows the training and prediction lookups to the predictor.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-2-potential-design-choices-to-address-myopic-predictionsalong-with-their-advantages-and-disadvantages" class="md-nav__link">
    <span class="md-ellipsis">
      
        Table 2: Potential design choices to address myopic predictions,along with their advantages and disadvantages.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-11-a-slowdown-in-mockingjay-with-drishti-without-a-low-latency-interconnect-between-slices-and-the-predictors-binterconnect-latency-sensitivity-on-a-32-core-system-across-35-homogeneous-and-35-heterogeneous-mixes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 11: (a) Slowdown in Mockingjay with Drishti without a low-latency interconnect between slices and the predictors. (b)Interconnect latency sensitivity on a 32-core system across 35 homogeneous and 35 heterogeneous mixes.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-3-per-core-hardware-budget-with-and-without-drishti-for-a-16-way-2mb-llc-slice" class="md-nav__link">
    <span class="md-ellipsis">
      
        Table 3: Per-core hardware budget with and without Drishti for a 16-way 2MB LLC slice.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-4-simulation-parameters-of-the-baseline-system" class="md-nav__link">
    <span class="md-ellipsis">
      
        Table 4: Simulation parameters of the baseline system.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure13-performance-improvement-with-state-of-the-artllcreplacement-policies-normalized-tolruon4-core6-core-32-core-systems-with-8mb32mband-64mb-sliced-llc-across-70-mixes-35-homogeneous-and-35-heterogeneous" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure13: Performance improvement with state-of-the-artLLCreplacement policies normalized toLRUon4-core,6-core, 32-core systems with 8MB,32MB,and 64MB sliced LLC across 70 mixes (35 homogeneous and 35 heterogeneous).
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-14-miss-reduction-over-lru-on-4-16and-32-cores-averaged-across-70-35-homoand-35-hetero-mixes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 14: Miss reduction over LRU on 4, 16,and 32 cores averaged across 70 (35 homo.and 35 hetero) mixes.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4fc3cc59d033115cfb967016852255e92d32d57d6fecaf90af004fa36a09ab11jpg" class="md-nav__link">
    <span class="md-ellipsis">
      
        4fc3cc59d033115cfb967016852255e92d32d57d6fecaf90af004fa36a09ab11.jpg
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cd4d55378946d91908ea2a26818da676288f5d965dbcd6898c86fe689bde961ajpg" class="md-nav__link">
    <span class="md-ellipsis">
      
        cd4d55378946d91908ea2a26818da676288f5d965dbcd6898c86fe689bde961a.jpg
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-5-average-llc-wpki-across-35-homogeneous-mixes-and-35-heterogeneous-mixes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Table 5: Average LLC WPKI across 35 homogeneous mixes and 35 heterogeneous mixes.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-15-uncore-llc-noc-and-dram-energy-consumption-normalized-to-lru-across-70-mixes-lower-the-better" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 15: Uncore (LLC, NOC, and DRAM) energy consumption normalized to LRU across 70 mixes (lower the better).
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-6-drishti-on-a-32-core-system-with-64mb-llc-across-35-homogeneous-and-35-heterogeneous-mixes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Table 6: Drishti on a 32-core system with 64MB LLC across 35 homogeneous and 35 heterogeneous mixes.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-16-performance-of-mockingjay-and-d-mockingjay-on-32-core-systems-across-70-mixesthe-mixes-are-shown-in-sorted-order-as-per-performance-improvement-and-their-indices-do-not-correspond-to-those-in-figure-2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 16: Performance of Mockingjay and D-Mockingjay on 32-core systems across 70 mixes.The mixes are shown in sorted order (as per performance improvement), and their indices do not correspond to those in Figure 2.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-17-performance-normalized-to-lru-with-only-global-view-and-d-mockingjay-with-global-view-dsc-across-32-core-35-homogeneous-and-heterogeneous-mixes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 17: Performance normalized to LRU with only global view and D-Mockingjay with global view &amp; DSC across 32- core 35 homogeneous and heterogeneous mixes.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-18-etr-values-with-drishti-in-mockingjay-for-xalan-running-on-a-16-core-system" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 18: ETR values with Drishti in Mockingjay for xalan running on a 16-core system.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-19-performance-of-hawkeye-d-hawkeye-mockingjayd-mockingjay-on-50-16-core-and-50-32-core-mixes-created-from-cvp1-46google-datacenter-traces-1551cloudsuite-4and-xsbench-14" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 19: Performance of Hawkeye, D-Hawkeye, Mockingjay,D-Mockingjay on 50 16-core and 50 32-core mixes created from CVP1 [46],Google datacenter traces [15,51],CloudSuite [4],and XSBench [14].
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-20-performance-normalized-to-lru-on-a-16-core-system-with-different-sizes-of-sliced-llc" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 20: Performance normalized to LRU on a 16-core system with different sizes of sliced LLC.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-21-performance-normalized-to-lru-on-a-16-core-system-with-different-sizes-of-l2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 21: Performance normalized to LRU on a 16-core system with different sizes of L2.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-22-performance-normalized-to-lru-on-a-16-core-system-with-different-dramchannels" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 22: Performance normalized to LRU on a 16-core system with different DRAMchannels.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-23-performance-normalized-to-lru-with-different-hardware-prefetchers-averaged-across-16-and-32-core-mixes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 23: Performance normalized to LRU with different hardware prefetchers averaged across 16 and 32-core mixes.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#489b4a8ebaba549f37e1b5dbbc679e569672d623ed1ce784b351a74e45f3bba0jpg" class="md-nav__link">
    <span class="md-ellipsis">
      
        489b4a8ebaba549f37e1b5dbbc679e569672d623ed1ce784b351a74e45f3bba0.jpg
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-8-drishti-with-shipchromeand-glider-policies-for16-core-systems" class="md-nav__link">
    <span class="md-ellipsis">
      
        Table 8: Drishti with SHiP++,CHROME,and Glider policies for16-core systems.
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="drishti-do-not-forget-slicing-while-designing-last-level-cache-replacement-policies-for-many-core-systems">Drishti: Do Not Forget Slicing While Designing Last-Level Cache Replacement Policies for Many-Core Systems 图表详解<a class="headerlink" href="#drishti-do-not-forget-slicing-while-designing-last-level-cache-replacement-policies-for-many-core-systems" title="Permanent link">&para;</a></h1>
<h3 id="loads-of-pcyfrom-core-30-abc-h-figure-1-mockingjay-with-per-slice-per-core-reuse-predictor-on-a-sliced-llc-based-32-core-system-each-slice-has-a-predictor-indexed-with-a-hash-of-pc-and-core-id">Loads of PCyfrom core 30: A,B,C,.., H Figure 1: Mockingjay with per-slice per-core reuse predictor on a sliced LLC-based 32-core system. Each slice has a predictor, indexed with a hash of PC and core ID.<a class="headerlink" href="#loads-of-pcyfrom-core-30-abc-h-figure-1-mockingjay-with-per-slice-per-core-reuse-predictor-on-a-sliced-llc-based-32-core-system-each-slice-has-a-predictor-indexed-with-a-hash-of-pc-and-core-id" title="Permanent link">&para;</a></h3>
<p><img alt="59636762a91768643e580290115c1c6b24de54bbf4d4d06b4ae087357f4ac38e.jpg" src="../images/59636762a91768643e580290115c1c6b24de54bbf4d4d06b4ae087357f4ac38e.jpg" /></p>
<ul>
<li>该图描绘了一个32核系统中，<strong>Mockingjay</strong>替换策略在<strong>分片LLC</strong>架构下的工作流程，核心关注点是<strong>PCy</strong>（程序计数器）从<strong>Core 30</strong>发出的负载序列A, B, C, ..., H。</li>
<li>图中清晰展示了<strong>分片式设计</strong>：整个LLC被划分为32个独立的Slice（Slice 0到Slice 31），每个Slice都配备了自己的<strong>采样缓存</strong>（Sampled Cache）和<strong>预测器</strong>（Predictor）。</li>
<li><strong>负载散列与映射</strong>：来自Core 30的负载请求（如A, D）根据其地址被路由到不同的Slice（例如Slice 0）。图中标注了具体的映射关系：<ul>
<li>Load A, D → Slice 0</li>
<li>Load G, H → Slice 2</li>
<li>Load E, F → Slice 30</li>
<li>Load B, C → Slice 1</li>
</ul>
</li>
<li><strong>本地化处理</strong>：每个Slice内的<strong>采样缓存</strong>负责记录其接收到的负载访问行为。随后，这些信息用于训练位于同一Slice内的<strong>预测器</strong>。这种设计意味着每个预测器仅能“看到”并学习分配给其所在Slice的访问模式，导致了论文中提到的<strong>近视预测</strong>（Myopic predictions）问题。</li>
<li><strong>预测器结构</strong>：图中显示每个Slice包含多个预测器实例，这对应于论文中描述的“per-slice per-core reuse predictor”，即预测器条目由<strong>PC和Core ID的哈希值</strong>索引，以区分不同核心的相同PC行为。</li>
<li><strong>互连网络</strong>：图底部标注了“Interconnect”，表明各个Slice之间通过片上互连网络进行通信，这是多核系统的基础架构。</li>
<li><strong>流程步骤</strong>：图中的数字标记了事件顺序：<ol>
<li><strong>Core 30</strong>发出负载请求。</li>
<li>请求被路由到相应的<strong>Slice</strong>。</li>
<li><strong>Slice</strong>内的<strong>采样缓存</strong>记录访问，并更新其本地的<strong>预测器</strong>。</li>
</ol>
</li>
<li><strong>关键局限性</strong>：此架构的核心问题是，由于负载被分散到不同Slice，一个特定PC（如PCy）的所有访问行为无法被单一预测器完整观察。每个预测器只能基于其局部视图进行训练，从而降低了预测准确性，尤其是在核心数量增加时，这种“近视”效应会更加严重。这正是论文提出<strong>Drishti</strong>增强方案所要解决的根本问题。</li>
</ul>
<h3 id="1970890555c7f00a5cf660d3b688d30bff1dc943809016e826a17962ca70f36ajpg">1970890555c7f00a5cf660d3b688d30bff1dc943809016e826a17962ca70f36a.jpg<a class="headerlink" href="#1970890555c7f00a5cf660d3b688d30bff1dc943809016e826a17962ca70f36ajpg" title="Permanent link">&para;</a></h3>
<p><img alt="1970890555c7f00a5cf660d3b688d30bff1dc943809016e826a17962ca70f36a.jpg" src="../images/1970890555c7f00a5cf660d3b688d30bff1dc943809016e826a17962ca70f36a.jpg" /></p>
<ul>
<li>图片展示了在 <strong>16-core workload mixes</strong> 下，每个核心中 <strong>PCs (Program Counters)</strong> 的负载请求被映射到 <strong>单一 LLC slice</strong> 的比例分布。</li>
<li>纵轴为 <strong>Fraction of PCs (%)</strong>，表示每个核心中 PC 映射到单个 LLC slice 的百分比；横轴为 <strong>16-core workload mixes</strong>，共 70 个混合工作负载（35 个同构 + 35 个异构）。</li>
<li>数据点显示，<strong>平均 66.2% 的 PCs</strong>（每个核心）的负载请求仅映射到一个 LLC slice，表明存在显著的 <strong>myopic behavior</strong>。</li>
<li>在部分工作负载（如 xalan，对应图中第 20 个混合）中，<strong>约 40% 的 PCs</strong> 仅映射到一个 slice，导致其预测器训练数据高度局部化，预测准确性下降。</li>
<li>散点图趋势表明，随着工作负载混合的变化，该比例波动较大，但整体集中在 <strong>50%-80% 区间</strong>，说明 <strong>PC 分散性普遍存在</strong>，是影响全局重用预测准确性的关键因素。</li>
<li>此图用于支撑论文中 <strong>Observation I: Myopic predictions</strong>，强调在 sliced LLC 架构下，本地预测器因缺乏全局访问信息而做出次优决策。</li>
</ul>
<table>
<thead>
<tr>
<th>工作负载混合索引</th>
<th>映射到单一 LLC slice 的 PCs 比例 (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>20 (xalan)</td>
<td>~40%</td>
</tr>
<tr>
<td>平均值</td>
<td>66.2%</td>
</tr>
<tr>
<td>多数区间</td>
<td>50% - 80%</td>
</tr>
</tbody>
</table>
<ul>
<li>该图未受 <strong>LLC replacement policies</strong> 或 <strong>hardware prefetching</strong> 影响，反映的是底层地址映射与切片分布的固有特性。</li>
</ul>
<h3 id="figure-2-fraction-of-pcs-per-coreexcluding-those-that-bring-only-a-single-load-mapping-demand-loads-to-one-llc-slice-throughout-their-execution-for-16-core-mixes-35-homogenous-and-35-heterogenous-created-from-spec-cpu2017-and-gapthe-higher-the-better-figure-3-etr-values-corresponding-to-the-loads-of-pc-0x59cdbf-with-mockingjay-when-the-predictor-sees-global-view-myopic-view-and-the-oracle-view-of-access-pattern-on-a-16-core-system-running-a-homogeneous-mix-of-xalan">Figure 2: Fraction of PCs per core(excluding those that bring only a single load) mapping demand loads to one LLC slice throughout their execution for 16-core mixes (35 homogenous and 35 heterogenous created from SPEC CPU2017 and GAP).The higher, the better. Figure 3: ETR values corresponding to the loads of PC 0x59cdbf with Mockingjay when the predictor sees global view, myopic view, and the oracle view of access pattern on a 16-core system running a homogeneous mix of xalan.<a class="headerlink" href="#figure-2-fraction-of-pcs-per-coreexcluding-those-that-bring-only-a-single-load-mapping-demand-loads-to-one-llc-slice-throughout-their-execution-for-16-core-mixes-35-homogenous-and-35-heterogenous-created-from-spec-cpu2017-and-gapthe-higher-the-better-figure-3-etr-values-corresponding-to-the-loads-of-pc-0x59cdbf-with-mockingjay-when-the-predictor-sees-global-view-myopic-view-and-the-oracle-view-of-access-pattern-on-a-16-core-system-running-a-homogeneous-mix-of-xalan" title="Permanent link">&para;</a></h3>
<p><img alt="6c61da1eaeb450a14a7c528e65bd2e70d19a4abb6ff4737fd898f668450e4989.jpg" src="../images/6c61da1eaeb450a14a7c528e65bd2e70d19a4abb6ff4737fd898f668450e4989.jpg" /></p>
<ul>
<li>图片展示了在16核系统上运行xalan工作负载时，Mockingjay替换策略下PC 0x59cdbf对应的ETR值预测结果，对比了三种不同视角：<strong>Global view</strong>（全局视图）、<strong>Myopic view</strong>（近视视图）和<strong>Oracle view</strong>（理想视图）。</li>
<li>横轴为Core-ID（核心ID），从1到15，代表不同核心的观测数据；纵轴为ETR Values（Estimated Time Remaining），表示预测的剩余重用时间。</li>
<li><strong>Global view</strong>用深蓝色实心圆点表示，其ETR值分布相对集中且稳定，整体接近Oracle view，表明全局训练能更准确捕捉跨切片的重用行为。</li>
<li><strong>Myopic view</strong>用浅灰色空心圆圈表示，每个核心对应多个点（最多16个），反映各LLC切片独立训练导致的预测分散性。这些点明显偏离Global view和Oracle view，尤其在部分核心（如Core 1, 3, 7, 11）出现极端低值或高值，说明<strong>局部采样导致预测偏差大、准确性下降</strong>。</li>
<li><strong>Oracle view</strong>用红色实心圆点表示，代表真实重用距离，作为基准。可见Global view与Oracle view高度吻合，而Myopic view则波动剧烈，误差显著。</li>
<li>数据表明，在多核切片式LLC架构中，若沿用每切片独立预测器（Myopic view），会导致<strong>预测精度严重退化</strong>，进而影响替换决策质量。而采用全局共享预测器（Global view）可有效缓解该问题，提升性能。</li>
</ul>
<table>
<thead>
<tr>
<th>视角类型</th>
<th>标识符号</th>
<th>特征描述</th>
<th>预测准确性</th>
</tr>
</thead>
<tbody>
<tr>
<td>Global view</td>
<td>深蓝实心圆</td>
<td>跨所有切片训练，预测稳定且贴近真实值</td>
<td>高</td>
</tr>
<tr>
<td>Myopic view</td>
<td>浅灰空心圆</td>
<td>每切片独立训练，预测分散、波动大</td>
<td>低</td>
</tr>
<tr>
<td>Oracle view</td>
<td>红色实心圆</td>
<td>实际重用距离，作为理想基准</td>
<td>最高</td>
</tr>
</tbody>
</table>
<ul>
<li>此图直观验证了论文提出的“<strong>近视行为</strong>”问题：随着核心数增加，同一PC的访问被分散到不同LLC切片，本地预测器无法获得完整访问模式，从而做出次优甚至错误的替换决策。Drishti方案通过引入<strong>per-core global predictor</strong>，正是为了克服这一根本缺陷。</li>
</ul>
<h3 id="figure-4-frequency-distributionofetrs-and-rrips-in-mockingjay-and-hawkeye-for-xalan-and-pr-running-ona16-core-system">Figure 4: Frequency distributionofETRs and RRIPs in Mockingjay and Hawkeye for xalan and pr running ona16-core system<a class="headerlink" href="#figure-4-frequency-distributionofetrs-and-rrips-in-mockingjay-and-hawkeye-for-xalan-and-pr-running-ona16-core-system" title="Permanent link">&para;</a></h3>
<p><img alt="133735d0929e8f5cc5edaf07abfdf5841e2b5cea3475fa6d2166ab22212d55e1.jpg" src="../images/133735d0929e8f5cc5edaf07abfdf5841e2b5cea3475fa6d2166ab22212d55e1.jpg" /></p>
<ul>
<li>图片展示了在16核系统上，针对xalan和pr两个工作负载，Mockingjay与Hawkeye两种替换策略在“全局视图”（Global view）与“近视视图”（Myopic view）下预测值的频率分布对比。</li>
<li><strong>核心观察</strong>：近视视图导致预测值分布发生显著偏移，偏离全局视图，从而降低预测准确性。</li>
<li><strong>子图 (a) ETR values in xalan with Mockingjay</strong>：<ul>
<li>全局视图下，ETR值主要分布在0-31区间（约45%）和64-128区间（约55%），无32-63区间值。</li>
<li>近视视图下，0-31区间占比骤降至约10%，64-128区间升至约75%，并出现少量32-63区间值（约15%）。</li>
<li>表明在xalan负载下，近视视图严重低估了短重用距离（0-31），高估了长重用距离（64-128）。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>视图</th>
<th>ETR 0-31 (%)</th>
<th>ETR 32-63 (%)</th>
<th>ETR 64-128 (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Global</td>
<td>~45</td>
<td>0</td>
<td>~55</td>
</tr>
<tr>
<td>Myopic</td>
<td>~10</td>
<td>~15</td>
<td>~75</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>子图 (b) ETR values in pr with Mockingjay</strong>：<ul>
<li>全局视图下，ETR值几乎全部集中在0-31区间（&gt;95%），其余区间可忽略。</li>
<li>近视视图下，0-31区间仍占主导（~90%），但出现了少量32-63和64-128区间值。</li>
<li>表明pr负载本身重用模式集中，近视视图虽有轻微扰动，但影响相对较小。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>视图</th>
<th>ETR 0-31 (%)</th>
<th>ETR 32-63 (%)</th>
<th>ETR 64-128 (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Global</td>
<td>&gt;95</td>
<td>\&lt;5</td>
<td>0</td>
</tr>
<tr>
<td>Myopic</td>
<td>~90</td>
<td>~5</td>
<td>~5</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>子图 (c) RRIP values in xalan with Hawkeye</strong>：<ul>
<li>全局视图下，RRIP=0（cache-friendly）占比极低（\&lt;5%），RRIP=7（cache-averse）占比极高（&gt;95%）。</li>
<li>近视视图下，RRIP=0占比大幅上升至约40%，RRIP=7占比下降至约60%。</li>
<li>表明近视视图错误地将大量本应标记为“cache-averse”的块识别为“cache-friendly”，导致替换决策失误。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>视图</th>
<th>RRIP 0 (%)</th>
<th>RRIP 7 (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Global</td>
<td>\&lt;5</td>
<td>&gt;95</td>
</tr>
<tr>
<td>Myopic</td>
<td>~40</td>
<td>~60</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>子图 (d) RRIP values in pr with Hawkeye</strong>：<ul>
<li>全局视图下，RRIP=0占比约60%，RRIP=7占比约40%。</li>
<li>近视视图下，RRIP=0占比进一步上升至约75%，RRIP=7占比下降至约25%。</li>
<li>表明在pr负载下，近视视图同样倾向于过度预测“cache-friendly”，但其基础分布与xalan不同。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>视图</th>
<th>RRIP 0 (%)</th>
<th>RRIP 7 (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Global</td>
<td>~60</td>
<td>~40</td>
</tr>
<tr>
<td>Myopic</td>
<td>~75</td>
<td>~25</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>综合结论</strong>：无论使用Mockingjay还是Hawkeye，近视视图均会扭曲预测值的分布，尤其在xalan这类负载上影响巨大。这种扭曲源于PC访问被分散到不同LLC切片，导致每个切片的本地预测器仅基于局部、不完整的访问历史进行训练，最终做出次优甚至错误的替换决策。这验证了论文中关于“myopic predictions”的核心论点。</li>
</ul>
<h3 id="figure-5-miss-per-kilo-accesses-mpka-per-llc-set-with-three-different-16-core-homogeneous-workloads">Figure 5: Miss per kilo accesses (MPKA) per LLC set with three different 16-core homogeneous workloads.<a class="headerlink" href="#figure-5-miss-per-kilo-accesses-mpka-per-llc-set-with-three-different-16-core-homogeneous-workloads" title="Permanent link">&para;</a></h3>
<p><img alt="dafe876c740783f360803ce2027231754468b90417c9aafbfb613a15a50b7d32.jpg" src="../images/dafe876c740783f360803ce2027231754468b90417c9aafbfb613a15a50b7d32.jpg" /></p>
<ul>
<li>图片展示了三个不同 16 核同构工作负载（mcf、gcc、lbm）下，每个 LLC 集合的 <strong>Miss per Kilo Accesses (MPKA)</strong> 分布情况，横轴为 Set（集合编号），纵轴为 Slice（切片编号），Z 轴为 MPKA 值。</li>
<li><strong>图 (a) mcf</strong>：MPKA 值分布极不均匀，颜色从深蓝（低 MPKA，约 100）到亮黄（高 MPKA，约 500）过渡明显。部分集合 MPKA 极低，而另一些则显著偏高，表明该工作负载对 LLC 集合的访问存在强烈倾斜。</li>
<li><strong>图 (b) gcc</strong>：MPKA 分布相对 mcf 更均匀，但仍存在局部波动。大部分集合 MPKA 在 750 至 925 之间，颜色以绿色和黄色为主，少数区域出现蓝色（低 MPKA）或深紫色（极高 MPKA），说明其访问模式虽较均衡，但仍有部分集合被频繁访问。</li>
<li><strong>图 (c) lbm</strong>：MPKA 值高度一致，所有集合均呈现相近的青绿色，数值集中在 960 至 1040 区间。这表明 lbm 是典型的流式工作负载，对所有 LLC 集合的访问频率几乎相同，无明显热点。</li>
<li>三张图共同揭示了不同工作负载对 LLC 集合访问行为的差异性，这对设计高效采样缓存策略至关重要。若随机选择采样集合，可能因未覆盖高 MPKA 集合而导致预测精度下降。</li>
</ul>
<table>
<thead>
<tr>
<th>工作负载</th>
<th>MPKA 分布特征</th>
<th>颜色范围</th>
<th>访问模式类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>mcf</td>
<td>极度不均匀</td>
<td>深蓝 → 亮黄</td>
<td>强烈倾斜</td>
</tr>
<tr>
<td>gcc</td>
<td>相对均匀，有局部波动</td>
<td>绿 → 黄，少量蓝/紫</td>
<td>较均衡，有热点</td>
</tr>
<tr>
<td>lbm</td>
<td>高度一致</td>
<td>统一青绿</td>
<td>流式，均匀访问</td>
</tr>
</tbody>
</table>
<h3 id="a414717151ed11725279a36c126d05e1e6488e3fe8c84436b02d3fb137d31f89jpg">a414717151ed11725279a36c126d05e1e6488e3fe8c84436b02d3fb137d31f89.jpg<a class="headerlink" href="#a414717151ed11725279a36c126d05e1e6488e3fe8c84436b02d3fb137d31f89jpg" title="Permanent link">&para;</a></h3>
<p><img alt="a414717151ed11725279a36c126d05e1e6488e3fe8c84436b02d3fb137d31f89.jpg" src="../images/a414717151ed11725279a36c126d05e1e6488e3fe8c84436b02d3fb137d31f89.jpg" /></p>
<ul>
<li>该图片为一张小型数据表格，源自论文第3.2节“Under-utilized sampled cache”，用于展示在16核系统上运行<code>mcf</code>工作负载时，不同采样集选择策略对Mockingjay替换策略性能的影响。</li>
<li>表格包含两行三列，第一行为表头，第二行为性能提升百分比数据。</li>
<li><strong>表头</strong>清晰标明了三种不同的实验案例（Case I, II, III），分别对应不同的LLC采样集选择方法。</li>
<li><strong>数据行</strong>显示了每种案例下的性能加速比（Speedup%），具体数值如下：</li>
</ul>
<table>
<thead>
<tr>
<th>Case</th>
<th>I</th>
<th>II</th>
<th>III</th>
</tr>
</thead>
<tbody>
<tr>
<td>Speedup(%)</td>
<td><strong>16.4</strong></td>
<td><strong>8.3</strong></td>
<td><strong>9.5</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Case I</strong>：选择MPKA（Miss per Kilo Access）最高的32个LLC集合作为采样集，获得了<strong>16.4%</strong>的最高性能提升。</li>
<li><strong>Case II</strong>：选择MPKA最低的32个LLC集合作为采样集，性能提升仅为<strong>8.3%</strong>，是三种情况中最差的。</li>
<li><strong>Case III</strong>：混合选择，一半（16个）为高MPKA集合，另一半（16个）为低MPKA集合，性能提升为<strong>9.5%</strong>，介于前两者之间。</li>
<li>该结果有力地支持了论文的核心论点之一：随机选择采样集会导致次优决策，而基于访问频率（如MPKA）动态选择高需求集合能显著提升预测准确性和整体性能。</li>
</ul>
<h3 id="figure-6-tracking-reuse-behavior-and-training-the-local-predictors-with-a-global-centralized-sampled-cache">Figure 6: Tracking reuse behavior and training the local predictors with a global (centralized) sampled cache.<a class="headerlink" href="#figure-6-tracking-reuse-behavior-and-training-the-local-predictors-with-a-global-centralized-sampled-cache" title="Permanent link">&para;</a></h3>
<p><img alt="d399ff4f5b6db784981a990c235372f43d078f09ef1242e847098ef06d2eabe1.jpg" src="../images/d399ff4f5b6db784981a990c235372f43d078f09ef1242e847098ef06d2eabe1.jpg" /></p>
<ul>
<li>图片展示了在<strong>分片式 LLC (sliced LLC)</strong> 架构下，采用<strong>全局集中式采样缓存 (centralized sampled cache)</strong> 来追踪重用行为并训练各个本地预测器的系统结构。</li>
<li><strong>核心组件</strong>包括：<ul>
<li>多个 <strong>LLC slice</strong>（图中展示从 slice 0 到 slice 31）。</li>
<li>一个位于中央的 <strong>Centralized Sampled Cache</strong>。</li>
<li>每个 LLC slice 对应一个本地 <strong>Predictor</strong>。</li>
</ul>
</li>
<li><strong>数据流与交互过程</strong>：<ul>
<li>当某个 LLC slice（如 slice 0）发生访问时，它会将 <strong>PC、地址、命中/未命中状态</strong> 发送给中央采样缓存（步骤①）。</li>
<li>中央采样缓存根据接收到的信息，计算出该 PC 的<strong>重用距离 (Reuse Distance)</strong>，然后将此信息广播给所有本地预测器（步骤②）。</li>
<li>所有本地预测器都会根据接收到的 PC 和重用距离信息来更新自身的预测模型。</li>
</ul>
</li>
<li><strong>设计意图</strong>：通过集中式采样缓存统一收集所有切片的访问信息，从而避免因访问分散到不同切片而导致的<strong>局部性预测偏差 (myopic predictions)</strong>。</li>
<li><strong>潜在问题</strong>：<ul>
<li><strong>带宽瓶颈</strong>：所有切片的访问信息都需发送至中央采样缓存，随着核心数增加，通信量激增。</li>
<li><strong>广播开销</strong>：每次更新都需要向所有预测器广播，进一步加剧了互连带宽压力。</li>
</ul>
</li>
<li><strong>对比分析</strong>：</li>
</ul>
<table>
<thead>
<tr>
<th>设计方案</th>
<th>采样缓存位置</th>
<th>预测器位置</th>
<th>主要优势</th>
<th>主要劣势</th>
</tr>
</thead>
<tbody>
<tr>
<td>原始设计</td>
<td>每切片本地</td>
<td>每切片本地</td>
<td>低延迟，无跨切片通信</td>
<td>预测局部化，准确性差</td>
</tr>
<tr>
<td><strong>图示设计 (Figure 6)</strong></td>
<td><strong>中央集中式</strong></td>
<td><strong>每切片本地</strong></td>
<td><strong>全局视角，提升预测准确性</strong></td>
<td><strong>严重带宽瓶颈，广播开销大</strong></td>
</tr>
<tr>
<td>Drishti 设计</td>
<td>每切片本地</td>
<td><strong>每核心全局式</strong></td>
<td>平衡准确性与带宽开销</td>
<td>需专用低延迟互连</td>
</tr>
</tbody>
</table>
<ul>
<li>该图旨在说明，虽然集中式采样缓存能提供全局视图以改善预测，但其带来的<strong>互连带宽和流量问题</strong>使其在多核系统中难以扩展。这正是 Drishti 提出“每核心全局预测器 + 本地采样缓存”方案的动机所在。</li>
</ul>
<h3 id="figure-7-tracking-reuse-behavior-and-training-the-local-predictors-with-a-global-distributed-sampled-cache">Figure 7: Tracking reuse behavior and training the local predictors with a global (distributed) sampled cache.<a class="headerlink" href="#figure-7-tracking-reuse-behavior-and-training-the-local-predictors-with-a-global-distributed-sampled-cache" title="Permanent link">&para;</a></h3>
<p><img alt="5479e0934da1c80acb4a01044329873d41abc3bc85eb16dee9567bf7326c7347.jpg" src="../images/5479e0934da1c80acb4a01044329873d41abc3bc85eb16dee9567bf7326c7347.jpg" /></p>
<ul>
<li>该图展示了在 <strong>32-core</strong> 系统中，使用 <strong>global (distributed) sampled cache</strong> 来追踪重用行为并训练 <strong>local predictors</strong> 的架构。</li>
<li>图中包含 <strong>32个 LLC slices</strong>（从 slice 0 到 slice 31），每个 slice 都连接到一个独立的 <strong>Sampled Cache</strong> 和 <strong>Predictor</strong> 模块。</li>
<li><strong>步骤①</strong>：当某个 LLC slice（如 slice 0）发生访问时，会将 <strong>PC, Address, Hit/Miss</strong> 信息发送给其对应的 <strong>Sampled Cache</strong> 进行记录。</li>
<li><strong>步骤②</strong>：<strong>Sampled Cache</strong> 在记录访问后，会将重用行为（如重用距离）反馈给所有 <strong>32个 Predictor</strong>，实现全局广播更新。</li>
<li><strong>关键设计点</strong>：虽然 <strong>Sampled Cache</strong> 是分布式的（每个 slice 一个），但其功能是全局的，因为它能与所有 slice 的 Predictor 通信，从而避免了集中式结构的带宽瓶颈。</li>
<li><strong>优势</strong>：相比集中式采样缓存，分布式结构允许并发访问，缓解了高核心数下的带宽压力。</li>
<li><strong>挑战</strong>：仍需广播更新所有 Predictor，这在大规模系统中可能带来额外的互连带宽开销。</li>
<li><strong>术语保留</strong>：LLC slice、Sampled Cache、Predictor、PC、Hit/Miss、global (distributed) sampled cache。</li>
</ul>
<table>
<thead>
<tr>
<th>组件</th>
<th>功能描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>LLC slice 0~31</td>
<td>分布式最后一级缓存切片，每个切片处理本地访问。</td>
</tr>
<tr>
<td>Sampled Cache</td>
<td>记录来自对应 LLC slice 的访问信息（PC, Address, Hit/Miss）。</td>
</tr>
<tr>
<td>Predictor</td>
<td>根据 Sampled Cache 提供的重用行为进行预测，每个 slice 有一个本地预测器。</td>
</tr>
<tr>
<td>步骤①</td>
<td>LLC slice 向其 Sampled Cache 发送访问信息。</td>
</tr>
<tr>
<td>步骤②</td>
<td>Sampled Cache 向所有 Predictor 广播重用行为以更新预测模型。</td>
</tr>
</tbody>
</table>
<ul>
<li>该架构旨在平衡 <strong>全局视图</strong> 与 <strong>可扩展性</strong>，通过分布式采样缓存减少单点瓶颈，同时保持对全局重用模式的感知能力。</li>
</ul>
<h3 id="figure-8-tracking-reuse-behavior-by-a-local-sampled-cache-and-using-it-to-train-the-global-centralized-predictor">Figure 8: Tracking reuse behavior by a local sampled cache and using it to train the global (centralized) predictor.<a class="headerlink" href="#figure-8-tracking-reuse-behavior-by-a-local-sampled-cache-and-using-it-to-train-the-global-centralized-predictor" title="Permanent link">&para;</a></h3>
<p><img alt="e16456fd3fdb5ff33829435bb7d63a0235dd7ed293168c52f01caa8ceb650bed.jpg" src="../images/e16456fd3fdb5ff33829435bb7d63a0235dd7ed293168c52f01caa8ceb650bed.jpg" /></p>
<ul>
<li>图片展示了在<strong>分片式 LLC (sliced LLC)</strong> 架构下，一种名为 <strong>“Centralized Predictor”</strong> 的全局复用预测器的设计方案，其核心是利用各 <strong>LLC slice</strong> 内的本地 <strong>Sampled Cache</strong> 来训练一个集中式的预测器。</li>
<li>该图描绘了数据流和控制流的两个关键步骤：<ul>
<li>步骤①：当某个 <strong>LLC slice</strong>（如 LLC slice 0）发生访问时，它会将访问信息（包括 <strong>PC, Address, Hit/Miss</strong>）发送给其本地的 <strong>Sampled Cache</strong> 进行记录。</li>
<li>步骤②：本地 <strong>Sampled Cache</strong> 在记录后，会将提取出的 <strong>PC</strong> 和对应的 <strong>Reuse Behavior</strong>（例如命中/未命中、重用距离等）上报给位于系统中心的 <strong>Centralized Predictor</strong>，用于更新全局预测模型。</li>
</ul>
</li>
<li>该设计旨在解决“<strong>myopic predictions</strong>”问题，即每个切片的本地预测器只能看到本切片内的访问行为，导致预测不准确。通过集中所有切片的数据进行训练，预测器可以获得更全面的全局视图。</li>
<li>然而，这种设计也带来了显著的挑战：<ul>
<li><strong>带宽瓶颈</strong>：所有 LLC slices 的访问信息都必须汇聚到单一的 Centralized Predictor，随着核心数增加，通信流量激增。</li>
<li><strong>广播开销</strong>：由于一个 PC 的访问可能分散在多个切片，当预测器更新时，需要向所有相关切片的本地预测器广播更新消息，进一步加剧了互连带宽压力。</li>
</ul>
</li>
<li>与论文中提出的 <strong>Drishti</strong> 方案相比，此图所示的 Centralized Predictor 是一种被作者认为“<strong>costly design choice</strong>”的备选方案。Drishti 采用的是 <strong>per-core yet global predictor</strong>，即每个核心拥有一个独立的预测器，放置在离其最近的 LLC slice 旁，从而避免了单点瓶颈和全网广播。</li>
<li>下表总结了该图所代表的设计与 Drishti 设计的关键对比：</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">特性</th>
<th style="text-align: left;">图中设计 (Centralized Predictor)</th>
<th style="text-align: left;">Drishti 设计 (Per-core Global Predictor)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>预测器位置</strong></td>
<td style="text-align: left;">单一集中式</td>
<td style="text-align: left;">分布式，每个核心一个</td>
</tr>
<tr>
<td style="text-align: left;"><strong>训练数据来源</strong></td>
<td style="text-align: left;">所有 LLC slices 的 Sampled Cache</td>
<td style="text-align: left;">所有 LLC slices 的 Sampled Cache</td>
</tr>
<tr>
<td style="text-align: left;"><strong>主要优势</strong></td>
<td style="text-align: left;">全局视图，预测精度高</td>
<td style="text-align: left;">避免单点瓶颈，降低带宽压力</td>
</tr>
<tr>
<td style="text-align: left;"><strong>主要劣势</strong></td>
<td style="text-align: left;">带宽瓶颈，广播开销大</td>
<td style="text-align: left;">需要专用低延迟互连 (NOCSTAR)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>可扩展性</strong></td>
<td style="text-align: left;">差，随核心数增加性能下降</td>
<td style="text-align: left;">好，设计上支持大规模多核</td>
</tr>
</tbody>
</table>
<ul>
<li>总之，该图清晰地阐释了为解决分片式缓存带来的“近视”预测问题，一种直观但代价高昂的集中式解决方案，也为理解 Drishti 提出的分布式、每核心全局预测器的优越性提供了重要背景。</li>
</ul>
<h3 id="figure-9-drishtis-enhancement-tracking-reuse-behavior-and-training-the-per-core-and-yet-global-reuse-predictor-with-local-per-slice-sampled-caches">Figure 9: Drishti's enhancement: Tracking reuse behavior and training the per-core and yet global reuse predictor with local (per-slice) sampled caches.<a class="headerlink" href="#figure-9-drishtis-enhancement-tracking-reuse-behavior-and-training-the-per-core-and-yet-global-reuse-predictor-with-local-per-slice-sampled-caches" title="Permanent link">&para;</a></h3>
<p><img alt="d1fb66abe495352f9851f1eec950332b277dc1a0372947b9d3718aa0ce6e1c72.jpg" src="../images/d1fb66abe495352f9851f1eec950332b277dc1a0372947b9d3718aa0ce6e1c72.jpg" /></p>
<ul>
<li>图片展示了 Drishti 增强方案的核心架构，旨在解决多核系统中切片式 LLC（Sliced LLC）带来的“近视”预测问题。</li>
<li>该架构采用 <strong>本地每切片采样缓存</strong>（Local per-slice Sampled Cache）与 <strong>每核心但全局复用预测器</strong>（Per-core yet Global Reuse Predictor）的组合设计。</li>
<li>图中包含 32 个 LLC 切片（LLC slice 0 至 LLC slice 31），每个切片配备一个独立的 <strong>采样缓存</strong>（Sampled Cache），用于记录本切片内发生的访问行为。</li>
<li>每个核心（Core 0 至 Core 31）拥有一个专属的 <strong>预测器</strong>（Predictor），该预测器虽物理上分布于各切片附近，但逻辑上为全局共享，可被所有切片访问。</li>
<li>当某个 LLC 切片（如 LLC slice 0）发生采样集访问时，会将相关信息（PC、地址、命中/未命中状态）传递给其本地采样缓存（步骤①）。</li>
<li>本地采样缓存随后将复用行为信息（PC, Reuse Behavior）发送至对应核心的预测器进行训练（步骤②），例如 Core 0 的预测器接收来自 LLC slice 0 的数据。</li>
<li>此设计避免了传统集中式预测器的带宽瓶颈，同时克服了每切片本地预测器的“近视”缺陷，实现了<strong>全局视角下的精准复用预测</strong>。</li>
<li>关键优势在于：<strong>预测器按核心划分，靠近核心部署</strong>，减少跨切片通信延迟；<strong>采样缓存仍保持本地化</strong>，维持低开销和高效率。</li>
</ul>
<table>
<thead>
<tr>
<th>组件</th>
<th>功能</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>LLC Slice</strong></td>
<td>存储实际数据块，支持多核共享访问</td>
<td>分布式结构，非均匀访问（NUCA）</td>
</tr>
<tr>
<td><strong>Sampled Cache (per slice)</strong></td>
<td>跟踪本切片内采样集的访问行为</td>
<td>本地化，轻量级，仅监控部分集合</td>
</tr>
<tr>
<td><strong>Predictor (per core)</strong></td>
<td>根据 PC 预测缓存行复用行为</td>
<td>全局可见，按核心索引，物理分布</td>
</tr>
<tr>
<td><strong>Interconnect (NOCSTAR)</strong></td>
<td>连接采样缓存与预测器</td>
<td>专用低延迟互连，3周期延迟</td>
</tr>
</tbody>
</table>
<ul>
<li>该图清晰体现了 Drishti 的两大增强：一是<strong>预测器全局化但按核心部署</strong>，二是<strong>采样缓存本地化</strong>，二者协同提升预测准确性。</li>
<li>通过此架构，即使同一 PC 的负载被映射到不同切片，其复用行为仍能被统一收集并训练至对应核心的预测器，从而获得更全面的访问模式认知。</li>
</ul>
<h3 id="figure-10-accesses-per-kilo-instructions-to-the-centralized-and-per-core-global-predictors-in-mockingjayaveraged-across-35-homogeneous-and-35-heterogeneous-mixes-each-bar-shows-the-training-and-prediction-lookups-to-the-predictor">Figure 10: Accesses per kilo instructions to the centralized and per-core global predictors in Mockingjay,averaged across 35 homogeneous and 35 heterogeneous mixes. Each bar shows the training and prediction lookups to the predictor.<a class="headerlink" href="#figure-10-accesses-per-kilo-instructions-to-the-centralized-and-per-core-global-predictors-in-mockingjayaveraged-across-35-homogeneous-and-35-heterogeneous-mixes-each-bar-shows-the-training-and-prediction-lookups-to-the-predictor" title="Permanent link">&para;</a></h3>
<p><img alt="b8f26cb8260be139143f1195636ab0a57e3ad05d85215631eb875d750112db7d.jpg" src="../images/b8f26cb8260be139143f1195636ab0a57e3ad05d85215631eb875d750112db7d.jpg" /></p>
<ul>
<li>图片展示了在 Mockingjay 替换策略下，<strong>集中式预测器 (Centralized predictor)</strong> 与 <strong>每核全局预测器 (Per-core yet global predictor)</strong> 在不同核心数（4、16、32）下的访问频率对比，单位为“每千条指令的访问次数”，数据基于 35 个同构和 35 个异构混合负载的平均值。</li>
<li>每个柱状图分为两部分：<strong>训练 (Training)</strong> 和 <strong>预测 (Prediction)</strong> 访问，分别用斜线填充和纯色填充表示。</li>
<li>核心观察：<ul>
<li>随着核心数从 4 增加到 32，<strong>集中式预测器</strong> 的总访问量急剧上升，最大访问量从约 100 跃升至超过 250，平均访问量也从约 15 增长至近 70。</li>
<li>相比之下，<strong>每核全局预测器</strong> 的访问量增长极为平缓，最大访问量从约 10 略增至 15，平均访问量稳定在 2.5 左右。</li>
<li>这表明集中式设计会带来严重的带宽瓶颈，而每核全局设计能有效分散访问压力，保持低开销。</li>
</ul>
</li>
</ul>
<p>以下是关键数据的表格化总结：</p>
<table>
<thead>
<tr>
<th>核心数</th>
<th>预测器类型</th>
<th>最大访问量 (per kilo instructions)</th>
<th>平均访问量 (per kilo instructions)</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>Centralized</td>
<td>~100</td>
<td>~15</td>
</tr>
<tr>
<td>4</td>
<td>Per-core global</td>
<td>~10</td>
<td>~2.5</td>
</tr>
<tr>
<td>16</td>
<td>Centralized</td>
<td>~150</td>
<td>~30</td>
</tr>
<tr>
<td>16</td>
<td>Per-core global</td>
<td>~12</td>
<td>~2.5</td>
</tr>
<tr>
<td>32</td>
<td>Centralized</td>
<td>&gt;250</td>
<td>~70</td>
</tr>
<tr>
<td>32</td>
<td>Per-core global</td>
<td>~15</td>
<td>~2.5</td>
</tr>
</tbody>
</table>
<ul>
<li>此图直观论证了 Drishti 提出的“每核全局预测器”设计的必要性：它能在保持全局视图优势的同时，将预测器访问开销控制在极低水平，避免成为系统性能瓶颈。</li>
</ul>
<h3 id="table-2-potential-design-choices-to-address-myopic-predictionsalong-with-their-advantages-and-disadvantages">Table 2: Potential design choices to address myopic predictions,along with their advantages and disadvantages.<a class="headerlink" href="#table-2-potential-design-choices-to-address-myopic-predictionsalong-with-their-advantages-and-disadvantages" title="Permanent link">&para;</a></h3>
<p><img alt="347b818e9942ee29d18912cfedb70f4b68bac7cd1abedb79da624192d798b06b.jpg" src="../images/347b818e9942ee29d18912cfedb70f4b68bac7cd1abedb79da624192d798b06b.jpg" /></p>
<ul>
<li>该表格（Table 2）系统性地对比了四种应对“myopic predictions”（短视预测）的设计方案，核心变量为 <strong>Sampled cache</strong> 和 <strong>Predictor</strong> 的部署方式（Local 或 Global），以及 Global 结构的实现形态（Centralized 或 Distributed）。</li>
<li>表格从三个维度评估各方案：是否提供 <strong>Global View</strong>（全局视角）、<strong>Bandwidth</strong>（带宽开销）和是否需要 <strong>Broadcast</strong>（广播机制）。</li>
<li><strong>关键结论</strong>：Drishti 采用的方案——<strong>Local Sampled Cache + Distributed Global Predictor</strong>——在表格中被高亮标出，其优势在于同时满足 <strong>Yes</strong>（全局视角）、<strong>Low</strong>（低带宽）和 <strong>No</strong>（无需广播），是唯一达成此三重优化的组合。</li>
</ul>
<table>
<thead>
<tr>
<th>Sampled cache</th>
<th>Predictor</th>
<th>Type</th>
<th>Global View?</th>
<th>Bandwidth</th>
<th>Broadcast?</th>
</tr>
</thead>
<tbody>
<tr>
<td>Global</td>
<td>Local</td>
<td>Centralized</td>
<td>Yes</td>
<td>High</td>
<td>Yes</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Distributed</td>
<td>Yes</td>
<td>Low</td>
<td>Yes</td>
</tr>
<tr>
<td>Local</td>
<td>Global</td>
<td>Centralized</td>
<td>Yes</td>
<td>High</td>
<td>No</td>
</tr>
<tr>
<td></td>
<td></td>
<td><strong>Distributed</strong></td>
<td><strong>Yes</strong></td>
<td><strong>Low</strong></td>
<td><strong>No</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Global Sampled Cache + Local Predictor</strong> 方案：<ul>
<li>无论 Centralized 或 Distributed，均需 <strong>Broadcast</strong> 更新所有本地预测器，导致带宽压力大或结构复杂。</li>
<li>虽然能提供全局视角，但广播机制成为性能瓶颈，尤其在多核系统中。</li>
</ul>
</li>
<li><strong>Local Sampled Cache + Centralized Global Predictor</strong> 方案：<ul>
<li>避免了广播，但所有切片访问都需竞争单一中央预测器，造成 <strong>High Bandwidth</strong> 瓶颈。</li>
<li>随着核心数增加，争用加剧，扩展性差。</li>
</ul>
</li>
<li><strong>Local Sampled Cache + Distributed Global Predictor</strong>（Drishti 方案）：<ul>
<li><strong>Per-core predictor</strong> 分布于各切片，靠近对应核心，减少跨切片访问延迟。</li>
<li>仅当本地采样缓存命中时才更新对应核心的预测器，避免全局广播。</li>
<li>通过专用低延迟互连（NOCSTAR）保障通信效率，最终实现 <strong>Low Bandwidth</strong> 与 <strong>No Broadcast</strong> 的平衡。</li>
<li>此设计有效缓解了 myopic behavior，同时保持系统可扩展性。</li>
</ul>
</li>
</ul>
<h3 id="figure-11-a-slowdown-in-mockingjay-with-drishti-without-a-low-latency-interconnect-between-slices-and-the-predictors-binterconnect-latency-sensitivity-on-a-32-core-system-across-35-homogeneous-and-35-heterogeneous-mixes">Figure 11: (a) Slowdown in Mockingjay with Drishti without a low-latency interconnect between slices and the predictors. (b)Interconnect latency sensitivity on a 32-core system across 35 homogeneous and 35 heterogeneous mixes.<a class="headerlink" href="#figure-11-a-slowdown-in-mockingjay-with-drishti-without-a-low-latency-interconnect-between-slices-and-the-predictors-binterconnect-latency-sensitivity-on-a-32-core-system-across-35-homogeneous-and-35-heterogeneous-mixes" title="Permanent link">&para;</a></h3>
<p><img alt="70c486d52e124569e24857169dd1a3d7d26dbe698f4633315f2dbe79781b491a.jpg" src="../images/70c486d52e124569e24857169dd1a3d7d26dbe698f4633315f2dbe79781b491a.jpg" /></p>
<ul>
<li>图 11 包含两个子图，分别展示 <strong>Drishti</strong> 增强版 Mockingjay 在缺乏低延迟互连时的性能退化情况。</li>
<li>子图 (a) 显示在不同核心数系统中，使用现有片上互连（非 NOCSTAR）导致的性能下降百分比：<ul>
<li><strong>4 核心系统</strong>：平均性能下降约 <strong>2.8%</strong>。</li>
<li><strong>16 核心系统</strong>：平均性能下降约 <strong>5.5%</strong>。</li>
<li><strong>32 核心系统</strong>：平均性能下降约 <strong>9%</strong>，部分工作负载（如 mcf）最高可达 <strong>40%</strong>。</li>
</ul>
</li>
<li>子图 (b) 展示在 <strong>32 核心系统</strong> 中，互连延迟（以周期计）对性能的影响：<ul>
<li>延迟为 <strong>1 周期</strong>：几乎无性能损失。</li>
<li>延迟为 <strong>5 周期</strong>：轻微性能下降。</li>
<li>延迟为 <strong>10 周期</strong>：性能下降约 <strong>5%</strong>。</li>
<li>延迟为 <strong>20 周期</strong>：性能下降约 <strong>10%</strong>。</li>
<li>延迟为 <strong>30 周期</strong>：性能下降超过 <strong>15%</strong>。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>互连延迟 (周期)</th>
<th>性能下降 (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>~0%</td>
</tr>
<tr>
<td>5</td>
<td>\&lt;5%</td>
</tr>
<tr>
<td>10</td>
<td>~5%</td>
</tr>
<tr>
<td>20</td>
<td>~10%</td>
</tr>
<tr>
<td>30</td>
<td>&gt;15%</td>
</tr>
</tbody>
</table>
<ul>
<li>关键结论：<strong>NOCSTAR 互连</strong> 的 <strong>3 周期延迟</strong> 是确保 Drishti 高效运行的关键；若延迟超过 <strong>5 周期</strong>，性能优势将被抵消甚至逆转。</li>
<li>该图强调了 <strong>低延迟互连设计</strong> 对于 Drishti 架构在多核系统中的必要性，尤其在核心数增加时，延迟影响呈非线性放大。</li>
</ul>
<h3 id="table-3-per-core-hardware-budget-with-and-without-drishti-for-a-16-way-2mb-llc-slice">Table 3: Per-core hardware budget with and without Drishti for a 16-way 2MB LLC slice.<a class="headerlink" href="#table-3-per-core-hardware-budget-with-and-without-drishti-for-a-16-way-2mb-llc-slice" title="Permanent link">&para;</a></h3>
<p><img alt="0abaf749c497c949f9ccecde5dffa544e3027b0ee188b124e372b5fc8f6f67da.jpg" src="../images/0abaf749c497c949f9ccecde5dffa544e3027b0ee188b124e372b5fc8f6f67da.jpg" /></p>
<ul>
<li>
<p><strong>Drishti 对硬件预算的影响</strong>：该表格详细对比了在 16-way 2MB LLC slice 配置下，Hawkeye 和 Mockingjay 两种替换策略在应用 Drishti 增强前后的每核心硬件开销。</p>
</li>
<li>
<p><strong>Hawkeye 策略的硬件变化</strong>：</p>
<ul>
<li><strong>采样缓存 (Sampled Cache)</strong>：从 <strong>12 KB</strong> 大幅缩减至 <strong>3 KB</strong>。</li>
<li><strong>占用向量 (Occupancy Vector)</strong>：保持 <strong>1 KB</strong> 不变。</li>
<li><strong>预测器 (Predictor)</strong>：保持 <strong>3 KB</strong> 不变。</li>
<li><strong>RRIP 计数器 (RRIP counters)</strong>：保持 <strong>12 KB</strong> 不变。</li>
<li><strong>饱和计数器 (Saturating counters)</strong>：新增 <strong>1.75 KB</strong>（用于动态采样）。</li>
<li><strong>总计</strong>：总开销从 <strong>28 KB</strong> 降至 <strong>20.75 KB</strong>，实现 <strong>7.25 KB</strong> 的净节省。</li>
</ul>
</li>
<li>
<p><strong>Mockingjay 策略的硬件变化</strong>：</p>
<ul>
<li><strong>采样缓存 (Sampled Cache)</strong>：从 <strong>9.41 KB</strong> 缩减至 <strong>4.7 KB</strong>。</li>
<li><strong>预测器 (Predictor)</strong>：保持 <strong>1.75 KB</strong> 不变。</li>
<li><strong>ETR 计数器 (ETR counters)</strong>：保持 <strong>20.75 KB</strong> 不变。</li>
<li><strong>饱和计数器 (Saturating counters)</strong>：新增 <strong>1.75 KB</strong>（用于动态采样）。</li>
<li><strong>总计</strong>：总开销从 <strong>31.91 KB</strong> 降至 <strong>28.95 KB</strong>，实现 <strong>2.96 KB</strong> 的净节省。</li>
</ul>
</li>
<li>
<p><strong>核心结论</strong>：</p>
<ul>
<li>Drishti 的主要优化在于<strong>智能减少采样缓存大小</strong>，通过动态选择高 MPKA 的集合，用更少的采样集获得更好的预测效果。</li>
<li>新增的饱和计数器带来的存储开销被采样缓存的大幅缩减所抵消，最终实现了<strong>净存储节省</strong>。</li>
<li>这种设计不仅提升了性能，还降低了硬件成本，体现了 Drishti 在资源效率上的优势。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>Replacement Policy</th>
<th>Component</th>
<th>Without Drishti</th>
<th>With Drishti</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hawkeye</td>
<td>Sampled Cache</td>
<td>12 KB</td>
<td><strong>3 KB</strong></td>
</tr>
<tr>
<td></td>
<td>Occupancy Vector</td>
<td>1 KB</td>
<td>1 KB</td>
</tr>
<tr>
<td></td>
<td>Predictor</td>
<td>3 KB</td>
<td>3 KB</td>
</tr>
<tr>
<td></td>
<td>RRIP counters</td>
<td>12 KB</td>
<td>12 KB</td>
</tr>
<tr>
<td></td>
<td>Saturating counters</td>
<td>NA</td>
<td><strong>1.75 KB</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Total</strong></td>
<td><strong>28 KB</strong></td>
<td><strong>20.75 KB</strong></td>
</tr>
<tr>
<td>Mockingjay</td>
<td>Sampled Cache</td>
<td>9.41 KB</td>
<td><strong>4.7 KB</strong></td>
</tr>
<tr>
<td></td>
<td>Predictor</td>
<td>1.75 KB</td>
<td>1.75 KB</td>
</tr>
<tr>
<td></td>
<td>ETR counters</td>
<td>20.75 KB</td>
<td>20.75 KB</td>
</tr>
<tr>
<td></td>
<td>Saturating counters</td>
<td>NA</td>
<td><strong>1.75 KB</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Total</strong></td>
<td><strong>31.91 KB</strong></td>
<td><strong>28.95 KB</strong></td>
</tr>
</tbody>
</table>
<h3 id="table-4-simulation-parameters-of-the-baseline-system">Table 4: Simulation parameters of the baseline system.<a class="headerlink" href="#table-4-simulation-parameters-of-the-baseline-system" title="Permanent link">&para;</a></h3>
<p><img alt="7f3b940883616d7c30799a3c84a7ad8e1e8c7f67f6113e54d6185715dd755b49.jpg" src="../images/7f3b940883616d7c30799a3c84a7ad8e1e8c7f67f6113e54d6185715dd755b49.jpg" /></p>
<ul>
<li>该表格详细列出了论文中用于仿真的基线系统参数，为评估 Drishti 增强方案提供了硬件配置基准。</li>
<li>核心（Core）部分采用<strong>乱序执行</strong>架构，配备<strong>哈希感知器分支预测器</strong>，运行频率为 <strong>4 GHz</strong>，具备 <strong>6 发射宽度</strong>、<strong>4 重提宽度</strong>和 <strong>352 项 ROB</strong>。</li>
<li>TLBs 配置包括 L1 iTLB/dTLB（64 项，4 路，1 周期）和 STLB（1536 项，12 路，8 周期），确保地址转换效率。</li>
<li>L1I 缓存为 <strong>32 KB</strong>，8 路组相联，访问延迟 <strong>4 周期</strong>，配备 <strong>8 个 MSHR</strong> 和 <strong>LRU 替换策略</strong>。</li>
<li>L1D 缓存为 <strong>48 KB</strong>，12 路组相联，访问延迟 <strong>5 周期</strong>，配备 <strong>16 个 MSHR</strong>、<strong>LRU 替换策略</strong>及<strong>下一行预取器</strong>。</li>
<li>L2 缓存为 <strong>512 KB</strong>，8 路组相联，访问延迟 <strong>15 周期</strong>，配备 <strong>32 个 MSHR</strong>、<strong>SRRIP 替换策略</strong>、<strong>非包含式设计</strong>及<strong>IP-stride 预取器</strong>。</li>
<li>LLC 采用<strong>每核一片</strong>的切片设计，每片容量 <strong>2 MB</strong>，16 路组相联，访问延迟 <strong>20 周期</strong>，配备 <strong>64 个 MSHR</strong>、<strong>LRU 替换策略</strong>及<strong>非包含式设计</strong>，地址映射方式参考文献 [33]。</li>
<li>网络路由器采用<strong>两级虫洞</strong>结构，每个端口支持<strong>六个虚拟通道</strong>，数据包缓冲深度为<strong>八个 flit</strong>，地址包为<strong>一个 flit</strong>。</li>
<li>网络拓扑为<strong>Mesh 结构</strong>，每个节点包含一个路由器、处理器、私有 L1 缓存、L2 缓存和一个 LLC 切片。</li>
<li>DRAM 控制器配置为<strong>每通道服务 4 核心</strong>，带宽 <strong>6400 MT/s</strong>，采用 <strong>FR-FCFS 调度策略</strong>，写水位为 <strong>7/8th</strong>，芯片级配置包括 <strong>4 KB 行缓冲区</strong>、<strong>开放页策略</strong>，以及关键时序参数：<strong>tRP: 12.5 ns</strong>、<strong>tRCD: 12.5 ns</strong>、<strong>tCAS: 12.5 ns</strong>。</li>
</ul>
<table>
<thead>
<tr>
<th>组件</th>
<th>参数描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Core</td>
<td>Out-of-order, hashed-perceptron branch predictor, 4 GHz, 6-issue width, 4-retire width, 352-entry ROB</td>
</tr>
<tr>
<td>TLBs</td>
<td>L1 iTLB/dTLB: 64 entries, 4-way, 1 cycle; STLB: 1536 entries, 12-way, 8 cycles</td>
</tr>
<tr>
<td>L1I</td>
<td>32 KB, 8-way, 4 cycles, 8 MSHRs, LRU</td>
</tr>
<tr>
<td>L1D</td>
<td>48 KB, 12-way, 5 cycles, 16 MSHRs, LRU, next-line prefetcher</td>
</tr>
<tr>
<td>L2</td>
<td>512 KB, 8-way, 15 cycles, 32 MSHRs, SRRIP, non-inclusive, IP-stride prefetcher</td>
</tr>
<tr>
<td>LLC</td>
<td>1 slice per core, 2 MB, 16-way, 20 cycles, 64 MSHRs, LRU, non-inclusive</td>
</tr>
<tr>
<td>Network Router</td>
<td>2-stage wormhole, six virtual channels per port, eight flits per data packet, one flit per address packet</td>
</tr>
<tr>
<td>Network Topology</td>
<td>Mesh, each node has a router, processor, private L1 cache, L2 cache, and an LLC slice</td>
</tr>
<tr>
<td>DRAM</td>
<td>Controller: One channel/4-cores, 6400 MT/s, FR-FCFS, write watermark: 7/8th, Chip: 4 KB row-buffer, open page, tRP: 12.5 ns, tRCD: 12.5 ns, tCAS: 12.5 ns</td>
</tr>
</tbody>
</table>
<ul>
<li>所有缓存层级均采用<strong>多扇区缓冲区（MSHR）</strong>机制，以提升并发处理能力。</li>
<li>LLC 的<strong>非包含式设计</strong>有助于减少冗余存储，提高整体缓存利用率。</li>
<li><strong>Mesh 拓扑</strong>与<strong>低延迟互连（NOCSTAR）</strong>结合，确保在多核系统中高效通信。</li>
<li>DRAM 的<strong>FR-FCFS 调度策略</strong>与<strong>开放页策略</strong>优化了内存访问延迟和带宽利用率。</li>
</ul>
<h3 id="figure13-performance-improvement-with-state-of-the-artllcreplacement-policies-normalized-tolruon4-core6-core-32-core-systems-with-8mb32mband-64mb-sliced-llc-across-70-mixes-35-homogeneous-and-35-heterogeneous">Figure13: Performance improvement with state-of-the-artLLCreplacement policies normalized toLRUon4-core,6-core, 32-core systems with 8MB,32MB,and 64MB sliced LLC across 70 mixes (35 homogeneous and 35 heterogeneous).<a class="headerlink" href="#figure13-performance-improvement-with-state-of-the-artllcreplacement-policies-normalized-tolruon4-core6-core-32-core-systems-with-8mb32mband-64mb-sliced-llc-across-70-mixes-35-homogeneous-and-35-heterogeneous" title="Permanent link">&para;</a></h3>
<p><img alt="b79d0f985e8163f61bbd155baac0c7316c46ebb84b3385840936570ec6df32dd.jpg" src="../images/b79d0f985e8163f61bbd155baac0c7316c46ebb84b3385840936570ec6df32dd.jpg" /></p>
<ul>
<li>图表展示了在 4 核、16 核和 32 核系统上，<strong>Hawkeye</strong>、<strong>D-Hawkeye</strong>、<strong>Mockingjay</strong> 和 <strong>D-Mockingjay</strong> 四种 LLC 替换策略相对于 LRU 基线的性能提升，数据基于 70 种混合负载（35 个同构 + 35 个异构）。</li>
<li>性能指标分为两类：<strong>Maximum Weighted Speedup</strong>（最大加权加速比）和 <strong>Geomean Weighted Speedup</strong>（几何平均加权加速比），分别反映最优情况与整体平均水平。</li>
<li>所有策略在 32 核系统上的性能增益均高于 4 核和 16 核，表明 <strong>Drishti 的增强效果随核心数增加而放大</strong>。</li>
<li>在 32 核系统中，<strong>D-Mockingjay</strong> 达到最高性能，其 Maximum 加速比为 <strong>1.77</strong>，Geomean 加速比为 <strong>1.13</strong>，显著优于原始 Mockingjay（1.59 / 1.07）。</li>
<li>D-Hawkeye 在 32 核系统中的 Geomean 加速比为 <strong>1.06</strong>，略高于 Hawkeye 的 1.03，但提升幅度小于 D-Mockingjay。</li>
<li>数据表明，<strong>Drishti 对 Mockingjay 的优化效果远大于 Hawkeye</strong>，尤其在多核环境下，这与论文中提到的 Mockingjay 更依赖全局重用预测一致。</li>
<li>下表总结各策略在不同核心数下的性能表现：</li>
</ul>
<table>
<thead>
<tr>
<th>核心数</th>
<th>策略</th>
<th>Maximum 加速比</th>
<th>Geomean 加速比</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>Hawkeye</td>
<td>1.38</td>
<td>1.03</td>
</tr>
<tr>
<td></td>
<td>D-Hawkeye</td>
<td>1.63</td>
<td>1.04</td>
</tr>
<tr>
<td></td>
<td>Mockingjay</td>
<td>1.57</td>
<td>1.06</td>
</tr>
<tr>
<td></td>
<td>D-Mockingjay</td>
<td>1.72</td>
<td>1.07</td>
</tr>
<tr>
<td>16</td>
<td>Hawkeye</td>
<td>1.41</td>
<td>1.04</td>
</tr>
<tr>
<td></td>
<td>D-Hawkeye</td>
<td>1.55</td>
<td>1.06</td>
</tr>
<tr>
<td></td>
<td>Mockingjay</td>
<td>1.57</td>
<td>1.09</td>
</tr>
<tr>
<td></td>
<td>D-Mockingjay</td>
<td>1.76</td>
<td>1.12</td>
</tr>
<tr>
<td>32</td>
<td>Hawkeye</td>
<td>1.36</td>
<td>1.03</td>
</tr>
<tr>
<td></td>
<td>D-Hawkeye</td>
<td>1.54</td>
<td>1.06</td>
</tr>
<tr>
<td></td>
<td>Mockingjay</td>
<td>1.59</td>
<td>1.07</td>
</tr>
<tr>
<td></td>
<td>D-Mockingjay</td>
<td><strong>1.77</strong></td>
<td><strong>1.13</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>图表底部基准线为 1.0，代表 LRU 性能。所有柱状图均高于该线，说明所有策略均优于 LRU，且 <strong>Drishti 增强版本始终优于原始版本</strong>。</li>
<li>从趋势看，随着核心数增加，<strong>D-Mockingjay 的相对优势持续扩大</strong>，证明 Drishti 的 per-core global predictor 和 dynamic sampled cache 在大规模系统中更有效。</li>
</ul>
<h3 id="figure-14-miss-reduction-over-lru-on-4-16and-32-cores-averaged-across-70-35-homoand-35-hetero-mixes">Figure 14: Miss reduction over LRU on 4, 16,and 32 cores averaged across 70 (35 homo.and 35 hetero) mixes.<a class="headerlink" href="#figure-14-miss-reduction-over-lru-on-4-16and-32-cores-averaged-across-70-35-homoand-35-hetero-mixes" title="Permanent link">&para;</a></h3>
<p><img alt="527daac70fbfe02666795d1c681f8867659937496b5cbdbfd291b2a6afea3b6e.jpg" src="../images/527daac70fbfe02666795d1c681f8867659937496b5cbdbfd291b2a6afea3b6e.jpg" /></p>
<ul>
<li>图表展示了在 4、16 和 32 核系统上，<strong>Hawkeye</strong>、<strong>D-Hawkeye</strong>、<strong>Mockingjay</strong> 和 <strong>D-Mockingjay</strong> 四种替换策略相较于 <strong>LRU</strong> 基线的平均 <strong>MPKI（Misses Per Kilo Instructions）</strong> 减少百分比，数据基于 70 个混合负载（35 个同构 + 35 个异构）的平均值。</li>
<li><strong>Drishti 的增强效果随核心数增加而显著提升</strong>。在 4 核时，D-Hawkeye 相比 Hawkeye 仅小幅提升；但在 32 核时，D-Hawkeye 的 MPKI 减少幅度明显优于 Hawkeye，表明 Drishti 在多核场景下更有效。</li>
<li><strong>Mockingjay 系列整体优于 Hawkeye 系列</strong>。在所有核心数配置下，Mockingjay 和 D-Mockingjay 的 MPKI 减少百分比均高于 Hawkeye 和 D-Hawkeye，说明 Mockingjay 的多类预测机制在减少缓存缺失方面更具优势。</li>
<li><strong>D-Mockingjay 在 32 核系统中表现最佳</strong>，其 MPKI 减少幅度接近 24%，远超其他策略，体现了 Drishti 对 Mockingjay 的强化效果最为显著。</li>
<li>数据趋势显示，随着核心数从 4 增加到 32，<strong>所有策略的 MPKI 减少幅度均有所下降</strong>，这与多核系统中缓存竞争加剧、访问模式更分散有关，但 Drishti 通过全局预测和动态采样缓解了这一问题。</li>
</ul>
<table>
<thead>
<tr>
<th>核心数</th>
<th>Hawkeye (MPKI 减少 %)</th>
<th>D-Hawkeye (MPKI 减少 %)</th>
<th>Mockingjay (MPKI 减少 %)</th>
<th>D-Mockingjay (MPKI 减少 %)</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>~12.9%</td>
<td>~14.5%</td>
<td>~23.8%</td>
<td>~24.0%</td>
</tr>
<tr>
<td>16</td>
<td>~12.0%</td>
<td>~14.0%</td>
<td>~22.5%</td>
<td>~23.5%</td>
</tr>
<tr>
<td>32</td>
<td>~10.6%</td>
<td>~14.1%</td>
<td>~21.2%</td>
<td>~24.1%</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Drishti 的设计解决了 sliced LLC 中的两个关键问题</strong>：一是通过 per-core global predictor 缓解 myopic prediction，二是通过 dynamic sampled cache 提升采样集的有效性，从而在高并发多核环境中维持甚至提升缓存效率。</li>
<li>图表中的误差线或波动较小，表明实验结果具有较高一致性，不同混合负载对各策略的影响相对稳定，进一步验证了 Drishti 增强方案的鲁棒性。</li>
</ul>
<h3 id="4fc3cc59d033115cfb967016852255e92d32d57d6fecaf90af004fa36a09ab11jpg">4fc3cc59d033115cfb967016852255e92d32d57d6fecaf90af004fa36a09ab11.jpg<a class="headerlink" href="#4fc3cc59d033115cfb967016852255e92d32d57d6fecaf90af004fa36a09ab11jpg" title="Permanent link">&para;</a></h3>
<p><img alt="4fc3cc59d033115cfb967016852255e92d32d57d6fecaf90af004fa36a09ab11.jpg" src="../images/4fc3cc59d033115cfb967016852255e92d32d57d6fecaf90af004fa36a09ab11.jpg" /></p>
<ul>
<li>图片展示了四个用于评估多核系统性能与公平性的关键指标公式，它们分别是 <strong>Individual Slowdown (ISi)</strong>、<strong>Weighted Speedup (WS)</strong>、<strong>Harmonic Mean of Speedups (HS)</strong> 和 <strong>Unfairness</strong>。</li>
<li>这些公式基于两个核心变量：<code>IPC_together</code>（核心 i 在多程序负载下与其他 N-1 个应用共同运行时的指令每周期数）和 <code>IPC_alone</code>（核心 i 在独占 N 核系统时的指令每周期数）。</li>
<li><strong>Individual Slowdown (ISi)</strong> 的计算方式为 <code>IPC_together_i / IPC_alone_i</code>。该值大于 1 表示性能下降，小于 1 表示性能提升。</li>
<li><strong>Weighted Speedup (WS)</strong> 是所有核心 ISi 值的总和，即 <code>Σ (IPC_together_i / IPC_alone_i)</code>，从 i=0 到 N-1。它衡量的是整个系统的综合性能增益。</li>
<li><strong>Harmonic Mean of Speedups (HS)</strong> 的计算公式为 <code>N / Σ (IPC_alone_i / IPC_together_i)</code>，同样从 i=0 到 N-1。它更关注表现最差的核心，对系统整体公平性敏感。</li>
<li><strong>Unfairness</strong> 的定义是所有核心 ISi 值中的最大值除以最小值，即 <code>max{IS0, IS1, ..., ISN-1} / min{IS0, IS1, ..., ISN-1}</code>。该值越接近 1，表示系统调度越公平。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">指标名称</th>
<th style="text-align: left;">公式</th>
<th style="text-align: left;">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Individual Slowdown (ISi)</strong></td>
<td style="text-align: left;"><code>IPC_together_i / IPC_alone_i</code></td>
<td style="text-align: left;">核心 i 在共享环境下的性能损失或增益比例。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Weighted Speedup (WS)</strong></td>
<td style="text-align: left;"><code>Σ (IPC_together_i / IPC_alone_i)</code></td>
<td style="text-align: left;">系统所有核心性能增益的加权总和。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Harmonic Mean of Speedups (HS)</strong></td>
<td style="text-align: left;"><code>N / Σ (IPC_alone_i / IPC_together_i)</code></td>
<td style="text-align: left;">对系统中最慢核心敏感的平均性能指标。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Unfairness</strong></td>
<td style="text-align: left;"><code>max{IS0, ..., ISN-1} / min{IS0, ..., ISN-1}</code></td>
<td style="text-align: left;">衡量系统内各核心间性能差异的公平性指标。</td>
</tr>
</tbody>
</table>
<h3 id="cd4d55378946d91908ea2a26818da676288f5d965dbcd6898c86fe689bde961ajpg">cd4d55378946d91908ea2a26818da676288f5d965dbcd6898c86fe689bde961a.jpg<a class="headerlink" href="#cd4d55378946d91908ea2a26818da676288f5d965dbcd6898c86fe689bde961ajpg" title="Permanent link">&para;</a></h3>
<p><img alt="cd4d55378946d91908ea2a26818da676288f5d965dbcd6898c86fe689bde961a.jpg" src="../images/cd4d55378946d91908ea2a26818da676288f5d965dbcd6898c86fe689bde961a.jpg" /></p>
<ul>
<li>图片内容为一个数学公式，定义了“最大个体减速”（Maximum Individual Slowdown, <strong>MIS</strong>）的计算方法。</li>
<li>该公式表示 <strong>MIS</strong> 是所有核心个体减速（Individual Slowdown, <strong>IS</strong>）中的最大值。</li>
<li>公式具体形式为：<strong>MIS = MAX{IS₀, IS₁, ..., ISₙ₋₁}</strong>。</li>
<li>其中，<strong>ISᵢ</strong> 代表第 i 个核心的个体减速，N 代表系统中的总核心数。</li>
<li>此指标用于评估多核系统中性能最差的核心，是衡量系统公平性的重要参数。</li>
</ul>
<h3 id="table-5-average-llc-wpki-across-35-homogeneous-mixes-and-35-heterogeneous-mixes">Table 5: Average LLC WPKI across 35 homogeneous mixes and 35 heterogeneous mixes.<a class="headerlink" href="#table-5-average-llc-wpki-across-35-homogeneous-mixes-and-35-heterogeneous-mixes" title="Permanent link">&para;</a></h3>
<p><img alt="f32af35d17a6d03c5093b9b01ed6f418020bea00537e16bcc089a43c5e7673d1.jpg" src="../images/f32af35d17a6d03c5093b9b01ed6f418020bea00537e16bcc089a43c5e7673d1.jpg" /></p>
<ul>
<li>该图片为论文中的 <strong>Table 5</strong>，标题为“Average LLC WPKI across 35 homogeneous mixes and 35 heterogeneous mixes”，展示的是不同核心数下，各替换策略的 <strong>LLC Writebacks per Kilo Instruction (WPKI)</strong> 平均值。</li>
<li>表格数据按核心数（4、16、32）分组，列出了 <strong>LRU、Hawkeye、D-Hawkeye、Mockingjay、D-Mockingjay</strong> 五种策略的 WPKI 值。</li>
<li>数据显示，随着核心数增加，所有策略的 WPKI 值整体呈下降趋势，表明在多核环境下，写回压力有所缓解。</li>
<li><strong>Drishti 增强后的策略（D-Hawkeye 和 D-Mockingjay）</strong> 在所有核心数下，其 WPKI 值均高于未增强版本（Hawkeye 和 Mockingjay），说明 Drishti 的优化导致了更多的写回操作。</li>
<li>这一现象与文中解释一致：Hawkeye 和 Mockingjay 等策略倾向于将脏块（dirty lines）赋予最低优先级，从而加速其写回至 DRAM，而 Drishti 的增强进一步放大了这一行为。</li>
<li>具体数值如下：</li>
</ul>
<table>
<thead>
<tr>
<th>Cores</th>
<th>LRU</th>
<th>Hawkeye</th>
<th>D-Hawkeye</th>
<th>Mockingjay</th>
<th>D-Mockingjay</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>0.18</td>
<td>1.48</td>
<td>2.63</td>
<td>7.64</td>
<td>6.20</td>
</tr>
<tr>
<td>16</td>
<td>0.18</td>
<td>1.15</td>
<td>2.63</td>
<td>7.16</td>
<td>7.02</td>
</tr>
<tr>
<td>32</td>
<td>0.17</td>
<td>1.23</td>
<td>2.60</td>
<td>7.26</td>
<td>6.98</td>
</tr>
</tbody>
</table>
<ul>
<li>特别值得注意的是，在 <strong>4 核心</strong>场景下，<strong>D-Mockingjay 的 WPKI (6.20) 显著低于 Mockingjay (7.64)</strong>，这与其他核心数下的趋势相反，可能反映了在低并行度下 Drishti 的动态采样或全局预测机制对写回行为产生了不同的影响。</li>
<li>总体而言，该表佐证了 Drishti 在提升性能的同时，也带来了写回开销的增加，这是设计权衡的一部分。</li>
</ul>
<h3 id="figure-15-uncore-llc-noc-and-dram-energy-consumption-normalized-to-lru-across-70-mixes-lower-the-better">Figure 15: Uncore (LLC, NOC, and DRAM) energy consumption normalized to LRU across 70 mixes (lower the better).<a class="headerlink" href="#figure-15-uncore-llc-noc-and-dram-energy-consumption-normalized-to-lru-across-70-mixes-lower-the-better" title="Permanent link">&para;</a></h3>
<p><img alt="fae276d619eccea953f463e54a87a8b0409f564c79c921d160f41190e6b8478a.jpg" src="../images/fae276d619eccea953f463e54a87a8b0409f564c79c921d160f41190e6b8478a.jpg" /></p>
<ul>
<li>图片展示了在 16 核与 32 核系统下，不同 LLC 替换策略对 <strong>Uncore</strong>（包含 LLC、NOC 和 DRAM）动态能耗的归一化影响，基准为 LRU。</li>
<li>所有数据基于 70 个混合工作负载（35 个同构 + 35 个异构），数值越低代表能效越好。</li>
<li>能耗被分解为两个部分：<strong>DRAM</strong>（白色区域）和 <strong>LLC+NOC</strong>（斜线/深色区域），便于分析各组件贡献。</li>
</ul>
<table>
<thead>
<tr>
<th>策略</th>
<th>16 核总能耗</th>
<th>32 核总能耗</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hawkeye</td>
<td>0.96</td>
<td>0.98</td>
</tr>
<tr>
<td>D-Hawkeye</td>
<td>0.95</td>
<td>0.97</td>
</tr>
<tr>
<td>Mockingjay</td>
<td>0.93</td>
<td>0.95</td>
</tr>
<tr>
<td>D-Mockingjay</td>
<td>0.92</td>
<td>0.91</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Drishti 增强显著降低能耗</strong>：无论核数多少，D-Mockingjay 均实现最低能耗，表明其在减少 LLC 冗余访问和优化数据流方面效果突出。</li>
<li>在 32 核系统中，D-Mockingjay 的能耗比 Mockingjay 降低 4%，且低于所有其他策略，体现其在大规模系统中的可扩展性优势。</li>
<li><strong>DRAM 能耗占比稳定</strong>：各策略下 DRAM 部分能耗变化较小，主要节能来自 LLC+NOC 子系统，说明 Drishti 通过更精准的替换决策减少了无效缓存操作和跨片通信。</li>
<li><strong>NOCSTAR 互连未引入额外能耗负担</strong>：尽管 D-Hawkeye 和 D-Mockingjay 引入了 per-core 全局预测器及 NOCSTAR 互连，但整体能耗仍优于原策略，证明其设计轻量高效。</li>
</ul>
<h3 id="table-6-drishti-on-a-32-core-system-with-64mb-llc-across-35-homogeneous-and-35-heterogeneous-mixes">Table 6: Drishti on a 32-core system with 64MB LLC across 35 homogeneous and 35 heterogeneous mixes.<a class="headerlink" href="#table-6-drishti-on-a-32-core-system-with-64mb-llc-across-35-homogeneous-and-35-heterogeneous-mixes" title="Permanent link">&para;</a></h3>
<p><img alt="23ed1a267c0a5ec704327349374800fd79454dca25b49896cf3d3a241816630f.jpg" src="../images/23ed1a267c0a5ec704327349374800fd79454dca25b49896cf3d3a241816630f.jpg" /></p>
<ul>
<li>该表格（Table 6）展示了在 <strong>32-core 系统</strong>、<strong>64MB LLC</strong> 配置下，Drishti 增强对 <strong>Hawkeye</strong> 和 <strong>Mockingjay</strong> 两种替换策略的性能影响，评估基于 <strong>35 个同构混合负载</strong> 和 <strong>35 个异构混合负载</strong>。</li>
<li>表格包含四个关键性能与公平性指标：<strong>加权速度提升 (WS%)</strong>、<strong>调和平均速度提升 (HS%)</strong>、<strong>不公平性 (Unfairness)</strong> 和 <strong>最大个体减速 (MIS%)</strong>。</li>
<li>数据表明，Drishti 的增强显著提升了性能，尤其在 <strong>Mockingjay</strong> 上效果更为突出。</li>
</ul>
<table>
<thead>
<tr>
<th>Metrics</th>
<th>Hawkeye</th>
<th>D-Hawkeye</th>
<th>Mockingjay</th>
<th>D-Mockingjay</th>
</tr>
</thead>
<tbody>
<tr>
<td>WS(%)</td>
<td>3.3</td>
<td><strong>5.6</strong></td>
<td>6.7</td>
<td><strong>13.3</strong></td>
</tr>
<tr>
<td>HS(%)</td>
<td>3.4</td>
<td><strong>5.0</strong></td>
<td>4.5</td>
<td><strong>12.8</strong></td>
</tr>
<tr>
<td>Unfairness</td>
<td>1.2</td>
<td>1.2</td>
<td>1.30</td>
<td>1.28</td>
</tr>
<tr>
<td>MIS(%)</td>
<td>41.4</td>
<td>40.0</td>
<td>37.0</td>
<td><strong>34.2</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>加权速度提升 (WS%)</strong>：D-Hawkeye 较 Hawkeye 提升 <strong>2.3%</strong>，D-Mockingjay 较 Mockingjay 提升 <strong>6.6%</strong>，显示 Drishti 对 Mockingjay 的增益更大。</li>
<li><strong>调和平均速度提升 (HS%)</strong>：D-Hawkeye 达到 <strong>5.0%</strong>，D-Mockingjay 达到 <strong>12.8%</strong>，进一步验证了 Drishti 在多核系统中对整体吞吐量的优化能力。</li>
<li><strong>不公平性 (Unfairness)</strong>：Drishti 增强后，各策略的不公平性指标基本保持稳定，说明其改进未牺牲核心间的公平性。</li>
<li><strong>最大个体减速 (MIS%)</strong>：D-Mockingjay 将 MIS 从 37% 降至 <strong>34.2%</strong>，表明 Drishti 能有效缓解最差情况下的性能退化，提升系统鲁棒性。</li>
</ul>
<h3 id="figure-16-performance-of-mockingjay-and-d-mockingjay-on-32-core-systems-across-70-mixesthe-mixes-are-shown-in-sorted-order-as-per-performance-improvement-and-their-indices-do-not-correspond-to-those-in-figure-2">Figure 16: Performance of Mockingjay and D-Mockingjay on 32-core systems across 70 mixes.The mixes are shown in sorted order (as per performance improvement), and their indices do not correspond to those in Figure 2.<a class="headerlink" href="#figure-16-performance-of-mockingjay-and-d-mockingjay-on-32-core-systems-across-70-mixesthe-mixes-are-shown-in-sorted-order-as-per-performance-improvement-and-their-indices-do-not-correspond-to-those-in-figure-2" title="Permanent link">&para;</a></h3>
<p><img alt="47b377e6a53c0b116dce760fee11bfb83ff0645be7afdc957aa88b5097abf4b3.jpg" src="../images/47b377e6a53c0b116dce760fee11bfb83ff0645be7afdc957aa88b5097abf4b3.jpg" /></p>
<ul>
<li>图表展示了在 <strong>32-core</strong> 系统上，<strong>Mockingjay</strong> 与 <strong>D-Mockingjay</strong> 在 <strong>70个 workload mixes</strong> 上的性能对比，纵轴为 <strong>Normalized Weighted Speedup</strong>，横轴为按性能提升排序的混合工作负载索引。</li>
<li><strong>D-Mockingjay</strong>（橙色圆点）在绝大多数工作负载中表现优于 <strong>Mockingjay</strong>（蓝色叉号），尤其在高索引（即性能提升显著的工作负载）区域，优势更为明显。</li>
<li>关键工作负载标注：<ul>
<li><strong>lbm</strong>：位于左下角，两者性能接近，均略低于基准线（1.0），表明该工作负载对两种策略均不友好。</li>
<li><strong>cc</strong>：位于中间偏左，D-Mockingjay 开始显著超越 Mockingjay。</li>
<li><strong>xalancbmk</strong>：位于中右部，D-Mockingjay 性能提升明显，达到约 1.2 倍。</li>
<li><strong>mcf</strong>：位于最右侧，D-Mockingjay 达到最高性能，约为 <strong>1.8倍</strong>，而 Mockingjay 约为 1.5 倍，显示 D-Mockingjay 对 mcf 工作负载优化效果极佳。</li>
</ul>
</li>
<li>数据趋势表明，随着工作负载复杂度或缓存压力增加（索引增大），<strong>Drishti 的增强机制</strong>（全局预测器 + 动态采样缓存）带来的性能增益越显著。</li>
<li>下表总结关键点：</li>
</ul>
<table>
<thead>
<tr>
<th>工作负载</th>
<th>Mockingjay (Speedup)</th>
<th>D-Mockingjay (Speedup)</th>
<th>提升幅度</th>
</tr>
</thead>
<tbody>
<tr>
<td>lbm</td>
<td>~0.95</td>
<td>~0.96</td>
<td>微小</td>
</tr>
<tr>
<td>cc</td>
<td>~1.05</td>
<td>~1.10</td>
<td>中等</td>
</tr>
<tr>
<td>xalancbmk</td>
<td>~1.20</td>
<td>~1.25</td>
<td>明显</td>
</tr>
<tr>
<td>mcf</td>
<td>~1.50</td>
<td><strong>~1.80</strong></td>
<td><strong>极大</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>整体来看，<strong>D-Mockingjay</strong> 在所有 70 个混合负载中均未劣于 Mockingjay，且在多数负载中实现正向加速，验证了 Drishti 设计的有效性。</li>
</ul>
<h3 id="figure-17-performance-normalized-to-lru-with-only-global-view-and-d-mockingjay-with-global-view-dsc-across-32-core-35-homogeneous-and-heterogeneous-mixes">Figure 17: Performance normalized to LRU with only global view and D-Mockingjay with global view &amp; DSC across 32- core 35 homogeneous and heterogeneous mixes.<a class="headerlink" href="#figure-17-performance-normalized-to-lru-with-only-global-view-and-d-mockingjay-with-global-view-dsc-across-32-core-35-homogeneous-and-heterogeneous-mixes" title="Permanent link">&para;</a></h3>
<p><img alt="f8b9146e4f1637b229a891f779a6cb1cd903d99fa37ee56335c33f6123e9c3b2.jpg" src="../images/f8b9146e4f1637b229a891f779a6cb1cd903d99fa37ee56335c33f6123e9c3b2.jpg" /></p>
<ul>
<li>图片展示了在32核系统上，<strong>D-Mockingjay</strong>相对于基准LRU的性能提升，通过归一化加权加速比（Normalized Weighted Speedup）进行衡量，并对比了不同增强方案的效果。</li>
<li>该图将工作负载分为四组：SPEC CPU2017同构混合、GAP同构混合、所有同构混合、所有异构混合，每组内比较三种策略：<ul>
<li><strong>Mockingjay</strong>（原始策略）</li>
<li><strong>D-Mockingjay with global view</strong>（仅启用全局视图预测器）</li>
<li><strong>D-Mockingjay with global view &amp; DSC</strong>（同时启用全局视图预测器和动态采样缓存）</li>
</ul>
</li>
<li>数据表明，<strong>D-Mockingjay with global view &amp; DSC</strong>在所有工作负载类别中均取得最高性能，证明两项增强协同作用显著。</li>
<li>从数据趋势看，随着工作负载复杂度增加（从SPEC到GAP再到所有混合），Drishti增强带来的收益更明显，尤其在异构混合负载下，性能提升接近<strong>1.17x</strong>。</li>
</ul>
<table>
<thead>
<tr>
<th>工作负载类别</th>
<th>Mockingjay</th>
<th>D-Mockingjay (global view)</th>
<th>D-Mockingjay (global view &amp; DSC)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Geomean (SPEC CPU2017)</td>
<td>~1.04</td>
<td>~1.08</td>
<td>~1.11</td>
</tr>
<tr>
<td>Geomean (GAP)</td>
<td>~1.06</td>
<td>~1.09</td>
<td>~1.10</td>
</tr>
<tr>
<td>Geomean (All Homo Mixes)</td>
<td>~1.05</td>
<td>~1.08</td>
<td>~1.10</td>
</tr>
<tr>
<td>Geomean (All Hetero Mixes)</td>
<td>~1.10</td>
<td>~1.15</td>
<td><strong>~1.17</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>关键结论</strong>：全局视图预测器是性能提升的主要驱动力，而动态采样缓存（DSC）进一步优化了采样集选择，尤其在高并发、高变化的工作负载中效果更佳。</li>
</ul>
<h3 id="figure-18-etr-values-with-drishti-in-mockingjay-for-xalan-running-on-a-16-core-system">Figure 18: ETR values with Drishti in Mockingjay for xalan running on a 16-core system.<a class="headerlink" href="#figure-18-etr-values-with-drishti-in-mockingjay-for-xalan-running-on-a-16-core-system" title="Permanent link">&para;</a></h3>
<p><img alt="1bb183ed13c6a1f3ef34d7ea5f436dc1c850e22e0a93c1bb5e1d839489f09399.jpg" src="../images/1bb183ed13c6a1f3ef34d7ea5f436dc1c850e22e0a93c1bb5e1d839489f09399.jpg" /></p>
<ul>
<li>图片展示了在 16 核系统上运行 xalan 工作负载时，Mockingjay 策略在不同视图下预测的 <strong>ETR (Estimated Time Remaining)</strong> 值的频率分布。</li>
<li>横轴代表三种不同的预测视图：<strong>Global view</strong>、<strong>Myopic view</strong> 和 <strong>Drishti's view</strong>。</li>
<li>纵轴表示 ETR 值的频率百分比，范围从 0% 到 100%。</li>
<li>ETR 值被划分为三个区间：<strong>0-31</strong>（深灰色）、<strong>32-63</strong>（浅灰色）和 <strong>64-128</strong>（中灰色），每个柱状图由这三个区间的堆叠组成。</li>
<li>在 <strong>Global view</strong> 下，约 50% 的 ETR 值落在 0-31 区间，其余 50% 落在 32-63 区间，64-128 区间无数据。</li>
<li>在 <strong>Myopic view</strong> 下，约 10% 的 ETR 值落在 0-31 区间，约 70% 落在 32-63 区间，约 20% 落在 64-128 区间。</li>
<li>在 <strong>Drishti's view</strong> 下，约 45% 的 ETR 值落在 0-31 区间，约 50% 落在 32-63 区间，约 5% 落在 64-128 区间。</li>
<li>对比显示，<strong>Drishti's view</strong> 的 ETR 分布更接近 <strong>Global view</strong>，表明 Drishti 的增强设计有效缓解了 Myopic view 带来的预测偏差。</li>
<li>数据总结如下表：</li>
</ul>
<table>
<thead>
<tr>
<th>视图</th>
<th>ETR 0-31 (%)</th>
<th>ETR 32-63 (%)</th>
<th>ETR 64-128 (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Global view</td>
<td>~50</td>
<td>~50</td>
<td>0</td>
</tr>
<tr>
<td>Myopic view</td>
<td>~10</td>
<td>~70</td>
<td>~20</td>
</tr>
<tr>
<td>Drishti's view</td>
<td>~45</td>
<td>~50</td>
<td>~5</td>
</tr>
</tbody>
</table>
<ul>
<li>结论：Drishti 通过其全局感知的预测机制，显著提升了 Mockingjay 在多核切片 LLC 环境下的 ETR 预测准确性，使其更贴近理想全局视图。</li>
</ul>
<h3 id="figure-19-performance-of-hawkeye-d-hawkeye-mockingjayd-mockingjay-on-50-16-core-and-50-32-core-mixes-created-from-cvp1-46google-datacenter-traces-1551cloudsuite-4and-xsbench-14">Figure 19: Performance of Hawkeye, D-Hawkeye, Mockingjay,D-Mockingjay on 50 16-core and 50 32-core mixes created from CVP1 [46],Google datacenter traces [15,51],CloudSuite [4],and XSBench [14].<a class="headerlink" href="#figure-19-performance-of-hawkeye-d-hawkeye-mockingjayd-mockingjay-on-50-16-core-and-50-32-core-mixes-created-from-cvp1-46google-datacenter-traces-1551cloudsuite-4and-xsbench-14" title="Permanent link">&para;</a></h3>
<p><img alt="7f32c64e141446660c4bf7c1a0d4fbf29508d8c99a82d52b932d3fb8e63c8d67.jpg" src="../images/7f32c64e141446660c4bf7c1a0d4fbf29508d8c99a82d52b932d3fb8e63c8d67.jpg" /></p>
<ul>
<li>图表展示了在<strong>16核</strong>和<strong>32核</strong>系统上，四种替换策略（Hawkeye、D-Hawkeye、Mockingjay、D-Mockingjay）的<strong>归一化加权加速比</strong>性能对比，基准为LRU。</li>
<li>数据集来源于CVP1、Google数据中心、CloudSuite和XSBench等真实工作负载，共构建了50组16核混合与50组32核混合。</li>
<li><strong>16核系统</strong>：<ul>
<li>Hawkeye性能提升约<strong>2%</strong>。</li>
<li>D-Hawkeye进一步提升至约<strong>3.5%</strong>。</li>
<li>Mockingjay性能提升约<strong>4%</strong>。</li>
<li>D-Mockingjay达到约<strong>5.5%</strong>。</li>
</ul>
</li>
<li><strong>32核系统</strong>：<ul>
<li>Hawkeye性能提升约<strong>3%</strong>。</li>
<li>D-Hawkeye提升至约<strong>5%</strong>。</li>
<li>Mockingjay性能提升约<strong>5%</strong>。</li>
<li>D-Mockingjay显著提升至约<strong>7%</strong>。</li>
</ul>
</li>
<li>性能增益趋势表明，随着核心数增加，<strong>Drishti增强</strong>（D-前缀）带来的收益更明显，尤其在<strong>32核</strong>场景下，D-Mockingjay表现最优。</li>
<li>对比可见，<strong>D-Mockingjay</strong>在两种核心规模下均优于其他策略，验证了Drishti对复杂真实负载的有效性。</li>
</ul>
<table>
<thead>
<tr>
<th>核心数</th>
<th>策略</th>
<th>归一化加权加速比</th>
</tr>
</thead>
<tbody>
<tr>
<td>16核</td>
<td>Hawkeye</td>
<td>~1.02</td>
</tr>
<tr>
<td></td>
<td>D-Hawkeye</td>
<td>~1.035</td>
</tr>
<tr>
<td></td>
<td>Mockingjay</td>
<td>~1.04</td>
</tr>
<tr>
<td></td>
<td>D-Mockingjay</td>
<td>~1.055</td>
</tr>
<tr>
<td>32核</td>
<td>Hawkeye</td>
<td>~1.03</td>
</tr>
<tr>
<td></td>
<td>D-Hawkeye</td>
<td>~1.05</td>
</tr>
<tr>
<td></td>
<td>Mockingjay</td>
<td>~1.05</td>
</tr>
<tr>
<td></td>
<td>D-Mockingjay</td>
<td>~1.07</td>
</tr>
</tbody>
</table>
<h3 id="figure-20-performance-normalized-to-lru-on-a-16-core-system-with-different-sizes-of-sliced-llc">Figure 20: Performance normalized to LRU on a 16-core system with different sizes of sliced LLC.<a class="headerlink" href="#figure-20-performance-normalized-to-lru-on-a-16-core-system-with-different-sizes-of-sliced-llc" title="Permanent link">&para;</a></h3>
<p><img alt="7975a4fe3fa2eaf8c7758a1976cedcddfcd245653cd21c2baa1315d14a90d8c4.jpg" src="../images/7975a4fe3fa2eaf8c7758a1976cedcddfcd245653cd21c2baa1315d14a90d8c4.jpg" /></p>
<ul>
<li>图片展示了在 <strong>16核系统</strong> 上，不同大小的 <strong>切片式LLC (Sliced LLC)</strong> 对 <strong>Hawkeye、D-Hawkeye、Mockingjay、D-Mockingjay</strong> 四种替换策略性能的影响，性能以 <strong>归一化加权加速比 (Normalized Weighted Speedup)</strong> 衡量，并与 <strong>LRU</strong> 基线对比。</li>
<li>性能趋势显示，<strong>Drishti增强</strong>（即 D-Hawkeye 和 D-Mockingjay）在所有LLC尺寸下均优于其基础版本（Hawkeye 和 Mockingjay），证实了其有效性不依赖于特定的LLC容量。</li>
<li>具体数据如下表所示：</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">LLC Size per Core</th>
<th style="text-align: left;">Hawkeye</th>
<th style="text-align: left;">D-Hawkeye</th>
<th style="text-align: left;">Mockingjay</th>
<th style="text-align: left;">D-Mockingjay</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">1MB</td>
<td style="text-align: left;">~1.035</td>
<td style="text-align: left;">~1.04</td>
<td style="text-align: left;">~1.03</td>
<td style="text-align: left;">~1.055</td>
</tr>
<tr>
<td style="text-align: left;">2MB</td>
<td style="text-align: left;">~1.03</td>
<td style="text-align: left;">~1.05</td>
<td style="text-align: left;">~1.04</td>
<td style="text-align: left;">~1.095</td>
</tr>
<tr>
<td style="text-align: left;">4MB</td>
<td style="text-align: left;">~1.03</td>
<td style="text-align: left;">~1.04</td>
<td style="text-align: left;">~1.05</td>
<td style="text-align: left;">~1.09</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>关键观察</strong>：<ul>
<li>在 <strong>2MB/core</strong> 配置下，<strong>D-Mockingjay</strong> 的性能提升最为显著，达到约 <strong>1.095</strong>，远超其他组合。</li>
<li><strong>Drishti</strong> 的增益在 <strong>2MB/core</strong> 时表现最佳，这与论文中提到的“2MB是最佳平衡点”相符，因为1MB需求样本集更少，而4MB则需要更多样本集来训练，导致效率下降。</li>
<li>尽管LLC尺寸变化，<strong>Drishti</strong> 增强始终带来正向收益，表明其设计对不同缓存容量具有良好的适应性。</li>
</ul>
</li>
</ul>
<h3 id="figure-21-performance-normalized-to-lru-on-a-16-core-system-with-different-sizes-of-l2">Figure 21: Performance normalized to LRU on a 16-core system with different sizes of L2.<a class="headerlink" href="#figure-21-performance-normalized-to-lru-on-a-16-core-system-with-different-sizes-of-l2" title="Permanent link">&para;</a></h3>
<p><img alt="88946bdb5abea1d8f0c560b12d81f0864c265fcfd42fb81400317c8ce103a59a.jpg" src="../images/88946bdb5abea1d8f0c560b12d81f0864c265fcfd42fb81400317c8ce103a59a.jpg" /></p>
<ul>
<li>图片展示了在 <strong>16核系统</strong> 上，不同 <strong>L2缓存大小</strong>（512KB、1MB、2MB）对四种替换策略性能的影响，性能以相对于 <strong>LRU</strong> 的归一化加权加速比（Normalized Weighted Speedup）衡量。</li>
<li>图中包含四组柱状图，分别对应：<ul>
<li><strong>Hawkeye</strong></li>
<li><strong>D-Hawkeye</strong>（Drishti增强版Hawkeye）</li>
<li><strong>Mockingjay</strong></li>
<li><strong>D-Mockingjay</strong>（Drishti增强版Mockingjay）</li>
</ul>
</li>
<li>性能趋势显示，随着 <strong>L2缓存增大</strong>，所有策略的性能提升幅度均有所下降。这是因为更大的L2缓存使更多工作集驻留在L2，导致LLC的访问压力和MPKI降低，从而削弱了LLC替换策略的优化空间。</li>
<li>在 <strong>512KB L2</strong> 条件下，<strong>D-Mockingjay</strong> 表现最佳，归一化加速比接近 <strong>1.12</strong>，显著优于其他策略。</li>
<li>当L2增大至 <strong>2MB</strong> 时，所有策略的加速比均趋近于 <strong>1.0</strong>，表明此时LLC替换策略的边际效益已非常有限。</li>
<li><strong>Drishti增强</strong> 在所有L2配置下均带来性能增益，但其相对优势随L2增大而减弱。例如，在512KB L2时，D-Mockingjay比Mockingjay高出约0.03；而在2MB L2时，差距缩小至约0.01。</li>
</ul>
<table>
<thead>
<tr>
<th>L2 Size</th>
<th>Hawkeye</th>
<th>D-Hawkeye</th>
<th>Mockingjay</th>
<th>D-Mockingjay</th>
</tr>
</thead>
<tbody>
<tr>
<td>512KB</td>
<td>~1.04</td>
<td>~1.06</td>
<td>~1.09</td>
<td><strong>~1.12</strong></td>
</tr>
<tr>
<td>1MB</td>
<td>~1.03</td>
<td>~1.05</td>
<td>~1.08</td>
<td><strong>~1.10</strong></td>
</tr>
<tr>
<td>2MB</td>
<td>~1.02</td>
<td>~1.03</td>
<td>~1.04</td>
<td><strong>~1.05</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>结论：<strong>Drishti增强</strong> 在L2较小、LLC压力较大的场景下效果最显著，能有效提升LLC替换策略的性能；当L2足够大时，其收益趋于饱和。</li>
</ul>
<h3 id="figure-22-performance-normalized-to-lru-on-a-16-core-system-with-different-dramchannels">Figure 22: Performance normalized to LRU on a 16-core system with different DRAMchannels.<a class="headerlink" href="#figure-22-performance-normalized-to-lru-on-a-16-core-system-with-different-dramchannels" title="Permanent link">&para;</a></h3>
<p><img alt="6ca70d961d4ca4cbf7a02433928d57ccabb97cd3efa78313c89e1ff3a83670a7.jpg" src="../images/6ca70d961d4ca4cbf7a02433928d57ccabb97cd3efa78313c89e1ff3a83670a7.jpg" /></p>
<ul>
<li>图表展示了在 <strong>16核系统</strong> 上，不同 <strong>DRAM通道数</strong>（2、4、8）对四种替换策略（Hawkeye、D-Hawkeye、Mockingjay、D-Mockingjay）性能的影响，性能以 <strong>Normalized Weighted Speedup</strong> 相对于 <strong>LRU</strong> 为基准。</li>
<li>所有策略的性能均随 DRAM 通道数增加而下降，表明 <strong>LLC miss latency 降低</strong> 会削弱替换策略的优化空间。</li>
<li>在 <strong>2通道</strong> 配置下，<strong>D-Mockingjay</strong> 表现最佳，速度提升达 <strong>1.09x</strong>，显著优于基础 Mockingjay（约 1.05x）和 D-Hawkeye（约 1.06x）。</li>
<li>当通道数增至 <strong>4通道</strong>，各策略性能差距缩小，<strong>D-Mockingjay</strong> 仍保持领先（约 1.08x），但优势幅度收窄。</li>
<li>在 <strong>8通道</strong> 配置下，所有策略性能趋近于 LRU 基线（1.00x），其中 <strong>D-Mockingjay</strong> 略高于 1.07x，显示其在高带宽场景下仍具一定优化能力。</li>
<li>数据表明，<strong>Drishti 增强</strong>（D-前缀）在低带宽场景（如2通道）下效果最显著，可带来高达 <strong>9%</strong> 的性能增益；而在高带宽场景中，其边际效益递减。</li>
</ul>
<table>
<thead>
<tr>
<th>DRAM Channels</th>
<th>Hawkeye</th>
<th>D-Hawkeye</th>
<th>Mockingjay</th>
<th>D-Mockingjay</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>~1.03x</td>
<td>~1.06x</td>
<td>~1.05x</td>
<td><strong>~1.09x</strong></td>
</tr>
<tr>
<td>4</td>
<td>~1.03x</td>
<td>~1.06x</td>
<td>~1.05x</td>
<td><strong>~1.08x</strong></td>
</tr>
<tr>
<td>8</td>
<td>~1.03x</td>
<td>~1.04x</td>
<td>~1.04x</td>
<td><strong>~1.07x</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>结论：<strong>Drishti</strong> 在 <strong>DRAM带宽受限</strong> 的系统中能最大化其价值，尤其在 <strong>低通道数</strong> 下对 <strong>Mockingjay</strong> 的增强效果最为突出。</li>
</ul>
<h3 id="figure-23-performance-normalized-to-lru-with-different-hardware-prefetchers-averaged-across-16-and-32-core-mixes">Figure 23: Performance normalized to LRU with different hardware prefetchers averaged across 16 and 32-core mixes.<a class="headerlink" href="#figure-23-performance-normalized-to-lru-with-different-hardware-prefetchers-averaged-across-16-and-32-core-mixes" title="Permanent link">&para;</a></h3>
<p><img alt="375eaa1dc229574e6c44a3f0688fb81f0d6f58d721e5808ea4dba5afec4579dc.jpg" src="../images/375eaa1dc229574e6c44a3f0688fb81f0d6f58d721e5808ea4dba5afec4579dc.jpg" /></p>
<ul>
<li>图片展示了在不同硬件预取器（Hardware Prefetchers）下，<strong>Hawkeye</strong>、<strong>D-Hawkeye</strong>、<strong>Mockingjay</strong> 和 <strong>D-Mockingjay</strong> 四种替换策略相对于 <strong>LRU</strong> 基线的归一化加权加速比（Normalized Weighted Speedup），数据平均自16核与32核混合负载。</li>
<li>图表分为两组：左侧为 <strong>16核系统</strong>，右侧为 <strong>32核系统</strong>，每组内包含五种预取器：<strong>IPCP</strong>、<strong>SPP+PPF</strong>、<strong>Bingo</strong>、<strong>Berti</strong>、<strong>Gaze</strong>。</li>
<li>所有策略在所有预取器配置下均优于 LRU（基准值 1.00），且 <strong>D-Mockingjay</strong> 在绝大多数情况下表现最佳，其加速比最高可达 <strong>1.12</strong>。</li>
<li><strong>Drishti 增强</strong>（即 D-前缀策略）在两种核心数配置下均显著提升性能，尤其在 <strong>32核系统</strong> 中效果更明显，表明其对高并发场景的适应性更强。</li>
<li>预取器精度影响基线性能：如 <strong>SPP+PPF</strong> 和 <strong>Berti</strong> 等高精度预取器使 LRU 基线性能提升，从而压缩了替换策略的相对增益空间；而 <strong>IPCP</strong> 和 <strong>Gaze</strong> 等预取器下，Drishti 的增益更为突出。</li>
<li>下表总结各策略在不同预取器下的平均加速比（近似值）：</li>
</ul>
<table>
<thead>
<tr>
<th>预取器</th>
<th>16核 Hawkeye</th>
<th>16核 D-Hawkeye</th>
<th>16核 Mockingjay</th>
<th>16核 D-Mockingjay</th>
<th>32核 Hawkeye</th>
<th>32核 D-Hawkeye</th>
<th>32核 Mockingjay</th>
<th>32核 D-Mockingjay</th>
</tr>
</thead>
<tbody>
<tr>
<td>IPCP</td>
<td>~1.03</td>
<td>~1.05</td>
<td>~1.07</td>
<td>~1.10</td>
<td>~1.03</td>
<td>~1.05</td>
<td>~1.08</td>
<td>~1.11</td>
</tr>
<tr>
<td>SPP+PPF</td>
<td>~1.03</td>
<td>~1.04</td>
<td>~1.09</td>
<td>~1.11</td>
<td>~1.03</td>
<td>~1.04</td>
<td>~1.09</td>
<td>~1.11</td>
</tr>
<tr>
<td>Bingo</td>
<td>~1.03</td>
<td>~1.05</td>
<td>~1.08</td>
<td>~1.10</td>
<td>~1.03</td>
<td>~1.05</td>
<td>~1.09</td>
<td>~1.11</td>
</tr>
<tr>
<td>Berti</td>
<td>~1.03</td>
<td>~1.05</td>
<td>~1.08</td>
<td>~1.10</td>
<td>~1.03</td>
<td>~1.05</td>
<td>~1.09</td>
<td>~1.11</td>
</tr>
<tr>
<td>Gaze</td>
<td>~1.03</td>
<td>~1.05</td>
<td>~1.08</td>
<td>~1.10</td>
<td>~1.03</td>
<td>~1.05</td>
<td>~1.09</td>
<td>~1.11</td>
</tr>
</tbody>
</table>
<ul>
<li>结论：<strong>Drishti 增强</strong>与各类硬件预取器协同工作良好，尤其在复杂预取环境下仍能保持显著性能优势，验证了其设计的鲁棒性与可扩展性。</li>
</ul>
<h3 id="489b4a8ebaba549f37e1b5dbbc679e569672d623ed1ce784b351a74e45f3bba0jpg">489b4a8ebaba549f37e1b5dbbc679e569672d623ed1ce784b351a74e45f3bba0.jpg<a class="headerlink" href="#489b4a8ebaba549f37e1b5dbbc679e569672d623ed1ce784b351a74e45f3bba0jpg" title="Permanent link">&para;</a></h3>
<p><img alt="489b4a8ebaba549f37e1b5dbbc679e569672d623ed1ce784b351a74e45f3bba0.jpg" src="../images/489b4a8ebaba549f37e1b5dbbc679e569672d623ed1ce784b351a74e45f3bba0.jpg" /></p>
<ul>
<li>该图片展示了一张表格，总结了 <strong>Drishti</strong> 增强方案对不同类别缓存替换策略的适用性。</li>
<li>表格按策略类型分为两大类：<strong>Memoryless Policies</strong> 和 <strong>Prediction-based Policies</strong>。</li>
<li>每类策略下进一步列出具体政策名称，并标注其是否支持 <strong>Per-core yet Global Predictor</strong> 和 <strong>Dynamic Sampled Cache</strong> 两项 Drishti 核心增强。</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>替换策略</th>
<th>Per-core yet Global Predictor</th>
<th>Dynamic Sampled Cache</th>
</tr>
</thead>
<tbody>
<tr>
<td>Memoryless Policies</td>
<td>DIP, RRIP, IPVs</td>
<td>×</td>
<td>✓</td>
</tr>
<tr>
<td>Prediction-based Policies</td>
<td>SDBP, SHiP, SHiP++, Leeway, Glider, MPPPB, Perceptron learning, MDPP, CARE, CHROME</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>Prediction-based Policies</td>
<td>EVA</td>
<td>×</td>
<td>×</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Memoryless Policies</strong> 如 DIP、RRIP、IPVs 通常依赖 set-dueling 机制，但随机选择采样集易导致次优决策。Drishti 的 <strong>Dynamic Sampled Cache</strong> 可提升其有效性，但无需全局预测器。</li>
<li><strong>Prediction-based Policies</strong> 多数使用采样缓存和重用预测器，如 SDBP、SHiP++、CHROME 等，均能从 Drishti 的两项增强中受益。</li>
<li><strong>EVA</strong> 是例外，它基于缓存命中分布优先级，不依赖 PC 或采样集，因此 <strong>两项增强均不适用</strong>。</li>
<li>该表清晰表明，Drishti 的设计具有广泛适用性，尤其对依赖 PC 和采样集的预测型策略效果显著。</li>
</ul>
<h3 id="table-8-drishti-with-shipchromeand-glider-policies-for16-core-systems">Table 8: Drishti with SHiP++,CHROME,and Glider policies for16-core systems.<a class="headerlink" href="#table-8-drishti-with-shipchromeand-glider-policies-for16-core-systems" title="Permanent link">&para;</a></h3>
<p><img alt="cbcbab900ed57e9658ee3e6baf09e600b43ad55b1d064f3a260216e683da4bd2.jpg" src="../images/cbcbab900ed57e9658ee3e6baf09e600b43ad55b1d064f3a260216e683da4bd2.jpg" /></p>
<ul>
<li>该图片为论文中的 <strong>Table 8</strong>，标题为 “Drishti with SHiP++, CHROME, and Glider policies for 16-core systems”，用于展示 Drishti 增强方案在三种不同替换策略上的性能提升效果。</li>
<li>表格数据以 <strong>归一化至 LRU 的性能加速比</strong> 形式呈现，数值越高代表性能越优。</li>
<li>数据表明，Drishti 对所有三种策略均带来显著性能增益，验证其增强机制的广泛适用性。</li>
</ul>
<table>
<thead>
<tr>
<th>策略名称</th>
<th>性能加速比（归一化至 LRU）</th>
</tr>
</thead>
<tbody>
<tr>
<td>SHiP++</td>
<td>1.03</td>
</tr>
<tr>
<td><strong>D-SHiP++</strong></td>
<td><strong>1.08</strong></td>
</tr>
<tr>
<td>CHROME</td>
<td>1.06</td>
</tr>
<tr>
<td><strong>D-CHROME</strong></td>
<td><strong>1.13</strong></td>
</tr>
<tr>
<td>Glider</td>
<td>1.03</td>
</tr>
<tr>
<td><strong>D-Glider</strong></td>
<td><strong>1.06</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>D-SHiP++</strong> 相较于原始 SHiP++ 提升 <strong>5%</strong>（从 1.03 → 1.08），说明 Drishti 的动态采样与全局预测机制有效缓解了 SHiP++ 的局部性偏差问题。</li>
<li><strong>D-CHROME</strong> 相较于原始 CHROME 提升 <strong>7%</strong>（从 1.06 → 1.13），表明即使基于强化学习的策略也能从 Drishti 的结构优化中获益。</li>
<li><strong>D-Glider</strong> 相较于原始 Glider 提升 <strong>3%</strong>（从 1.03 → 1.06），显示深度学习型策略同样可受益于 Drishti 的采样集优化和跨切片预测共享。</li>
<li>所有增强版本（D-前缀）均优于基线策略，证明 Drishti 的两项核心增强——<strong>每核全局复用预测器</strong> 与 <strong>动态采样缓存</strong> ——对多种架构设计具有普适价值。</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.sections", "navigation.top", "navigation.indexes", "search.suggest", "search.highlight", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
        <script src="../../../javascripts/switcher.js"></script>
      
        <script src="../../../javascripts/smart_back.js"></script>
      
    
  </body>
</html>