
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/notes_repo/apt-get-profile-guided-timely-software-prefetching/paper_notes/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../../assets/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>APT-GET: Profile-Guided Timely Software Prefetching 论文解析 - BlaBlaCut</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="amber">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#apt-get-profile-guided-timely-software-prefetching" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="BlaBlaCut" class="md-header__button md-logo" aria-label="BlaBlaCut" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BlaBlaCut
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              APT-GET: Profile-Guided Timely Software Prefetching 论文解析
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="切换到深色模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换到深色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="切换到浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换到浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="BlaBlaCut" class="md-nav__button md-logo" aria-label="BlaBlaCut" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    BlaBlaCut
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/Recent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Recent
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/awesome-data-prefetchers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Awesome Data Prefetchers
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/micro-2025/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MICRO 2025
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/dyn-lang-acc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Dynamic Language Acceleration
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#0" class="md-nav__link">
    <span class="md-ellipsis">
      
        0. 论文基本信息
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. 摘要
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. 背景知识与核心贡献
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. 核心技术和实现细节
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. 核心技术和实现细节">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#0_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        0. 技术架构概览
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1-profile-guided-prefetch-distance-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Profile-Guided Prefetch Distance Calculation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-dynamic-prefetch-injection-site-selection" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Dynamic Prefetch Injection Site Selection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-llvm-compiler-pass-for-profile-guided-prefetching" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. LLVM Compiler Pass for Profile-Guided Prefetching
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-automated-delinquent-load-profiling-methodology" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Automated Delinquent Load Profiling Methodology
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. 实验方法与实验结果
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="apt-get-profile-guided-timely-software-prefetching">APT-GET: Profile-Guided Timely Software Prefetching 论文解析<a class="headerlink" href="#apt-get-profile-guided-timely-software-prefetching" title="Permanent link">&para;</a></h1>
<h2 id="0">0. 论文基本信息<a class="headerlink" href="#0" title="Permanent link">&para;</a></h2>
<p><strong>作者 (Authors)</strong>: Saba Jamilan, Tanvir Ahmed Khan, Grant Ayers, et al.</p>
<p><strong>发表期刊/会议 (Journal/Conference)</strong>: EuroSys</p>
<p><strong>发表年份 (Publication Year)</strong>: 2022</p>
<p><strong>研究机构 (Affiliations)</strong>: University of California, Santa Cruz, University of Michigan, Google</p>
<hr />
<h2 id="1">1. 摘要<a class="headerlink" href="#1" title="Permanent link">&para;</a></h2>
<p><strong>目的</strong></p>
<ul>
<li>解决现有<strong>自动化软件数据预取</strong>（automated software data prefetching）技术因<strong>静态特性</strong>而无法保证<strong>预取及时性</strong>（prefetch timeliness）的核心问题。</li>
<li>现有方法（如 Ainsworth &amp; Jones [9]）虽能保证<strong>高准确率</strong>和<strong>覆盖率</strong>，但因缺乏动态执行时间信息，导致预取过早（可能被缓存驱逐）或过晚（无法完全隐藏延迟），从而错失大量性能提升机会。</li>
</ul>
<p><strong>方法</strong></p>
<ul>
<li>提出 <strong>APT-GET</strong>，一种<strong>基于剖析</strong>（profile-guided）的新型软件预取机制，通过动态执行信息确保预取的及时性。</li>
<li>其核心设计包含两个关键步骤：<ul>
<li><strong>动态剖析</strong>（Dynamic Profiling）：利用现代处理器中已有的硬件支持（如 Intel 的 **Last Branch Record **(LBR)），以极低开销收集应用程序执行剖析信息。该信息用于精确刻画包含延迟关键负载（delinquent loads）的循环的执行时间。</li>
<li><strong>分析建模</strong>（Analytical Modeling）：基于收集到的剖析数据，建立一个新颖的分析模型来确定两个最优参数：<ul>
<li>**预取距离 **(prefetch-distance)：通过分析循环执行时间的分布（如</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/aa7cb0a4b4a8e3f8fa632b180321133ecc304f3aab85689f9a5eb0a8edb8adfa.jpg" /></p>
<p><em>Figure 4. Distribution of a loop’s execution time containing a delinquent load [39] in terms of CPU cycles measured using LBR samples</em></p>
<p>所示），分离出指令组件（IC）和内存组件（MC）的延迟，从而计算出能完全隐藏内存延迟的最佳预取距离。
- **预取注入点 **(prefetch injection site)：对于嵌套循环，分析内层循环的平均迭代次数，决定是在内层还是外层循环中注入预取指令，以应对低迭代次数循环的挑战。</p>
<ul>
<li>将上述逻辑实现为一个 <strong>LLVM 编译器 Pass</strong>，能够自动、精准地将剖析得到的最优配置注入到程序的中间表示（IR）中。</li>
</ul>
<p><strong>结果</strong></p>
<ul>
<li>在 <strong>10 个真实世界的内存延迟敏感型应用</strong>上对 APT-GET 进行了评估，主要结果如下：</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">对比项</th>
<th style="text-align: left;">APT-GET</th>
<th style="text-align: left;">Ainsworth &amp; Jones [9] (SOTA)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>平均加速比</strong></td>
<td style="text-align: left;"><strong>1.30×</strong></td>
<td style="text-align: left;">1.04×</td>
</tr>
<tr>
<td style="text-align: left;"><strong>最高加速比</strong></td>
<td style="text-align: left;"><strong>1.98×</strong></td>
<td style="text-align: left;">&lt; 1.30×</td>
</tr>
<tr>
<td style="text-align: left;"><strong>LLC MPKI 平均降低</strong></td>
<td style="text-align: left;"><strong>65.4%</strong></td>
<td style="text-align: left;">48.3%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>平均指令开销</strong></td>
<td style="text-align: left;"><strong>1.14×</strong></td>
<td style="text-align: left;">1.19×</td>
</tr>
</tbody>
</table>
<ul>
<li>关键发现：<ul>
<li>APT-GET 的性能显著优于现有技术，在几乎所有测试应用上都取得了正向收益，而 SOTA 方法在某些应用（如 BC）上甚至出现了<strong>性能倒退</strong>。</li>
<li>APT-GET 确定的预取距离非常接近理论最优值（</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/92ab55ddaa48a6e502efda4cbb8d507b4f646d468e5a35766d018a56f4209b77.jpg" /></p>
<p><em>Figure 8. Speedup of prefetch-distance from LBR sampling technique and optimal prefetch-distance over non-prefetching baseline: LBR sampling technique achieves 1.30× overall speedup in average, compared to 1.32× speedup of optimal prefetchdistance, over non-prefetching baseline.</em></p>
<p>）。</p>
<ul>
<li>优化预取注入点至关重要，对于多数嵌套循环应用，在<strong>外层循环</strong>注入预取能带来显著性能提升（</li>
</ul>
<p><img alt="" src="../images/95616f7d281dd9c3f57d85acc5a821fc05dc64b0d6d12103f821a3cb567394c0.jpg" /></p>
<p><em>Figure 10. Speedup of injecting prefetches inside the outer or inner loops over non-prefetching baseline: For most of the applications, injecting prefeches inside the outer loop achieves 1.20× overall speedup in average, while injecting prefetches inside the inner loop improves speedup for DFS up to 1.11× over non-prefethcing baseline.</em></p>
<p>）。</p>
<ul>
<li>APT-GET 具有良好的<strong>输入泛化能力</strong>，在不同数据集上训练和测试的性能差异很小（</li>
</ul>
<p><img alt="" src="../images/d40bcd2dd5ed6f90e8476ab79bd23e73d2d1988b49f71c48a6dd60c3e693013b.jpg" /></p>
<p><em>Figure 12. Execution time speedup provided by APT-GET over the non-prefetching baseline for different inputs as train/test data: APT-GET achieves 1.36× average speedup on average for test data sets compared to the 1.39× average speedup obtained for train data sets</em></p>
<p>）。</p>
<p><strong>结论</strong></p>
<ul>
<li><strong>预取及时性</strong>是制约现有软件预取技术发挥全部潜力的关键瓶颈。</li>
<li>APT-GET 通过结合<strong>低成本的硬件剖析</strong>（LBR）和<strong>新颖的分析模型</strong>，成功解决了这一问题，实现了<strong>高时效性</strong>的软件预取。</li>
<li>作为一种实用的编译器优化技术，APT-GET 能够在<strong>现有硬件</strong>上部署，并为现代数据驱动的、具有不规则内存访问模式的应用带来<strong>显著且可靠的性能提升</strong>（平均 <strong>1.30×</strong>）。</li>
</ul>
<hr />
<h2 id="2">2. 背景知识与核心贡献<a class="headerlink" href="#2" title="Permanent link">&para;</a></h2>
<p><strong>研究背景</strong></p>
<ul>
<li>现代数据驱动应用（如机器学习、数据分析）展现出<strong>复杂且不规则的内存访问模式</strong>，导致处理器频繁遭遇<strong>cache miss</strong>，损失超过 <strong>60%</strong> 的处理器周期。</li>
<li>当前处理器中的<strong>硬件 prefetcher</strong>（如 next-line, stride prefetchers）无法有效处理这些不规则模式。</li>
<li>开发者因此依赖<strong>软件 prefetching</strong>，但手动插入困难且易出错。现有的<strong>编译器自动插入技术</strong>（如 Ainsworth &amp; Jones [9] 的工作）虽能保证<strong>高准确率 (accuracy)</strong> 和<strong>高覆盖率 (coverage)</strong>，但由于其<strong>静态 (static) 本质</strong>，无法确保<strong>prefetch timeliness</strong>（预取及时性）。</li>
</ul>
<p><strong>研究动机</strong></p>
<ul>
<li><strong>Prefetch timeliness</strong> 是性能的关键：过早预取的数据可能在使用前就被<strong>驱逐 (evicted)</strong> 出 cache，而过晚预取则无法完全隐藏内存访问延迟。</li>
<li>静态方法无法获知代码在动态执行时的真实耗时，因此无法为不同应用场景（如不同循环体复杂度、不同 trip count）确定最优的预取参数。</li>
<li>如 Figure 1 所示，对于同一段代码，随着 <code>do_work</code> 函数复杂度的变化，<strong>最优的 prefetch-distance</strong> 从 32 变为 16 再变为 4，静态方法无法适应这种变化。</li>
</ul>
<p><img alt="" src="../images/5d12b6591110701207a8bfa4b123a6d93fcda5c7285270a8cc3633470a7e3224.jpg" /></p>
<p><em>Figure 1. Performance impact of prefetching various distances for indirect memory accesses with 256 inner loop iterations and varying work function complexity</em></p>
<ul>
<li>如 Table 1 所示，即使预取地址准确（高 accuracy），小的 prefetch-distance 也会导致大量 <strong>late prefetch</strong>（需求加载命中 fill buffer 中的预取请求），证明了静态方法在<strong>及时性</strong>上的不足。</li>
</ul>
<p><img alt="" src="../images/04b440ce8b7348592fdb180c4c98bea9919e43e09a57a5605b842116a29cd467.jpg" /></p>
<p><em>Table 1. Prefetch accuracy and timeliness depending on the prefetch-distance</em></p>
<ul>
<li>对于 trip count 很小的循环，始终在<strong>内层循环 (inner loop)</strong> 注入预取指令效果甚微，需要能动态选择<strong>预取注入点 (prefetch injection site)</strong>，例如在外层循环进行预取。</li>
</ul>
<p><img alt="" src="../images/fae1be1db6294333c2c5daadea36581e3bbad6e49cf18b936f4ff245cac3b7e8.jpg" /></p>
<p><em>Figure 2. Performance impact of prefetch-distance for indirect memory access kernel with low work function complexity and varying inner loop trip count</em></p>
<p><strong>核心贡献</strong></p>
<ul>
<li>提出了 <strong>APT-GET</strong>，一种新颖的<strong>profile-guided</strong>（基于剖析的）软件预取机制，通过利用<strong>动态执行时间信息</strong>来确保预取的及时性。</li>
<li>设计了一套高效的剖析方法，利用 Intel <strong>Last Branch Record (LBR)</strong> 等现有硬件特性，以<strong>可忽略的开销</strong>收集应用程序的执行剖析信息，用于刻画负载指令的执行时间。</li>
</ul>
<p><img alt="" src="../images/fcbd28c0826cb2873e16705bc1691ace6427e0828466e49442265cf51545831c.jpg" /></p>
<p><em>Figure 3. Schematic view of the Intel CPU’s Last Branch Record (LBR) highlighting the outer loop branches in blue, the inner loop branches in orange and the cycle times of each branch in green</em></p>
<ul>
<li>引入了一个<strong>新颖的分析模型</strong>，基于收集到的剖析数据（特别是循环执行时间的分布，如 Figure 4 所示），自动计算出<strong>最优的 prefetch-distance</strong> 和 <strong>最优的 prefetch injection site</strong>。</li>
</ul>
<p><img alt="" src="../images/aa7cb0a4b4a8e3f8fa632b180321133ecc304f3aab85689f9a5eb0a8edb8adfa.jpg" /></p>
<p><em>Figure 4. Distribution of a loop’s execution time containing a delinquent load [39] in terms of CPU cycles measured using LBR samples</em></p>
<ul>
<li>实现了一个 <strong>LLVM compiler pass</strong>，能够根据剖析结果自动注入具有<strong>可变 prefetch-distance</strong> 和<strong>灵活 injection site</strong> 的预取指令。</li>
<li>在 <strong>10 个真实世界的应用</strong>上评估了 APT-GET，结果表明：<ul>
<li>相比无预取基线，APT-GET 平均获得 <strong>1.30×</strong> 的加速比，最高可达 <strong>1.98×</strong>。</li>
<li>相比当前最先进的软件预取机制 [9]，APT-GET 的性能平均高出 <strong>1.25×</strong>。</li>
<li>APT-GET 平均减少了 <strong>65.4%</strong> 的 LLC cache miss (MPKI)。</li>
</ul>
</li>
</ul>
<hr />
<h2 id="3">3. 核心技术和实现细节<a class="headerlink" href="#3" title="Permanent link">&para;</a></h2>
<h3 id="0_1">0. 技术架构概览<a class="headerlink" href="#0_1" title="Permanent link">&para;</a></h3>
<p><strong>整体技术架构</strong></p>
<p>APT-GET 的整体架构是一个 <strong>profile-guided</strong>（基于剖析的）软件预取系统，它通过结合硬件性能监控单元（PMU）和编译器技术，动态地为程序注入<strong>及时</strong>（timely）的预取指令。其核心目标是解决传统静态软件预取方法因无法获知动态执行时间而导致的预取过早（被驱逐）或过晚（无法隐藏延迟）的问题。</p>
<p>该架构主要由两个阶段构成：<strong>剖析阶段</strong>（Profiling Phase）和<strong>编译注入阶段</strong>（Compilation &amp; Injection Phase）。</p>
<ul>
<li><strong>剖析阶段</strong>（Profiling Phase）<ul>
<li>利用 Intel 处理器的 **Last Branch Record **(LBR) 硬件特性，在程序运行时以极低开销收集分支历史记录。</li>
<li>同时，使用 **Precise Event-Based Sampling **(PEBS) 来识别导致频繁 **Last Level Cache **(LLC) 失效的 <strong>delinquent loads</strong>（问题加载指令）。</li>
<li>将 LBR 样本与 delinquent loads 的程序计数器（PC）进行关联分析。</li>
<li>通过分析 LBR 记录中循环分支的时间戳，计算出包含问题加载指令的循环的<strong>执行时间分布</strong>。</li>
<li>基于执行时间分布图（如 Figure 4 所示），自动识别出代表不同缓存层级（L1/L2/LLC/DRAM）服务时间的<strong>峰值</strong>（peaks）。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/aa7cb0a4b4a8e3f8fa632b180321133ecc304f3aab85689f9a5eb0a8edb8adfa.jpg" /></p>
<p><em>Figure 4. Distribution of a loop’s execution time containing a delinquent load [39] in terms of CPU cycles measured using LBR samples</em></p>
<ul>
<li>
<p>利用这些峰值数据，计算出最优的 <strong>prefetch-distance</strong>（预取距离）。</p>
</li>
<li>
<p>同时，通过统计 LBR 记录中内外层循环分支的出现次数，推断出<strong>内层循环的平均 trip count</strong>（迭代次数），以此决定最优的 <strong>prefetch injection site</strong>（预取注入点），即是在内层循环还是外层循环中注入预取指令。</p>
</li>
<li>
<p><strong>编译注入阶段</strong>（Compilation &amp; Injection Phase）</p>
<ul>
<li>实现为一个 <strong>LLVM compiler pass</strong>，在 LLVM IR 层面工作。</li>
<li>该 Pass 能够利用 <strong>AutoFDO</strong> 技术，将剖析阶段得到的机器码 PC 地址精确映射回 LLVM IR 中的对应指令。</li>
<li>对于识别出的每个 delinquent load，Pass 会执行一个<strong>后向数据依赖分析</strong>（backward data dependency analysis），构建出用于计算其内存地址的指令序列，即 <strong>load-slice</strong>。</li>
<li>根据剖析阶段得出的 <strong>prefetch-distance</strong> 和 <strong>prefetch injection site</strong>，Pass 会复制并修改这个 load-slice：<ul>
<li>将其中的加载（load）指令替换为 <strong><code>__builtin_prefetch</code></strong> 指令。</li>
<li>在地址计算中加入预取距离偏移量。</li>
<li>将修改后的预取 slice 注入到指定的循环位置（内层或外层）。</li>
</ul>
</li>
<li>Listing 4 展示了在内层循环中注入预取 slice 后的 LLVM IR 示例。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/04ee1658f4e9f2f14fd31839754162f14314cea737c0da31a8069af99f0c2a29.jpg" /></p>
<p><em>Listing 3. The simplified LLVM’s IR-level representation of the microbenchmark 1 before injecting the prefetch slice Listing 4. The simplified LLVM’s IR-level representation of the microbenchmark 1 after injecting the prefetch slice inside the inner loop</em></p>
<p>整个架构的关键创新在于，它建立了一个从<strong>动态执行剖析</strong>到<strong>静态编译优化</strong>的闭环，利用硬件提供的精准、低开销剖析信息来指导编译器做出更优的预取决策，从而确保了预取操作的<strong>及时性</strong>。</p>
<h3 id="1-profile-guided-prefetch-distance-calculation">1. Profile-Guided Prefetch Distance Calculation<a class="headerlink" href="#1-profile-guided-prefetch-distance-calculation" title="Permanent link">&para;</a></h3>
<p><strong>核心原理与算法流程</strong></p>
<p>APT-GET 的核心在于利用硬件性能监控单元（PMU）和 <strong>Last Branch Record (LBR)</strong> 来动态推断最优的 <strong>prefetch-distance</strong>，以确保预取操作的 <strong>timeliness</strong>（及时性）。其基本思想是：通过分析包含“问题负载”（delinquent load）的循环在不同内存层次结构服务下的执行时间分布，分离出指令执行开销（IC_latency）和内存访问开销（MC_latency），从而计算出能完全隐藏内存延迟所需的预取距离。</p>
<ul>
<li>
<p><strong>输入</strong>:</p>
<ul>
<li>一个未经优化的、未注入预取指令的应用程序二进制文件。</li>
<li>硬件支持：Intel CPU 的 <strong>LBR</strong> 和 <strong>Precise Event-Based Sampling (PEBS)</strong> 功能。</li>
</ul>
</li>
<li>
<p><strong>输出</strong>:</p>
<ul>
<li>一个包含 <strong>delinquent load PC</strong>（程序计数器地址）、其对应的 <strong>optimal prefetch-distance</strong> 和 <strong>optimal prefetch injection site</strong> 的配置文件。该文件将被后续的 LLVM 编译器 Pass 消费。</li>
</ul>
</li>
<li>
<p><strong>算法流程</strong>:</p>
<ol>
<li><strong>识别问题负载 (Delinquent Load Identification)</strong>: 使用 <code>perf</code> 工具通过 <strong>PEBS</strong> 采样，捕获那些频繁引发 <strong>Last Level Cache (LLC)</strong> 未命中的加载指令的 <strong>PC</strong> 地址。</li>
<li><strong>收集执行轨迹 (Profile Collection)</strong>: 在默认频率下（例如每毫秒一次），使用 <code>perf record</code> 启用 <strong>LBR</strong> 收集应用程序的执行剖面。LBR 记录了最近32个已执行的基本块（BBL）的分支信息，包括源地址、目标地址和执行时的 <strong>CPU cycle</strong>。</li>
<li><strong>关联与过滤 (Correlation and Filtering)</strong>: 将第一步得到的 <strong>delinquent load PC</strong> 与第二步收集的 LBR 样本进行关联。具体来说，定位到包含该 <strong>load PC</strong> 的基本块，并找到所有包含至少两次该基本块执行记录的 LBR 样本。</li>
<li><strong>测量循环延迟 (Loop Latency Measurement)</strong>: 对于每个符合条件的 LBR 样本，通过计算两次连续执行该循环分支指令之间的 <strong>CPU cycle</strong> 差值，得到该次循环迭代的实际执行时间。</li>
<li><strong>构建延迟分布 (Latency Distribution Construction)</strong>: 汇总所有测量到的循环执行时间，构建一个延迟分布直方图。</li>
<li><strong>峰值检测与参数推导 (Peak Detection and Parameter Derivation)</strong>:<ul>
<li>分析延迟分布图，识别出多个 <strong>peaks</strong>（峰值）。这些峰值对应于负载数据被不同层级的内存（如 L1, L2, LLC, DRAM）服务时的典型延迟。</li>
<li>最左侧的峰值（最短延迟）被解释为在理想情况下（即数据已在 L1/L2 缓存中）的 <strong>instruction component latency (IC_latency)</strong>。</li>
<li>最右侧的峰值（最长延迟）代表了在未命中缓存、需要从主存（DRAM）加载数据时的总延迟。</li>
<li><strong>memory component latency (MC_latency)</strong> 被计算为：<code>总延迟 (最右峰值) - IC_latency (最左峰值)</code>。</li>
</ul>
</li>
<li><strong>计算最优预取距离 (Optimal Prefetch Distance Calculation)</strong>: 根据论文中的公式 <code>IC_latency × prefetch_distance = MC_latency</code>，推导出最优的 <strong>prefetch-distance</strong> 为 <code>MC_latency / IC_latency</code>。</li>
</ol>
</li>
</ul>
<p><img alt="" src="../images/aa7cb0a4b4a8e3f8fa632b180321133ecc304f3aab85689f9a5eb0a8edb8adfa.jpg" /></p>
<p><em>Figure 4. Distribution of a loop’s execution time containing a delinquent load [39] in terms of CPU cycles measured using LBR samples</em></p>
<hr />
<p><strong>关键参数与技术细节</strong></p>
<ul>
<li><strong>LBR 的作用</strong>: LBR 提供了低开销、高精度的动态执行信息。它不仅能提供循环的平均执行时间，更重要的是提供了完整的 <strong>execution time distribution</strong>，这是静态分析无法获得的。通过 cycle 级别的计时，APT-GET 能够精确地将内存延迟与指令执行延迟分离开来。</li>
<li><strong>峰值检测算法</strong>: APT-GET 使用 <code>scipy.signal.find_peaks_cwt</code> 库函数，该函数基于 <strong>continuous wavelet transform (CWT)</strong> 算法来自动、鲁棒地识别延迟分布图中的峰值位置，避免了人工设定阈值的麻烦。</li>
<li><strong>假设前提</strong>: 该方法的核心假设是，在没有缓存未命中的情况下，循环的指令执行部分（IC）的延迟是相对稳定和可预测的，这在实践中通常是成立的。</li>
</ul>
<hr />
<p><strong>在整体架构中的作用</strong></p>
<p>APT-GET 的 <strong>Profile-Guided Prefetch Distance Calculation</strong> 模块是整个系统实现 <strong>timely prefetching</strong> 的基石。它解决了传统静态编译器预取技术的最大痛点——无法根据实际运行时的动态行为调整预取策略。</p>
<ul>
<li><strong>上游依赖</strong>: 它依赖于标准的 Linux <code>perf</code> 工具链进行数据采集，这使得它能够无缝集成到现有的 <strong>Profile-Guided Optimization (PGO)</strong> 流程中，无需额外的、侵入式的探针代码。</li>
<li><strong>下游消费</strong>: 其输出的配置文件被一个定制的 <strong>LLVM compiler pass</strong> 所消费。该 Pass 负责将静态分析得到的 <strong>load-slice</strong>（用于计算预取地址的指令序列）与动态计算出的 <strong>prefetch-distance</strong> 相结合，生成最终的、带有精准预取指令的优化代码。</li>
<li><strong>效果验证</strong>: 如图8所示，通过 LBR 采样技术计算出的预取距离，其性能表现（1.30× 平均加速比）非常接近理论上的最优预取距离（1.32× 平均加速比），证明了该方法的有效性和准确性。</li>
</ul>
<p><img alt="" src="../images/92ab55ddaa48a6e502efda4cbb8d507b4f646d468e5a35766d018a56f4209b77.jpg" /></p>
<p><em>Figure 8. Speedup of prefetch-distance from LBR sampling technique and optimal prefetch-distance over non-prefetching baseline: LBR sampling technique achieves 1.30× overall speedup in average, compared to 1.32× speedup of optimal prefetchdistance, over non-prefetching baseline.</em></p>
<h3 id="2-dynamic-prefetch-injection-site-selection">2. Dynamic Prefetch Injection Site Selection<a class="headerlink" href="#2-dynamic-prefetch-injection-site-selection" title="Permanent link">&para;</a></h3>
<p>APT-GET 的动态预取注入点选择机制是其确保 <strong>prefetch timeliness</strong>（预取及时性）的核心创新之一，它解决了传统静态方法在面对不同循环结构时无法自适应调整的缺陷。</p>
<p><strong>核心动机与问题定义</strong></p>
<ul>
<li>传统的编译器预取技术（如 Ainsworth &amp; Jones [9]）通常将预取指令<strong>静态地</strong>注入到最内层循环（inner loop）中。</li>
<li>这种策略在<strong>内层循环 trip count 较高</strong>时是有效的，因为有足够的时间窗口让预取的数据在被使用前到达缓存。</li>
<li>然而，当内层循环的 <strong>trip count 很低</strong>（例如只有几次迭代）时，在内层循环中注入预取会带来严重问题：<ul>
<li>预取指令的执行开销（instruction overhead）相对于循环体本身变得不可忽略。</li>
<li>由于循环迭代次数少，预取可能无法覆盖足够多的后续内存访问，导致 <strong>coverage</strong>（覆盖率）低下。</li>
<li>预取操作可能过于“局促”，无法提供足够的提前量来隐藏内存延迟。</li>
</ul>
</li>
<li>因此，APT-GET 提出了一种动态决策机制：根据循环的实际运行时特征，智能地选择在 <strong>inner loop</strong> 或 <strong>outer loop</strong> 中注入预取指令。</li>
</ul>
<p><strong>实现原理与算法流程</strong></p>
<ul>
<li>APT-GET 利用 Intel 处理器的 <strong>Last Branch Record (LBR)</strong> 硬件特性来收集程序的动态执行信息。</li>
<li><strong>输入</strong>: LBR 性能分析样本。每个 LBR 样本记录了最近 32 个已执行的基本块（BBL）的分支信息，包括程序计数器（PC）、目标地址和执行时的 CPU 周期。</li>
<li><strong>关键洞察</strong>: 通过分析 LBR 样本中连续出现的分支 PC，可以推断出嵌套循环的结构和执行次数。<ul>
<li>例如，在一个两层嵌套循环中，LBR 记录会交替出现外层循环和内层循环的分支。通过统计两个外层循环分支之间内层循环分支出现的次数，即可估算出<strong>内层循环的平均 trip count</strong>。</li>
</ul>
</li>
<li><strong>决策方程</strong>: APT-GET 使用一个基于覆盖率的启发式方程来决定注入点：
    <code>avg_inner_trip_count * C &lt; prefetch_distance</code><ul>
<li>其中，<code>avg_inner_trip_count</code> 是从 LBR 分析得出的内层循环平均迭代次数。</li>
<li><code>prefetch_distance</code> 是通过分析循环执行时间分布（如 Figure 4 所示）计算出的最优预取距离。</li>
<li><code>C</code> 是一个常数，代表为了达到目标覆盖率（例如 80%）所需的最小迭代次数。论文中提到，若要覆盖 80% 的需求加载，<code>C</code> 的值应为 5。</li>
</ul>
</li>
<li><strong>决策逻辑</strong>:<ul>
<li>如果上述不等式成立，意味着在内层循环中执行预取无法有效覆盖大部分内存访问（因为循环体太小），此时 APT-GET 会选择在 <strong>outer loop</strong> 中注入预取。</li>
<li>否则，预取指令将被注入到 <strong>inner loop</strong> 中。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/fcbd28c0826cb2873e16705bc1691ace6427e0828466e49442265cf51545831c.jpg" /></p>
<p><em>Figure 3. Schematic view of the Intel CPU’s Last Branch Record (LBR) highlighting the outer loop branches in blue, the inner loop branches in orange and the cycle times of each branch in green</em></p>
<p><strong>在 LLVM 编译器中的实现细节</strong></p>
<ul>
<li>APT-GET 的 LLVM Pass 被设计为能够处理两种场景：单层循环和嵌套循环。</li>
<li>当决策结果为在 <strong>outer loop</strong> 注入时，编译器需要执行更复杂的代码转换：<ul>
<li><strong>Load-slice 扩展</strong>: 预取切片（load-slice）的构建不仅需要包含内层循环的归纳变量（PHI node），还需要回溯并包含外层循环的归纳变量。</li>
<li><strong>地址计算调整</strong>: 在外层循环的上下文中，内层循环的归纳变量是未知的。为了解决这个问题，APT-GET 采用一种简化策略：将内层归纳变量初始化为 0，并利用从 LBR 分析得到的<strong>平均内层 trip count</strong>，生成多个预取指令，以覆盖内层循环的典型执行范围。</li>
</ul>
</li>
<li>这一过程在 Algorithm 2 中体现为对 <code>PHINode</code> 数量的判断（<code>SetOfPhiNodes[p].size()&gt;1</code>），从而调用 <code>InjectPrefechesMorePhis</code> 函数来处理嵌套循环场景。</li>
</ul>
<p><strong>效果验证与作用</strong></p>
<ul>
<li>Figure 10 清晰地展示了该机制的有效性。对于大多数包含嵌套循环的应用（如 BFS, SSSP, BC 等），在外层循环注入预取带来了显著的性能提升，而在内层循环注入则可能导致性能下降甚至不如基线。</li>
<li>该机制的作用是确保预取操作不仅在<strong>时间上</strong>是及时的（通过最优 prefetch-distance），而且在<strong>空间/控制流上</strong>也是高效的（通过最优 injection site），从而最大化预取的收益并最小化其指令开销。</li>
</ul>
<p><img alt="" src="../images/95616f7d281dd9c3f57d85acc5a821fc05dc64b0d6d12103f821a3cb567394c0.jpg" /></p>
<p><em>Figure 10. Speedup of injecting prefetches inside the outer or inner loops over non-prefetching baseline: For most of the applications, injecting prefeches inside the outer loop achieves 1.20× overall speedup in average, while injecting prefetches inside the inner loop improves speedup for DFS up to 1.11× over non-prefethcing baseline.</em></p>
<h3 id="3-llvm-compiler-pass-for-profile-guided-prefetching">3. LLVM Compiler Pass for Profile-Guided Prefetching<a class="headerlink" href="#3-llvm-compiler-pass-for-profile-guided-prefetching" title="Permanent link">&para;</a></h3>
<p><strong>实现原理与核心流程</strong></p>
<p>APT-GET 的核心是一个 <strong>function-level LLVM pass</strong>，它通过结合动态剖析信息与静态代码分析，实现了精准且及时的软件预取。其工作流程主要分为两个阶段：剖析数据准备和编译时指令注入。</p>
<ul>
<li>
<p><strong>剖析数据准备阶段</strong>：</p>
<ul>
<li>系统首先运行目标应用，并利用 <strong>perf record</strong> 工具收集两类关键硬件性能事件样本。<ul>
<li>第一类是 <strong>Precise Event-Based Sampling (PEBS)</strong>，用于精确定位引发频繁 <strong>Last Level Cache (LLC) misses</strong> 的“问题加载指令”（delinquent loads），并记录其 <strong>Program Counter (PC)</strong>。</li>
<li>第二类是启用 <strong>Intel Last Branch Record (LBR)</strong> 的常规采样，用于捕获程序执行路径上的分支历史及其时间戳。</li>
</ul>
</li>
<li>随后，一个自动化脚本处理这些 LBR 样本。对于每个被识别出的 delinquent load PC，脚本会：<ul>
<li>在 LBR 记录中定位包含该 PC 的基本块（Basic Block, BBL）。</li>
<li>通过分析连续分支的时间戳差值，计算出包含该加载指令的循环的<strong>迭代执行时间分布</strong>。</li>
<li>利用 <strong>scipy.signal.find_peaks_cwt</strong> 算法自动分析该分布，识别出代表不同缓存层级（L1/L2/LLC/DRAM）服务延迟的峰值。</li>
<li>根据公式 <code>prefetch_distance = MC_latency / IC_latency</code>（其中 <code>MC_latency</code> 是内存组件延迟，<code>IC_latency</code> 是指令组件延迟），计算出<strong>最优预取距离</strong>。</li>
<li>同时，通过统计 LBR 中内外层循环分支的出现次数，计算出<strong>内层循环的平均 trip count</strong>，以决定<strong>最优预取注入点</strong>（内层或外层循环）。</li>
</ul>
</li>
<li>最终输出一个映射文件，将每个 delinquent load PC 与其对应的 <strong>prefetch-distance</strong> 和 <strong>prefetch injection site</strong> 关联起来。</li>
</ul>
</li>
<li>
<p><strong>编译时指令注入阶段 (LLVM Pass)</strong>：</p>
<ul>
<li>LLVM pass 在编译时读取上述生成的映射文件。</li>
<li>它利用 <strong>AutoFDO</strong> 的能力，将剖析阶段获得的 <strong>PC 地址精确映射回 LLVM IR 中的具体加载指令</strong>。</li>
<li>对于每个被标记的加载指令，pass 执行一个改进的 <strong>load-slice 搜索算法</strong>（基于深度优先搜索 DFS）。<ul>
<li>该算法向后遍历数据依赖图，不仅找到直接相关的循环归纳变量（PHINode），还会继续追溯以支持<strong>嵌套循环</strong>场景。</li>
<li>这使得系统能够构建出完整的地址计算切片，无论该加载指令位于单层还是多层循环中。</li>
</ul>
</li>
<li>根据映射文件中的指导信息，pass 决定在何处（内层或外层循环）注入预取指令，并使用计算出的<strong>可变预取距离</strong>来修改地址计算逻辑。</li>
<li>最后，pass 复制整个 load-slice，并将其中的原始加载指令替换为 <strong><code>__builtin_prefetch</code></strong> 内建函数，从而完成预取指令的注入。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/04ee1658f4e9f2f14fd31839754162f14314cea737c0da31a8069af99f0c2a29.jpg" /></p>
<p><em>Listing 3. The simplified LLVM’s IR-level representation of the microbenchmark 1 before injecting the prefetch slice Listing 4. The simplified LLVM’s IR-level representation of the microbenchmark 1 after injecting the prefetch slice inside the inner loop</em></p>
<p><strong>关键特性与参数设置</strong></p>
<ul>
<li><strong>动态距离与注入点</strong>：与传统静态方法使用固定 <code>prefetch-distance</code> 不同，APT-GET 为每个预取点计算<strong>独立的、动态的最优距离</strong>，并智能选择<strong>内层或外层循环</strong>作为注入点，这是其实现高时效性的关键。</li>
<li><strong>对复杂循环的支持</strong>：<ul>
<li>支持<strong>非规范型归纳变量</strong>（例如 <code>i *= 2</code> 而非仅 <code>i++</code>）。</li>
<li>支持<strong>复杂的循环退出条件</strong>（例如 <code>for(i:K){if(cond(i)) break;}</code>）。</li>
</ul>
</li>
<li><strong>后备机制</strong>：如果剖析数据不可用（例如 AutoFDO 映射失败），该 pass 会优雅地降级为执行 Ainsworth &amp; Jones 提出的<strong>纯静态预取方案</strong>，确保功能的鲁棒性。</li>
<li><strong>核心参数</strong>：算法中的一个关键阈值 <code>K</code>（见公式 <code>avg_inner_trip_count * K &lt; prefetch_distance</code>）用于决定何时切换到外层循环预取。文中提到，若要覆盖 80% 的需求加载，<code>K</code> 的值应设为 5。</li>
</ul>
<p><strong>输入输出关系及在整体系统中的作用</strong></p>
<p>APT-GET 的 LLVM pass 是连接动态剖析与最终优化代码的桥梁，其输入输出关系清晰定义了其在系统中的角色。</p>
<ul>
<li>
<p><strong>输入</strong>：</p>
<ul>
<li><strong>LLVM IR</strong>：待优化应用程序的中间表示。</li>
<li><strong>Profile 文件</strong>：由剖析阶段生成的、包含 delinquent load PC 及其对应 <code>prefetch-distance</code> 和 <code>injection site</code> 的映射文件。</li>
<li><strong>调试信息</strong>：编译时需开启 <code>-gmlt</code> 和 <code>-fdebug-info-for-profiling</code> 选项，以便 AutoFDO 能够准确地将 PC 映射到 IR 指令。</li>
</ul>
</li>
<li>
<p><strong>输出</strong>：</p>
<ul>
<li><strong>优化后的 LLVM IR</strong>：在原始 IR 的基础上，在计算出的最佳位置插入了带有可变距离的预取指令切片。</li>
</ul>
</li>
<li>
<p><strong>在整体系统中的作用</strong>：</p>
<ul>
<li><strong>执行者</strong>：它是 APT-GET 设计理念的最终执行者，负责将通过 LBR 剖析得出的“何时预取、预取多远”的动态洞察，转化为实际的机器指令。</li>
<li><strong>通用化接口</strong>：通过构建在 LLVM 之上，该 pass 具备了良好的通用性，可以无缝集成到任何使用 LLVM 工具链的现代编译流程中。</li>
<li><strong>性能兑现者</strong>：正是这个 pass 的精确注入，才使得 APT-GET 能够在真实应用中实现高达 <strong>1.98×</strong> 的加速比和 <strong>1.30×</strong> 的平均加速比，显著优于静态方法。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">对比项</th>
<th style="text-align: left;">APT-GET (Profile-Guided)</th>
<th style="text-align: left;">Ainsworth &amp; Jones (Static)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>预取距离</strong></td>
<td style="text-align: left;"><strong>动态、可变</strong>，为每个加载点单独计算</td>
<td style="text-align: left;"><strong>静态、固定</strong>，需手动调优</td>
</tr>
<tr>
<td style="text-align: left;"><strong>注入点选择</strong></td>
<td style="text-align: left;"><strong>智能决策</strong>，可在内层或外层循环</td>
<td style="text-align: left;"><strong>固定</strong>，仅在内层循环</td>
</tr>
<tr>
<td style="text-align: left;"><strong>剖析依赖</strong></td>
<td style="text-align: left;">依赖 <strong>LBR</strong> 和 <strong>PEBS</strong> 剖析数据</td>
<td style="text-align: left;">无依赖，纯静态分析</td>
</tr>
<tr>
<td style="text-align: left;"><strong>平均加速比</strong></td>
<td style="text-align: left;"><strong>1.30×</strong></td>
<td style="text-align: left;">1.04×</td>
</tr>
<tr>
<td style="text-align: left;"><strong>LLC MPKI 平均降低</strong></td>
<td style="text-align: left;"><strong>65.4%</strong></td>
<td style="text-align: left;">48.3%</td>
</tr>
</tbody>
</table>
<h3 id="4-automated-delinquent-load-profiling-methodology">4. Automated Delinquent Load Profiling Methodology<a class="headerlink" href="#4-automated-delinquent-load-profiling-methodology" title="Permanent link">&para;</a></h3>
<p><strong>自动化劣迹加载剖析方法论 (Automated Delinquent Load Profiling Methodology)</strong></p>
<p>APT-GET 的核心创新在于其完全自动化的剖析流程，该流程能够精准识别性能瓶颈（即劣迹加载），并利用硬件特性推导出最优的软件预取参数。其实现原理与算法流程如下：</p>
<ul>
<li><strong>输入</strong>: 未经任何预取优化的原始应用程序二进制文件。</li>
<li><strong>输出</strong>: 一个包含所有已识别劣迹加载指令指针（PC）及其对应<strong>最优预取距离 (optimal prefetch-distance)</strong> 和<strong>最优预取注入点 (optimal prefetch injection site)</strong> 的配置文件，供后续的 LLVM 编译器 Pass 使用。</li>
</ul>
<hr />
<p><strong>剖析流程详解</strong></p>
<p>该自动化方法由一系列紧密耦合的步骤组成，旨在从硬件性能计数器中提取动态执行信息：</p>
<ul>
<li>
<p><strong>步骤一：识别劣迹加载 (Delinquent Load Identification)</strong></p>
<ul>
<li>利用 Linux <code>perf</code> 工具的 <strong>Precise Event-Based Sampling (PEBS)</strong> 功能。</li>
<li>配置性能监控单元 (PMU) 以在发生 <strong>Last Level Cache (LLC) miss</strong> 时触发采样。</li>
<li>PEBS 能够精确地捕获导致缓存未命中的<strong>具体加载指令的程序计数器 (PC)</strong>，这些指令被标记为“劣迹加载”。</li>
</ul>
</li>
<li>
<p><strong>步骤二：收集 Last Branch Record (LBR) 剖析数据</strong></p>
<ul>
<li>在运行应用程序时，启用 Intel CPU 的 <strong>Last Branch Record (LBR)</strong> 功能进行剖析。</li>
<li>LBR 是一个硬件缓冲区，能记录最近执行的 32 个（在论文实验平台上）分支指令的详细信息，包括：<ul>
<li>分支源地址 (From)</li>
<li>分支目标地址 (To)</li>
<li>分支执行时的 <strong>CPU cycle 时间戳</strong></li>
</ul>
</li>
<li><img alt="" src="../images/fcbd28c0826cb2873e16705bc1691ace6427e0828466e49442265cf51545831c.jpg" /></li>
</ul>
</li>
</ul>
<p><em>Figure 3. Schematic view of the Intel CPU’s Last Branch Record (LBR) highlighting the outer loop branches in blue, the inner loop branches in orange and the cycle times of each branch in green</em></p>
<ul>
<li>
<p><strong>步骤三：关联 LBR 样本与劣迹加载</strong></p>
<ul>
<li>对收集到的所有 LBR 样本进行过滤，只保留那些<strong>包含已识别劣迹加载 PC</strong> 的样本。</li>
<li>通过检查 LBR 记录中连续两个分支条目所定义的 <strong>Basic Block (BBL)</strong> 范围，来确定劣迹加载 PC 是否位于该 BBL 内。</li>
</ul>
</li>
<li>
<p><strong>步骤四：提取循环延迟分布 (Loop Latency Distribution Extraction)</strong></p>
<ul>
<li>对于包含至少两次相同循环分支（即包含劣迹加载的循环）的 LBR 样本，通过<strong>相减两次分支的 CPU cycle 时间戳</strong>来计算单次循环迭代的执行时间。</li>
<li>将所有此类测量值汇集起来，形成一个<strong>循环执行时间的分布图</strong>。</li>
<li><img alt="" src="../images/aa7cb0a4b4a8e3f8fa632b180321133ecc304f3aab85689f9a5eb0a8edb8adfa.jpg" /></li>
</ul>
</li>
</ul>
<p><em>Figure 4. Distribution of a loop’s execution time containing a delinquent load [39] in terms of CPU cycles measured using LBR samples</em></p>
<ul>
<li>
<p>该分布图通常呈现多个峰值，每个峰值对应于劣迹加载从内存层次结构不同层级（如 L1, L2, LLC, DRAM）服务时的循环延迟。</p>
</li>
<li>
<p><strong>步骤五：自动计算最优预取距离</strong></p>
<ul>
<li>使用 <strong>scipy.signal.find_peaks_cwt</strong> 算法自动检测分布图中的峰值位置。</li>
<li>最左侧的峰值（最短延迟）被解释为<strong>指令组件延迟 (IC_latency)</strong>，即假设所有内存访问都命中 L1/L2 缓存时的循环执行时间。</li>
<li>最右侧的峰值（最长延迟）与 IC_latency 的差值被解释为<strong>内存组件延迟 (MC_latency)</strong>，即由 DRAM 访问引入的额外开销。</li>
<li>根据公式 <strong><code>prefetch_distance = MC_latency / IC_latency</code></strong> 计算得出最优预取距离。例如，在图4中，计算结果约为 <strong>7</strong>。</li>
</ul>
</li>
<li>
<p><strong>步骤六：确定最优预取注入点</strong></p>
<ul>
<li>通过分析 LBR 样本中内外循环分支的出现模式，<strong>自动计算内层循环的平均 trip count</strong>。</li>
<li>应用决策规则：如果 <strong><code>average_inner_trip_count * K &lt; prefetch_distance</code></strong>（其中 K 是一个基于覆盖率需求的经验常数，如覆盖 80% 的加载则 K=5），则将预取指令注入到<strong>外层循环</strong>，否则注入到<strong>内层循环</strong>。</li>
<li>此决策确保了在 trip count 较小的循环中，预取操作仍有足够的时间提前执行，从而保证<strong>预取的及时性 (timeliness)</strong>。</li>
</ul>
</li>
</ul>
<hr />
<p><strong>在 APT-GET 整体架构中的作用</strong></p>
<p>该自动化剖析方法是 APT-GET 实现高性能增益的关键前置步骤，其作用至关重要：</p>
<ul>
<li><strong>桥梁作用</strong>: 它成功地将<strong>动态运行时性能数据</strong>（来自 PEBS 和 LBR）与<strong>静态编译时代码优化</strong>（LLVM Pass）连接起来，克服了纯静态分析无法获知真实执行时间的固有缺陷。</li>
<li><strong>参数生成器</strong>: 它为后续的编译器优化阶段提供了精确、个性化的配置参数（预取距离和注入点），使得每个预取指令都能在其最佳时机被注入，最大化隐藏内存延迟的效果。</li>
<li><strong>通用性与自动化</strong>: 整个流程无需任何人工干预或手动调优，使其能够无缝集成到现有的 <strong>Profile-Guided Optimization (PGO)</strong> 工作流中（如 Google 数据中心已有的持续剖析基础设施），具备极强的实用性和可扩展性。</li>
</ul>
<hr />
<h2 id="4">4. 实验方法与实验结果<a class="headerlink" href="#4" title="Permanent link">&para;</a></h2>
<p><strong>实验设置</strong></p>
<ul>
<li><strong>硬件平台</strong>: 实验在一台配备 <strong>Intel Xeon Gold 6242R CPU</strong> (3.10GHz, 768GB DDR4-2666 DRAM) 的服务器上进行。</li>
<li><strong>软件栈</strong>: 使用 <strong>LLVM/Clang 10.0</strong> 编译器，在 <strong>Ubuntu 20.04</strong> (Kernel 5.4) 系统上实现。编译时启用最高优化级别 <code>-O3</code>，并使用 <code>-gmlt</code> 和 <code>-fdebug-info-for-profiling</code> 生成调试信息以支持 Profile-Guided Optimization (PGO)。</li>
<li><strong>对比基线</strong>:<ul>
<li><strong>No-Prefetching Baseline</strong>: 不进行任何预取的原始程序。</li>
<li><strong>Ainsworth &amp; Jones [9]</strong>: 代表当前最先进的静态编译器自动预取技术，其使用固定的预取距离（prefetch-distance）并将预取指令仅注入到内层循环。</li>
</ul>
</li>
<li><strong>评估指标</strong>: 主要关注 <strong>执行时间加速比 (Speedup)</strong>、<strong>LLC Misses Per Kilo Instructions (MPKI)</strong> 以及 <strong>指令开销 (Instruction Overhead)</strong>。</li>
<li><strong>基准测试集</strong>: 选取了 <strong>10 个真实世界的内存密集型应用</strong>，这些应用均包含无法被硬件预取器处理的间接内存访问模式。具体包括：<ul>
<li><strong>图计算</strong>: 来自 CRONO 和 Graph500 套件的 BFS, DFS, PageRank, BC, SSSP。</li>
<li><strong>科学计算</strong>: NAS Parallel Benchmarks 中的 IS (Integer Sort) 和 CG (Conjugate Gradient)。</li>
<li><strong>数据库与哈希</strong>: HPC Challenge 的 RandomAccess 以及两种 Hash Join (HJ2, HJ8)。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/b566bd68085cb978c4ee8687dec9b6f3969f88c6a7aa53a3d77fa5edc8691033.jpg" /></p>
<p><em>Table 3. The list of real-applications</em></p>
<p><img alt="" src="../images/fe2c5a10f3b191ca1f63c6c4cc3901eadd3e61745ca320d1ea8f3158e9c7eef9.jpg" /></p>
<p><em>Table 4. Graph data-sets properties</em></p>
<p><strong>核心结果数据</strong></p>
<ul>
<li><strong>整体性能提升</strong>: APT-GET 相对于无预取基线实现了 <strong>1.30× 的平均加速比</strong>，最高加速比达到 <strong>1.98×</strong> (在 HJ8 和 BFS 上)。相比之下，Ainsworth &amp; Jones 方法的平均加速比仅为 <strong>1.04×</strong>，且在某些应用（如 BC）上甚至出现了性能倒退。</li>
<li><strong>缓存未命中减少</strong>: APT-GET 平均减少了 <strong>65.4%</strong> 的 LLC MPKI，而 Ainsworth &amp; Jones 仅减少了 <strong>48.3%</strong>。这表明 APT-GET 能更有效地将数据提前加载到缓存中。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">方法</th>
<th style="text-align: center;">平均 Speedup</th>
<th style="text-align: center;">最大 Speedup</th>
<th style="text-align: center;">平均 MPKI Reduction</th>
<th style="text-align: center;">平均指令开销</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Ainsworth &amp; Jones [9]</td>
<td style="text-align: center;">1.04×</td>
<td style="text-align: center;">&lt; 1.5×</td>
<td style="text-align: center;">48.3%</td>
<td style="text-align: center;">1.19×</td>
</tr>
<tr>
<td style="text-align: left;"><strong>APT-GET</strong></td>
<td style="text-align: center;"><strong>1.30×</strong></td>
<td style="text-align: center;"><strong>1.98×</strong></td>
<td style="text-align: center;"><strong>65.4%</strong></td>
<td style="text-align: center;"><strong>1.14×</strong></td>
</tr>
</tbody>
</table>
<p><img alt="" src="../images/0844beaacc88f3137e7802c9c98e5d10be26a0c31589645da5b8ff459909628f.jpg" /></p>
<p><em>Figure 6. Execution time speedup provided by APT-GET over the non-prefetching baseline: APT-GET achieves 1.30× average speedup on average, compared to the 1.04× speedup provided by the state of the art (Ainsworth &amp; Jones).</em></p>
<p><img alt="" src="../images/696ecf9672232d85c990bd80e37acf574476f5df443a4bfb3af30cdd8162a7b3.jpg" /></p>
<p><em>Figure 7. APT-GET ’s LLC MPKI, misses per 1000-instructions, reduction over the non-prefetching baseline (lower is better): on average, APT-GET provides 1.35× greater MPKI reduction than the state of the art (Ainsworth &amp; Jones).</em></p>
<p><strong>消融实验 (Ablation Studies)</strong></p>
<p>消融实验旨在验证 APT-GET 中两个核心设计——<strong>基于 LBR 的预取距离优化</strong>和<strong>预取注入点优化</strong>——各自的有效性。</p>
<ul>
<li><strong>LBR 预取距离优化的有效性</strong>:<ul>
<li>通过将 APT-GET 计算出的动态预取距离与一组静态距离（4, 16, 64）进行比较，发现 APT-GET 在几乎所有应用上都取得了最佳或接近最佳的性能。</li>
<li>实验还表明，APT-GET 通过 LBR 采样找到的预取距离非常接近理论上的最优值（通过穷举搜索所有距离得到），证明了其分析模型的准确性。</li>
<li><strong>结论</strong>: 动态、基于剖析的预取距离选择显著优于任何固定的静态距离。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/92ab55ddaa48a6e502efda4cbb8d507b4f646d468e5a35766d018a56f4209b77.jpg" /></p>
<p><em>Figure 8. Speedup of prefetch-distance from LBR sampling technique and optimal prefetch-distance over non-prefetching baseline: LBR sampling technique achieves 1.30× overall speedup in average, compared to 1.32× speedup of optimal prefetchdistance, over non-prefetching baseline.</em></p>
<p><img alt="" src="../images/0015dcc6d01f2c06becaefa02034ef9c293ce33fba8c4229cfa29a2e46b8cefc.jpg" /></p>
<p><em>Figure 9. Speedup for different static offset values and LBR over non-prefetching baseline: prefetch-distance of 4, 16, 64, and LBR sampling technique achieve 1.16×, 1.26×, 1.28×, and 1.30× speedup in average over non-prefetching baseline, respectively.</em></p>
<ul>
<li><strong>预取注入点优化的有效性</strong>:<ul>
<li>对于包含嵌套循环的应用，实验分别测试了仅在内层循环注入预取和根据 APT-GET 分析结果（可能在外层循环注入）的性能。</li>
<li>结果显示，对于 trip count 较小的内层循环（如 BFS 在 loc-Brightkite 数据集上），在外层循环注入预取能带来显著性能提升（平均 <strong>1.20×</strong>），而在内层循环注入则几乎没有收益甚至有害。</li>
<li>唯一的例外是 DFS，其在内层循环注入效果更好。</li>
<li><strong>结论</strong>: 静态地将预取指令注入内层循环并非普适策略，动态选择最优的<strong>预取注入点 (prefetch injection site)</strong> 对于处理不同特性的循环至关重要。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/95616f7d281dd9c3f57d85acc5a821fc05dc64b0d6d12103f821a3cb567394c0.jpg" /></p>
<p><em>Figure 10. Speedup of injecting prefetches inside the outer or inner loops over non-prefetching baseline: For most of the applications, injecting prefeches inside the outer loop achieves 1.20× overall speedup in average, while injecting prefetches inside the inner loop improves speedup for DFS up to 1.11× over non-prefethcing baseline.</em></p>
<ul>
<li><strong>其他关键观察</strong>:<ul>
<li><strong>指令开销</strong>: APT-GET 的平均指令开销（1.14×）低于 Ainsworth &amp; Jones（1.19×），说明其更精准的预取策略避免了不必要的指令注入。</li>
<li><strong>输入泛化能力</strong>: 在一个数据集上训练（剖析）并在另一个数据集上测试，性能几乎没有下降，表明 APT-GET 的剖析信息具有良好的泛化性。</li>
<li><strong>剖析开销</strong>: 整个剖析过程耗时仅 <strong>15-20 秒</strong>，在数据中心等持续集成/部署（CI/CD）场景下是可以接受的。</li>
</ul>
</li>
</ul>
<hr />












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.sections", "navigation.top", "navigation.indexes", "search.suggest", "search.highlight", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
        <script src="../../../javascripts/switcher.js"></script>
      
        <script src="../../../javascripts/smart_back.js"></script>
      
    
  </body>
</html>