
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/notes_repo/investigating-managed-language-runtime-performance-why-javascript-and-python-are-8x-and-29x-slower-than-c-yet-java-and-go-can-be-faster/figs_notes/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../../assets/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>Investigating Managed Language Runtime Performance: Why JavaScript and Python are 8x and 29x slower than C++, yet Java and Go can be Faster? 图表详解 - BlaBlaCut</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="amber">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#investigating-managed-language-runtime-performance-why-javascript-and-python-are-8x-and-29x-slower-than-c-yet-java-and-go-can-be-faster" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="BlaBlaCut" class="md-header__button md-logo" aria-label="BlaBlaCut" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BlaBlaCut
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Investigating Managed Language Runtime Performance: Why JavaScript and Python are 8x and 29x slower than C++, yet Java and Go can be Faster? 图表详解
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="切换到深色模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换到深色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="切换到浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换到浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="BlaBlaCut" class="md-nav__button md-logo" aria-label="BlaBlaCut" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    BlaBlaCut
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/Recent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Recent
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/awesome-data-prefetchers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Awesome Data Prefetchers
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/micro-2025/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MICRO 2025
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/dyn-lang-acc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Dynamic Language Acceleration
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#figure-1-the-sequence-of-assembly-instructions-inlined-into-the-processing-of-each-bytecode-instruction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 1: The sequence of assembly instructions inlined into the processing of each bytecode instruction.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-1-the-applications-and-the-components-they-stress" class="md-nav__link">
    <span class="md-ellipsis">
      
        Table 1: The applications and the component(s) they stress.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-2-relative-completion-times-for-various-language-implementations-normalized-to-optimized-code-under-gcc-note-the-logarithmic-scale-of-the-y-axis-la-refers-to-the-log-analysis-application-the-numbers-at-the-bottom-shows-the-benchmarks-absolute-execution-time-in-the-c-implementation-for-benchmarks-with-concurrency-the-best-bars-are-annotated-with-the-thread-count-that-results-in-best-completion-time-for-key-value-store-and-file-server-it-is-the-number-of-client-threads-not-the-number-of-threads-used-server-side-for-gcc-and-openjdk-the-server-creates-1-kernel-thread-to-handle-each-client-thread-so-the-number-of-server-side-threads-is-the-same-as-the-client-for-both-nodejs-and-cpython-their-best-completion-time-in-key-value-store-is-achieved-when-using-a-single-server-side-thread-due-to-their-scalability-characterstic-described-in-7-as-for-the-file-server-benchmark-both-nodejs-and-cpythons-best-performance-is-achieved-when-using-64-server-side-threads-7-the-number-of-server-side-threads-in-go-is-automatically-determined-by-the-runtime-as-described-in-82-the-number-of-threads-for-log-analysis-is-the-number-of-worker-threads-as-there-is-no-client" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 2: Relative completion times for various language implementations normalized to optimized code under GCC. Note the logarithmic scale of the y axis. “LA” refers to the log analysis application. The numbers at the bottom shows the benchmark’s absolute execution time in the C++ implementation. For benchmarks with concurrency, the “Best” bars are annotated with the thread count that results in best completion time. For key-value store and file server it is the number of client threads, not the number of threads used server side. For GCC and OpenJDK, the server creates 1 (kernel) thread to handle each client thread, so the number of server-side threads is the same as the client. For both Node.js and CPython, their best completion time in key-value store is achieved when using a single server-side thread (due to their scalability characterstic described in §7). As for the file server benchmark, both Node.js and CPython’s best performance is achieved when using 64 server-side threads (§7). The number of server-side threads in Go is automatically determined by the runtime as described in §8.2. The number of threads for log analysis is the number of worker threads (as there is no client).
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-3-checks-required-to-access-boardxy-in-v8nodejs" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 3: Checks required to access board[x][y] in V8/Node.js.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-2-we-modified-v8s-jit-compiler-and-removed-each-of-the-checks-performed-for-a-2d-array-access-to-boardxy-shown-in-figure-3-we-measured-the-resulting-execution-time-and-compare-it-against-the-default-execution-time-with-all-checks-we-also-show-the-execution-time-when-all-checks-are-removed" class="md-nav__link">
    <span class="md-ellipsis">
      
        Table 2: We modified V8’s JIT compiler and removed each of the checks performed for a 2D array access to board[x][y] shown in Figure 3. We measured the resulting execution time, and compare it against the default execution time with all checks. We also show the execution time when all checks are removed.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-4-code-showing-where-go-and-openjdk-perform-array-bounds-checking-when-accessing-boardxi-in-a-loop-table-3-statistics-for-array-access-bytecodes-bc-performed-by-various-interpreters-for-the-sudoku-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 4: Code showing where Go and OpenJDK perform array bounds checking when accessing board[x][i] in a loop. Table 3: Statistics for array access bytecodes (BC) performed by various interpreters for the sudoku benchmark.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-5-the-key-value-store-before-and-after-a-gc-pause-white-boxes-logically-represent-java-objects-and-the-shaded-boxes-represent-the-objects-location-in-the-jvm-heap-a-b-denotes-a-bucket-mapped-to-by-the-hash-function-and-an-n-denotes-a-node-in-the-buckets-linked-list-the-number-of-the-node-represents-the-order-they-are-inserted-into-the-hashtable-the-memory-for-the-nodes-of-the-bucket-begins-scattered-but-after-gc-relocation-is-ordered-by-the-traversal-of-the-buckets-linked-lists" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 5: The key-value store before and after a GC pause. White boxes logically represent Java objects, and the shaded boxes represent the objects’ location in the JVM heap. A ‘B’ denotes a bucket mapped to by the hash function, and an ‘N’ denotes a node in the bucket’s linked list. The number of the node represents the order they are inserted into the hashtable. The memory for the nodes of the bucket begins scattered, but after GC relocation is ordered by the traversal of the bucket’s linked lists.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-6-the-openjdk-single-threaded-key-value-store-benchmark-run-with-increasing-heap-sizes-corresponding-to-fewer-gc-cycles" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 6: The OpenJDK single threaded key-value store benchmark run with increasing heap sizes, corresponding to fewer GC cycles.
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#figure-7-relative-completion-time-and-peak-memory-usage-for-various-language-implementations-as-a-multiplicative-factor-compared-to-optimized-code-under-gcc-each-benchmark-uses-the-most-optimized-version-for-that-language-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Figure 7: Relative completion time and peak memory usage for various language implementations as a multiplicative factor compared to optimized code under GCC. Each benchmark uses the most optimized version for that language implementation.
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="investigating-managed-language-runtime-performance-why-javascript-and-python-are-8x-and-29x-slower-than-c-yet-java-and-go-can-be-faster">Investigating Managed Language Runtime Performance: Why JavaScript and Python are 8x and 29x slower than C++, yet Java and Go can be Faster? 图表详解<a class="headerlink" href="#investigating-managed-language-runtime-performance-why-javascript-and-python-are-8x-and-29x-slower-than-c-yet-java-and-go-can-be-faster" title="Permanent link">&para;</a></h1>
<h3 id="figure-1-the-sequence-of-assembly-instructions-inlined-into-the-processing-of-each-bytecode-instruction">Figure 1: The sequence of assembly instructions inlined into the processing of each bytecode instruction.<a class="headerlink" href="#figure-1-the-sequence-of-assembly-instructions-inlined-into-the-processing-of-each-bytecode-instruction" title="Permanent link">&para;</a></h3>
<p><img alt="85ff05ad0f7319d461425abd9875b38a6612f4aef500dd9a6c5c2df433f30632.jpg" src="../images/85ff05ad0f7319d461425abd9875b38a6612f4aef500dd9a6c5c2df433f30632.jpg" /></p>
<ul>
<li>该图展示了为测量字节码指令执行时间而内联到解释器中的 <strong>x86 汇编指令序列</strong>，核心目标是读取 CPU 的 <strong>时间戳计数器 (TSC)</strong>。</li>
<li>指令序列设计精巧，旨在最小化对被测代码性能的干扰，同时确保测量精度。</li>
<li>序列开头通过 <code>push</code> 指令保存 <code>rax</code>, <code>rcx</code>, <code>rdx</code> 寄存器，以避免破坏解释器原有的寄存器状态。</li>
<li>关键指令 <code>rdtscp</code> 被用于读取 TSC，它将 TSC 的低 32 位存入 <code>EAX</code>，高 32 位存入 <code>EDX</code>，并确保指令在所有 CPU 核心上同步。</li>
<li>由于 <code>rdtscp</code> 返回的是两个 32 位值，后续指令 <code>shlq rdx, 32</code> 和 <code>orq rax, rdx</code> 负责将高 32 位左移并与低 32 位合并，最终得到一个完整的 64 位 TSC 值，并存储在 <code>RAX</code> 中。</li>
<li>最后三行 <code>pop</code> 指令恢复之前保存的寄存器，保证解释器逻辑不受影响。</li>
<li>此序列会被嵌入到每个目标字节码指令处理逻辑的<strong>开始和结束处</strong>，通过计算两次 TSC 读数的差值来精确测量该指令的执行延迟。</li>
</ul>
<table>
<thead>
<tr>
<th>行号</th>
<th>指令</th>
<th>功能描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td><code>push rax</code></td>
<td>保存 RAX 寄存器值，防止被后续操作覆盖。</td>
</tr>
<tr>
<td>2</td>
<td><code>push rcx</code></td>
<td>保存 RCX 寄存器值。</td>
</tr>
<tr>
<td>3</td>
<td><code>push rdx</code></td>
<td>保存 RDX 寄存器值。</td>
</tr>
<tr>
<td>4</td>
<td><code>rdtscp</code></td>
<td>读取时间戳计数器 (TSC)，将高 32 位存入 EDX，低 32 位存入 EAX。</td>
</tr>
<tr>
<td>5</td>
<td><code>shlq rdx, 32</code></td>
<td>将 RDX 中的高 32 位左移 32 位，准备与低 32 位合并。</td>
</tr>
<tr>
<td>6</td>
<td><code>orq rax, rdx</code></td>
<td>将 RDX（已移位）与 RAX 进行按位或操作，合并高低 32 位，形成完整的 64 位 TSC。</td>
</tr>
<tr>
<td>7</td>
<td><code>movq dst, rax</code></td>
<td>将最终的 64 位 TSC 值移动到目标寄存器 <code>dst</code>。</td>
</tr>
<tr>
<td>8</td>
<td><code>pop rdx</code></td>
<td>恢复 RDX 寄存器原始值。</td>
</tr>
<tr>
<td>9</td>
<td><code>pop rcx</code></td>
<td>恢复 RCX 寄存器原始值。</td>
</tr>
<tr>
<td>10</td>
<td><code>pop rax</code></td>
<td>恢复 RAX 寄存器原始值。</td>
</tr>
</tbody>
</table>
<ul>
<li>该方法允许研究人员在不修改应用源代码的情况下，对运行时系统内部的字节码执行进行<strong>细粒度性能剖析</strong>，是论文中分析 OpenJDK、V8 等复杂运行时性能瓶颈的关键技术手段。</li>
</ul>
<h3 id="table-1-the-applications-and-the-components-they-stress">Table 1: The applications and the component(s) they stress.<a class="headerlink" href="#table-1-the-applications-and-the-components-they-stress" title="Permanent link">&para;</a></h3>
<p><img alt="fea8e74b1eb77bb72926ec06cbf6a306083d041e47616eebace92c6fc088944a.jpg" src="../images/fea8e74b1eb77bb72926ec06cbf6a306083d041e47616eebace92c6fc088944a.jpg" /></p>
<ul>
<li>该图片为 <strong>Table 1</strong>，标题为 “The applications and the component(s) they stress”，用于说明 LangBench 基准测试套件中六个应用所侧重的压力维度。</li>
<li>表格包含五列：<strong>Application</strong>（应用名称）、<strong>CPU</strong>（CPU 密集型）、<strong>Memory</strong>（内存密集型）、<strong>I/O</strong>（I/O 密集型）、<strong>Parallel</strong>（并行性）。</li>
<li>各应用压力分布如下：</li>
</ul>
<table>
<thead>
<tr>
<th>Application</th>
<th>CPU</th>
<th>Memory</th>
<th>I/O</th>
<th>Parallel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sudoku solver</td>
<td>✓</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>String sorting</td>
<td>✓</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Graph coloring</td>
<td>✓</td>
<td>✓</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Key-Value store</td>
<td></td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>Log analysis</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>File server</td>
<td></td>
<td></td>
<td>✓</td>
<td>✓</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Sudoku solver</strong> 和 <strong>String sorting</strong> 仅对 <strong>CPU</strong> 有显著压力，属于纯计算密集型任务。</li>
<li><strong>Graph coloring</strong> 同时施压 <strong>CPU</strong> 和 <strong>Memory</strong>，表明其算法涉及大量内存访问与计算。</li>
<li><strong>Key-Value store</strong>、<strong>Log analysis</strong> 和 <strong>File server</strong> 均涉及 <strong>I/O</strong> 操作，且后两者还支持 <strong>Parallel</strong> 并行执行。</li>
<li><strong>Log analysis</strong> 是唯一一个同时在 <strong>CPU、Memory、I/O</strong> 三方面均有压力的应用，体现其综合性。</li>
<li><strong>File server</strong> 虽无 CPU 或 Memory 标记，但因其处理大量文件读取，实际依赖 <strong>I/O</strong> 与 <strong>Parallel</strong> 扩展能力。</li>
<li>此表设计旨在覆盖不同资源瓶颈场景，确保 LangBench 能全面评估各语言运行时在多样化负载下的表现。</li>
</ul>
<h3 id="figure-2-relative-completion-times-for-various-language-implementations-normalized-to-optimized-code-under-gcc-note-the-logarithmic-scale-of-the-y-axis-la-refers-to-the-log-analysis-application-the-numbers-at-the-bottom-shows-the-benchmarks-absolute-execution-time-in-the-c-implementation-for-benchmarks-with-concurrency-the-best-bars-are-annotated-with-the-thread-count-that-results-in-best-completion-time-for-key-value-store-and-file-server-it-is-the-number-of-client-threads-not-the-number-of-threads-used-server-side-for-gcc-and-openjdk-the-server-creates-1-kernel-thread-to-handle-each-client-thread-so-the-number-of-server-side-threads-is-the-same-as-the-client-for-both-nodejs-and-cpython-their-best-completion-time-in-key-value-store-is-achieved-when-using-a-single-server-side-thread-due-to-their-scalability-characterstic-described-in-7-as-for-the-file-server-benchmark-both-nodejs-and-cpythons-best-performance-is-achieved-when-using-64-server-side-threads-7-the-number-of-server-side-threads-in-go-is-automatically-determined-by-the-runtime-as-described-in-82-the-number-of-threads-for-log-analysis-is-the-number-of-worker-threads-as-there-is-no-client">Figure 2: Relative completion times for various language implementations normalized to optimized code under GCC. Note the logarithmic scale of the y axis. “LA” refers to the log analysis application. The numbers at the bottom shows the benchmark’s absolute execution time in the C++ implementation. For benchmarks with concurrency, the “Best” bars are annotated with the thread count that results in best completion time. For key-value store and file server it is the number of client threads, not the number of threads used server side. For GCC and OpenJDK, the server creates 1 (kernel) thread to handle each client thread, so the number of server-side threads is the same as the client. For both Node.js and CPython, their best completion time in key-value store is achieved when using a single server-side thread (due to their scalability characterstic described in §7). As for the file server benchmark, both Node.js and CPython’s best performance is achieved when using 64 server-side threads (§7). The number of server-side threads in Go is automatically determined by the runtime as described in §8.2. The number of threads for log analysis is the number of worker threads (as there is no client).<a class="headerlink" href="#figure-2-relative-completion-times-for-various-language-implementations-normalized-to-optimized-code-under-gcc-note-the-logarithmic-scale-of-the-y-axis-la-refers-to-the-log-analysis-application-the-numbers-at-the-bottom-shows-the-benchmarks-absolute-execution-time-in-the-c-implementation-for-benchmarks-with-concurrency-the-best-bars-are-annotated-with-the-thread-count-that-results-in-best-completion-time-for-key-value-store-and-file-server-it-is-the-number-of-client-threads-not-the-number-of-threads-used-server-side-for-gcc-and-openjdk-the-server-creates-1-kernel-thread-to-handle-each-client-thread-so-the-number-of-server-side-threads-is-the-same-as-the-client-for-both-nodejs-and-cpython-their-best-completion-time-in-key-value-store-is-achieved-when-using-a-single-server-side-thread-due-to-their-scalability-characterstic-described-in-7-as-for-the-file-server-benchmark-both-nodejs-and-cpythons-best-performance-is-achieved-when-using-64-server-side-threads-7-the-number-of-server-side-threads-in-go-is-automatically-determined-by-the-runtime-as-described-in-82-the-number-of-threads-for-log-analysis-is-the-number-of-worker-threads-as-there-is-no-client" title="Permanent link">&para;</a></h3>
<p><img alt="9450525787ccf28f146f9a3dfe07b1bb89bd5a87c4bae5316ca9bf395d715802.jpg" src="../images/9450525787ccf28f146f9a3dfe07b1bb89bd5a87c4bae5316ca9bf395d715802.jpg" /></p>
<ul>
<li>
<p>图表展示了 LangBench 基准测试中五种语言实现（GCC、Go、OpenJDK、Node.js/V8、CPython）的完成时间，<strong>所有数据均以 GCC 优化版本为基准进行归一化</strong>，纵轴为对数刻度。</p>
</li>
<li>
<p><strong>CPython 在绝大多数基准测试中表现最差</strong>，完成时间远超其他语言，尤其在 Sort 和 Sudoku 等计算密集型任务中，其耗时可达 GCC 的数十倍甚至上百倍。</p>
</li>
<li>
<p><strong>Node.js/V8 性能次于 CPython</strong>，但在部分 I/O 密集型任务（如 File Server）中表现接近 GCC，说明其事件驱动模型在特定场景下有效。</p>
</li>
<li>
<p><strong>Go 和 OpenJDK 整体性能接近 GCC</strong>，平均仅慢 1.30x 和 1.43x，且在部分测试（如 Key-Value Store 单线程、Graph Coloring）中甚至优于 GCC。</p>
</li>
<li>
<p><strong>并发性能差异显著</strong>：Go 和 OpenJDK 能有效利用多核，随着线程数增加性能提升；而 Node.js 和 CPython 因设计限制（单线程事件循环/GIL），增加线程反而导致性能下降，最佳性能通常出现在单线程或少量线程配置。</p>
</li>
<li>
<p><strong>关键数据点</strong>：</p>
<ul>
<li>Sudoku：CPython 耗时是 GCC 的 <strong>129.66x</strong>，Node.js 为 <strong>8.01x</strong>，Go 为 <strong>1.30x</strong>，OpenJDK 为 <strong>1.43x</strong>。</li>
<li>Sort：CPython 耗时是 GCC 的 <strong>29.50x</strong>，Node.js 为 <strong>8.01x</strong>，Go 为 <strong>1.30x</strong>，OpenJDK 为 <strong>1.43x</strong>。</li>
<li>Key-Value Store（Best）：Go 在 256 线程下比 GCC 快 <strong>1.02x</strong>，OpenJDK 在 160 线程下接近 GCC，Node.js 和 CPython 最佳性能在 1 线程。</li>
<li>File Server（Best）：Go、OpenJDK、GCC 均在高并发下表现良好，Node.js 和 CPython 在 64 线程下达到最佳。</li>
</ul>
</li>
<li>
<p><strong>平均性能因子</strong>：</p>
<table>
<thead>
<tr>
<th>语言</th>
<th>平均完成时间因子</th>
</tr>
</thead>
<tbody>
<tr>
<td>GCC</td>
<td>1.00x</td>
</tr>
<tr>
<td>Go</td>
<td>1.30x</td>
</tr>
<tr>
<td>OpenJDK</td>
<td>1.43x</td>
</tr>
<tr>
<td>Node.js/V8</td>
<td>8.01x</td>
</tr>
<tr>
<td>CPython</td>
<td>29.50x</td>
</tr>
</tbody>
</table>
</li>
<li>
<p><strong>图表底部标注了每个基准测试在 GCC 下的绝对执行时间</strong>，便于理解相对性能的实际意义。例如，Sudoku 在 GCC 下仅需 0.715 秒，而 CPython 需要超过 90 秒。</p>
</li>
<li>
<p><strong>并发优化注释</strong>：对于支持并发的基准测试，“Best”柱状图上标注了达到最佳性能的线程数，这些数字反映了各语言运行时在并发调度上的不同策略和效率。</p>
</li>
</ul>
<h3 id="figure-3-checks-required-to-access-boardxy-in-v8nodejs">Figure 3: Checks required to access board[x][y] in V8/Node.js.<a class="headerlink" href="#figure-3-checks-required-to-access-boardxy-in-v8nodejs" title="Permanent link">&para;</a></h3>
<p><img alt="884c7dd4855e384cc178d18e827c550d18b4fc3b63ec67c4df6a098e33cc9958.jpg" src="../images/884c7dd4855e384cc178d18e827c550d18b4fc3b63ec67c4df6a098e33cc9958.jpg" /></p>
<ul>
<li>图片展示了在 <strong>V8/Node.js</strong> 运行时中，访问二维数组 <code>board[x][y]</code> 所需执行的完整类型与边界检查流程，共包含 <strong>11 个独立检查步骤</strong>。</li>
<li>整个流程分为两个主要阶段：<strong>第一维数组访问</strong>（<code>board[x]</code>）和<strong>第二维数组访问</strong>（<code>board[x][y]</code>），每个阶段都包含对象类型、形状、边界和空值检查。</li>
<li><strong>第一维访问</strong>（<code>board[x]</code>）的检查路径：<ul>
<li>首先确认 <code>board</code> 是一个 <strong>object</strong>（非整数）。</li>
<li>确认其内部 <strong>shape</strong> 为数组类型。</li>
<li>检查索引 <code>x</code> 是否为 <strong>int</strong> 类型。</li>
<li>执行 <strong>bounds check</strong>，确保 <code>x</code> 在数组长度范围内。</li>
<li>检查 <code>board[x]</code> 的值是否为 <strong>hole</strong>（稀疏数组中的未初始化位置），若是则转换为 <code>undefined</code>。</li>
</ul>
</li>
<li><strong>第二维访问</strong>（<code>board[x][y]</code>）重复上述逻辑：<ul>
<li>对 <code>board[x]</code> 的结果再次确认是 <strong>object</strong>。</li>
<li>确认其 <strong>shape</strong> 为数组。</li>
<li>检查索引 <code>y</code> 是否为 <strong>int</strong>。</li>
<li>执行 <strong>bounds check</strong>。</li>
<li>检查 <code>board[x][y]</code> 是否为 <strong>hole</strong>。</li>
</ul>
</li>
<li>最终，在所有检查通过后，系统确认 <code>board[x][y]</code> 是一个安全可用的 <strong>int</strong> 值，方可用于后续计算。</li>
<li>根据论文数据，这些检查在 Sudoku 基准测试中占 V8 总执行时间的 <strong>41.83%</strong>，是性能瓶颈的主要来源。</li>
<li>下表总结了移除不同检查对性能的影响：</li>
</ul>
<table>
<thead>
<tr>
<th>移除的检查项</th>
<th>性能提升幅度</th>
</tr>
</thead>
<tbody>
<tr>
<td>第一维的 object? 和 int? 检查</td>
<td>8.1%</td>
</tr>
<tr>
<td>所有检查（完全禁用）</td>
<td>8x 加速</td>
</tr>
</tbody>
</table>
<ul>
<li>论文指出，通过改用 <strong>packed arrays</strong>（如 <code>Int8Array</code>）可避免 hole 检查，使优化版 Sudoku 实现提速 <strong>1.48x</strong>。</li>
<li>此图直观揭示了动态类型语言在运行时为保证安全性所付出的巨大性能代价，也解释了为何静态类型语言（如 Go、Java）在此类操作上更高效。</li>
</ul>
<h3 id="table-2-we-modified-v8s-jit-compiler-and-removed-each-of-the-checks-performed-for-a-2d-array-access-to-boardxy-shown-in-figure-3-we-measured-the-resulting-execution-time-and-compare-it-against-the-default-execution-time-with-all-checks-we-also-show-the-execution-time-when-all-checks-are-removed">Table 2: We modified V8’s JIT compiler and removed each of the checks performed for a 2D array access to board[x][y] shown in Figure 3. We measured the resulting execution time, and compare it against the default execution time with all checks. We also show the execution time when all checks are removed.<a class="headerlink" href="#table-2-we-modified-v8s-jit-compiler-and-removed-each-of-the-checks-performed-for-a-2d-array-access-to-boardxy-shown-in-figure-3-we-measured-the-resulting-execution-time-and-compare-it-against-the-default-execution-time-with-all-checks-we-also-show-the-execution-time-when-all-checks-are-removed" title="Permanent link">&para;</a></h3>
<p><img alt="3aabc3024728493c3f8172a624453993134d912d237172c39d6d4abea4244c3f.jpg" src="../images/3aabc3024728493c3f8172a624453993134d912d237172c39d6d4abea4244c3f.jpg" /></p>
<ul>
<li>该表格（Table 2）展示了在 V8/Node.js 的 Sudoku 基准测试中，通过修改 JIT 编译器逐步移除对二维数组 <code>board[x][y]</code> 访问所执行的类型与边界检查后，程序执行时间的变化。</li>
<li>表格记录了六种不同代码版本的执行耗时（秒）及对应检查开销百分比，旨在量化动态类型检查对性能的具体影响。</li>
<li><strong>默认版本</strong>（Default）包含全部11项检查，执行时间为 <strong>2.369 秒</strong>，作为基准线。</li>
<li>逐步移除检查后，执行时间显著下降：<ul>
<li>移除对象/整数类型检查（1-2）：耗时降至 <strong>2.177 秒</strong>，开销占比 <strong>8.105%</strong>。</li>
<li>移除 Shape 检查（3）：耗时 <strong>2.219 秒</strong>，开销 <strong>6.332%</strong>。</li>
<li>移除边界检查（4）：耗时 <strong>2.154 秒</strong>，开销 <strong>9.076%</strong>。</li>
<li>移除 Hole 检查（5）：耗时 <strong>2.051 秒</strong>，开销 <strong>13.423%</strong> —— 此项开销最大。</li>
<li>移除所有检查（1-5）：耗时锐减至 <strong>1.378 秒</strong>，总检查开销高达 <strong>41.832%</strong>。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>Code Version</th>
<th>Time (s)</th>
<th>Overhead of Checks (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Default</td>
<td>2.369</td>
<td>–</td>
</tr>
<tr>
<td>1-2 Remove Obj./Int Checks</td>
<td>2.177</td>
<td>8.105</td>
</tr>
<tr>
<td>3 Remove Shape Check</td>
<td>2.219</td>
<td>6.332</td>
</tr>
<tr>
<td>4 Remove Bounds Check</td>
<td>2.154</td>
<td>9.076</td>
</tr>
<tr>
<td>5 Remove Hole Check</td>
<td>2.051</td>
<td>13.423</td>
</tr>
<tr>
<td>1-5 Remove All Checks</td>
<td>1.378</td>
<td>41.832</td>
</tr>
</tbody>
</table>
<ul>
<li>数据表明，在 V8 中，<strong>动态类型和边界检查是性能瓶颈的核心来源</strong>，尤其“Hole Check”贡献了最大单一项开销。</li>
<li>完全移除所有检查后，性能提升近 <strong>1.72x</strong>，证明若开发者能确保数据类型稳定（如使用 monotype），可极大释放 JIT 性能潜力。</li>
<li>此实验也揭示了 JavaScript 动态语义在高性能场景下的代价，以及通过底层运行时干预实现优化的可能性。</li>
</ul>
<h3 id="figure-4-code-showing-where-go-and-openjdk-perform-array-bounds-checking-when-accessing-boardxi-in-a-loop-table-3-statistics-for-array-access-bytecodes-bc-performed-by-various-interpreters-for-the-sudoku-benchmark">Figure 4: Code showing where Go and OpenJDK perform array bounds checking when accessing board[x][i] in a loop. Table 3: Statistics for array access bytecodes (BC) performed by various interpreters for the sudoku benchmark.<a class="headerlink" href="#figure-4-code-showing-where-go-and-openjdk-perform-array-bounds-checking-when-accessing-boardxi-in-a-loop-table-3-statistics-for-array-access-bytecodes-bc-performed-by-various-interpreters-for-the-sudoku-benchmark" title="Permanent link">&para;</a></h3>
<p><img alt="d3470b599b510a483f65bc1ddae16863852f47251d264a833f048da1002da936.jpg" src="../images/d3470b599b510a483f65bc1ddae16863852f47251d264a833f048da1002da936.jpg" /></p>
<ul>
<li>该图片为论文中的 <strong>Table 3</strong>，标题为“Statistics for array access bytecodes (BC) performed by various interpreters for the sudoku benchmark”，用于量化不同运行时在执行数独基准测试时，处理数组访问字节码（Bytecode）的性能开销。</li>
<li>表格数据揭示了 <strong>OpenJDK、Node.js 和 CPython</strong> 在解释器层面的性能差异，尤其体现在指令数（Insn. per BC）和周期数（Cycles per BC）两个维度上。</li>
<li><strong>OpenJDK</strong> 的性能表现最优，其汇编实现的 <code>aaload</code> 和 <code>iaload</code> 字节码分别仅需 <strong>12 条指令/7.7 周期</strong> 和 <strong>11 条指令/7.1 周期</strong>。这得益于其静态类型系统和针对特定数据类型的专用字节码。</li>
<li>OpenJDK 的 C++ 实现版本性能较差，<code>aaload</code> 需要 <strong>33 条指令/12.5 周期</strong>，<code>iaload</code> 需要 <strong>22 条指令/11.1 周期</strong>，表明手写汇编比 C++ 编译器生成的代码效率更高。</li>
<li><strong>Node.js (V8)</strong> 使用单一的 <code>LdaKeyedProperty</code> 字节码处理所有类型的键值访问，导致其开销显著增加，需要 <strong>90 条指令/26.3 周期</strong>。</li>
<li><strong>CPython</strong> 的性能最差，其 <code>BINARY_SUBSCR</code> 字节码需要 <strong>138 条指令/41.8 周期</strong>，是 V8 的约 1.5 倍，是 OpenJDK 汇编版本的近 6 倍。</li>
<li>数据对比清晰地说明了 <strong>静态类型与专用字节码设计</strong> 对于解释器性能的巨大优势，以及 <strong>动态类型语言</strong> 在通用字节码设计下所付出的高昂性能代价。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">运行时</th>
<th style="text-align: left;">Bytecode</th>
<th style="text-align: left;">Insn. per BC</th>
<th style="text-align: left;">Cycles per BC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>OpenJDK</strong></td>
<td style="text-align: left;">Assembly aaload</td>
<td style="text-align: left;"><strong>12</strong></td>
<td style="text-align: left;"><strong>7.7</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>OpenJDK</strong></td>
<td style="text-align: left;">Assembly iaload</td>
<td style="text-align: left;"><strong>11</strong></td>
<td style="text-align: left;"><strong>7.1</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>OpenJDK</strong></td>
<td style="text-align: left;">C++ aaload</td>
<td style="text-align: left;">33</td>
<td style="text-align: left;">12.5</td>
</tr>
<tr>
<td style="text-align: left;"><strong>OpenJDK</strong></td>
<td style="text-align: left;">C++ iaload</td>
<td style="text-align: left;">22</td>
<td style="text-align: left;">11.1</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Node.js</strong></td>
<td style="text-align: left;">LdaKeyedProperty</td>
<td style="text-align: left;">90</td>
<td style="text-align: left;">26.3</td>
</tr>
<tr>
<td style="text-align: left;"><strong>CPython</strong></td>
<td style="text-align: left;">BINARY_SUBSCR</td>
<td style="text-align: left;">138</td>
<td style="text-align: left;">41.8</td>
</tr>
</tbody>
</table>
<h3 id="figure-5-the-key-value-store-before-and-after-a-gc-pause-white-boxes-logically-represent-java-objects-and-the-shaded-boxes-represent-the-objects-location-in-the-jvm-heap-a-b-denotes-a-bucket-mapped-to-by-the-hash-function-and-an-n-denotes-a-node-in-the-buckets-linked-list-the-number-of-the-node-represents-the-order-they-are-inserted-into-the-hashtable-the-memory-for-the-nodes-of-the-bucket-begins-scattered-but-after-gc-relocation-is-ordered-by-the-traversal-of-the-buckets-linked-lists">Figure 5: The key-value store before and after a GC pause. White boxes logically represent Java objects, and the shaded boxes represent the objects’ location in the JVM heap. A ‘B’ denotes a bucket mapped to by the hash function, and an ‘N’ denotes a node in the bucket’s linked list. The number of the node represents the order they are inserted into the hashtable. The memory for the nodes of the bucket begins scattered, but after GC relocation is ordered by the traversal of the bucket’s linked lists.<a class="headerlink" href="#figure-5-the-key-value-store-before-and-after-a-gc-pause-white-boxes-logically-represent-java-objects-and-the-shaded-boxes-represent-the-objects-location-in-the-jvm-heap-a-b-denotes-a-bucket-mapped-to-by-the-hash-function-and-an-n-denotes-a-node-in-the-buckets-linked-list-the-number-of-the-node-represents-the-order-they-are-inserted-into-the-hashtable-the-memory-for-the-nodes-of-the-bucket-begins-scattered-but-after-gc-relocation-is-ordered-by-the-traversal-of-the-buckets-linked-lists" title="Permanent link">&para;</a></h3>
<p><img alt="fa792df5cb2c57349d056fcd7483cac43197c42d32b05c5f49fb82a841833a31.jpg" src="../images/fa792df5cb2c57349d056fcd7483cac43197c42d32b05c5f49fb82a841833a31.jpg" /></p>
<ul>
<li>图片展示了 JVM 在执行 <strong>Garbage Collection (GC)</strong> 前后，<strong>Hashtable</strong> 中链表节点在堆内存中的布局变化。</li>
<li>左侧图 (a) “Before GC” 显示初始状态：节点按插入顺序（N2, N1, N3, N4, N6, N5）分配在堆中，导致同一桶（B1, B2）内的节点物理地址<strong>高度分散</strong>，缺乏局部性。</li>
<li>右侧图 (b) “After GC” 显示 GC 后状态：JVM 的<strong>移动式垃圾回收器 (moving GC)</strong> 将存活对象复制到新区域，并按<strong>链表遍历顺序</strong>重新排列。例如，B1 桶的节点被重排为 B1:N2, B1:N3, B1:N6；B2 桶的节点被重排为 B2:N1, B2:N4, B2:N5。</li>
<li>这种重排显著改善了<strong>缓存局部性 (cache locality)</strong>。当程序遍历链表时，相邻节点更可能位于相邻或相近的内存页/缓存行中，从而减少缓存未命中。</li>
<li>该优化是 OpenJDK 在单线程 key-value store 基准测试中比 GCC 快 1.46x 的关键原因，尽管其循环内指令数更多。</li>
<li>此现象揭示了一个反直觉结论：<strong>更频繁的 GC 触发</strong>（通过设置较小堆空间实现）能带来更好的性能，因为它更频繁地整理内存，提升局部性。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">状态</th>
<th style="text-align: left;">节点物理布局</th>
<th style="text-align: left;">缓存局部性</th>
<th style="text-align: left;">性能影响</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Before GC</td>
<td style="text-align: left;">按插入顺序分散存储</td>
<td style="text-align: left;">差</td>
<td style="text-align: left;">遍历时缓存未命中率高，性能差</td>
</tr>
<tr>
<td style="text-align: left;">After GC</td>
<td style="text-align: left;">按链表遍历顺序紧凑存储</td>
<td style="text-align: left;">好</td>
<td style="text-align: left;">遍历时缓存命中率高，性能优</td>
</tr>
</tbody>
</table>
<ul>
<li>图中白色方框代表逻辑上的 Java 对象（如节点 N1），灰色方框代表它们在 JVM 堆中的实际物理位置。虚线箭头表示对象间的引用关系。</li>
</ul>
<h3 id="figure-6-the-openjdk-single-threaded-key-value-store-benchmark-run-with-increasing-heap-sizes-corresponding-to-fewer-gc-cycles">Figure 6: The OpenJDK single threaded key-value store benchmark run with increasing heap sizes, corresponding to fewer GC cycles.<a class="headerlink" href="#figure-6-the-openjdk-single-threaded-key-value-store-benchmark-run-with-increasing-heap-sizes-corresponding-to-fewer-gc-cycles" title="Permanent link">&para;</a></h3>
<p><img alt="9157f190a12855d901da31bc9b44db6395ad774465a813704029ae80b92d4b58.jpg" src="../images/9157f190a12855d901da31bc9b44db6395ad774465a813704029ae80b92d4b58.jpg" /></p>
<ul>
<li>图表展示了 OpenJDK 在单线程 key-value store 基准测试中，<strong>完成时间（Completion Time）</strong> 随 <strong>堆大小（Heap Size）</strong> 增加的变化趋势。</li>
<li>横轴为堆大小，从 128 MB 递增至 128 GB；纵轴为完成时间，单位为秒（s），范围从 160 s 至 400 s。</li>
<li>数据点显示，随着堆大小增加，完成时间总体呈上升趋势，尤其在堆大小超过 8 GB 后，增长速率显著加快。</li>
<li><strong>关键观察</strong>：当堆大小为 128 MB 时，完成时间约为 180 s；而当堆大小增至 128 GB 时，完成时间接近 370 s，<strong>性能下降近一倍</strong>。</li>
<li>这种现象源于 GC 行为：较小的堆会触发更频繁的 GC 周期，而频繁的 GC 会通过对象重定位改善内存局部性（cache locality），从而提升性能。</li>
<li>相反，大堆导致 GC 触发频率降低，对象在内存中保持初始分散布局，导致缓存命中率下降，进而拖慢执行速度。</li>
<li>图表直观验证了论文第 8.1 节的核心发现：<strong>GC 的移动特性可优化缓存局部性，反而使程序在小堆、高频 GC 下运行更快</strong>。</li>
</ul>
<table>
<thead>
<tr>
<th>堆大小 (Heap Size)</th>
<th>完成时间 (Completion Time, s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>128 MB</td>
<td>~180</td>
</tr>
<tr>
<td>256 MB</td>
<td>~175</td>
</tr>
<tr>
<td>512 MB</td>
<td>~195</td>
</tr>
<tr>
<td>1 GB</td>
<td>~195</td>
</tr>
<tr>
<td>2 GB</td>
<td>~195</td>
</tr>
<tr>
<td>4 GB</td>
<td>~195</td>
</tr>
<tr>
<td>8 GB</td>
<td>~205</td>
</tr>
<tr>
<td>16 GB</td>
<td>~230</td>
</tr>
<tr>
<td>32 GB</td>
<td>~280</td>
</tr>
<tr>
<td>64 GB</td>
<td>~360</td>
</tr>
<tr>
<td>128 GB</td>
<td>~370</td>
</tr>
</tbody>
</table>
<ul>
<li>此图是理解“<strong>GC 不仅不是纯开销，反而可能成为性能优化手段</strong>”的关键证据。</li>
</ul>
<h3 id="figure-7-relative-completion-time-and-peak-memory-usage-for-various-language-implementations-as-a-multiplicative-factor-compared-to-optimized-code-under-gcc-each-benchmark-uses-the-most-optimized-version-for-that-language-implementation">Figure 7: Relative completion time and peak memory usage for various language implementations as a multiplicative factor compared to optimized code under GCC. Each benchmark uses the most optimized version for that language implementation.<a class="headerlink" href="#figure-7-relative-completion-time-and-peak-memory-usage-for-various-language-implementations-as-a-multiplicative-factor-compared-to-optimized-code-under-gcc-each-benchmark-uses-the-most-optimized-version-for-that-language-implementation" title="Permanent link">&para;</a></h3>
<p><img alt="a18d7ab3bae98fe36c9ccc4e7009bee1415dc5ec6eb8523c6dd9a9f2e9e5ccdf.jpg" src="../images/a18d7ab3bae98fe36c9ccc4e7009bee1415dc5ec6eb8523c6dd9a9f2e9e5ccdf.jpg" /></p>
<ul>
<li>图表分为上下两部分，上半部分展示各语言实现的<strong>完成时间</strong>（Completion Time），下半部分展示<strong>峰值内存使用量</strong>（Peak Memory Usage），两者均以 GCC 为基准进行归一化处理。</li>
<li>完成时间采用对数刻度，单位为秒，数值越小表示性能越好；内存使用量采用线性刻度，数值越小表示内存效率越高。</li>
<li>图例中包含五种语言实现：<strong>GCC</strong>、<strong>Go</strong>、<strong>OpenJDK</strong>、<strong>Node.js/V8</strong>、<strong>CPython</strong>，以及一个“Min Memory Usage”条形图，代表在最小内存配置下运行时的完成时间。</li>
<li>横轴列出十二个 LangBench 基准测试，包括 Sudoku、Sort、Graph Iterative、Graph Recursive、Key-Value Store 1 Thread、Key-Value Store Best、LA Regex 1 Thread、LA Regex Best、LA Indexed 1 Thread、LA Indexed Best、File Server 1 Thread、File Server Best，最后是 Average Factor。</li>
</ul>
<table>
<thead>
<tr>
<th>基准测试</th>
<th>GCC 完成时间 (s)</th>
<th>Go 完成时间倍数</th>
<th>OpenJDK 完成时间倍数</th>
<th>Node.js/V8 完成时间倍数</th>
<th>CPython 完成时间倍数</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sudoku</td>
<td>0.715</td>
<td>~1.3x</td>
<td>~2.0x</td>
<td>~3.5x</td>
<td>~100x</td>
</tr>
<tr>
<td>Sort</td>
<td>8.295</td>
<td>~1.3x</td>
<td>~10.0x</td>
<td>~8.0x</td>
<td>~130x</td>
</tr>
<tr>
<td>Graph Iterative</td>
<td>19.175</td>
<td>~1.4x</td>
<td>~1.6x</td>
<td>~2.0x</td>
<td>~5.0x</td>
</tr>
<tr>
<td>Graph Recursive</td>
<td>18.572</td>
<td>~1.4x</td>
<td>~1.6x</td>
<td>~2.0x</td>
<td>~5.0x</td>
</tr>
<tr>
<td>Key-Value Store 1 Thread</td>
<td>281.978</td>
<td>~1.1x</td>
<td>~1.4x</td>
<td>~2.0x</td>
<td>~3.0x</td>
</tr>
<tr>
<td>Key-Value Store Best</td>
<td>38.091</td>
<td>~1.0x</td>
<td>~1.4x</td>
<td>~2.0x</td>
<td>~3.0x</td>
</tr>
<tr>
<td>LA Regex 1 Thread</td>
<td>143.319</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~2.0x</td>
</tr>
<tr>
<td>LA Regex Best</td>
<td>19.383</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~2.0x</td>
</tr>
<tr>
<td>LA Indexed 1 Thread</td>
<td>44.074</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~2.0x</td>
</tr>
<tr>
<td>LA Indexed Best</td>
<td>9.231</td>
<td>~0.9x</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~2.0x</td>
</tr>
<tr>
<td>File Server 1 Thread</td>
<td>63.012</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~1.0x</td>
</tr>
<tr>
<td>File Server Best</td>
<td>16.852</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~1.0x</td>
<td>~1.0x</td>
</tr>
<tr>
<td>Average Factor</td>
<td>—</td>
<td><strong>1.30x</strong></td>
<td><strong>1.43x</strong></td>
<td><strong>8.01x</strong></td>
<td><strong>29.50x</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>
<p><strong>完成时间分析</strong>：</p>
<ul>
<li><strong>Go</strong> 和 <strong>OpenJDK</strong> 性能接近 GCC，平均分别慢 1.30x 和 1.43x，部分场景甚至优于 GCC。</li>
<li><strong>Node.js/V8</strong> 平均慢 8.01x，主要瓶颈在于动态类型检查和解释器开销。</li>
<li><strong>CPython</strong> 平均慢 29.50x，最差情况（Sudoku）高达 100x 以上，主要因无 JIT 编译且解释器效率低下。</li>
<li>“Min Memory Usage” 条形图显示，在最小内存配置下，部分语言（如 OpenJDK 在 Sudoku 上）性能显著下降，表明内存与性能存在权衡。</li>
</ul>
</li>
<li>
<p><strong>峰值内存使用量分析</strong>：</p>
<ul>
<li>所有语言实现均比 GCC 使用更多内存，平均倍数分别为：<strong>Go 2.12x</strong>、<strong>OpenJDK 3.38x</strong>、<strong>Node.js/V8 3.70x</strong>、<strong>CPython 2.08x</strong>。</li>
<li><strong>OpenJDK</strong> 和 <strong>Node.js/V8</strong> 内存开销最大，尤其在 Sudoku 上分别达到 10.94x 和 10.0x。</li>
<li><strong>Go</strong> 在 Sudoku 上表现优异，仅用 0.59x 内存，源于其轻量级标准库和高效内存管理。</li>
<li><strong>CPython</strong> 内存效率相对较高，但仍在 Sort 上达到 4.06x 开销。</li>
</ul>
</li>
<li>
<p><strong>关键发现</strong>：</p>
<ul>
<li><strong>内存与性能权衡</strong>：为获得最佳性能，OpenJDK 和 Node.js/V8 需要大量堆内存，导致资源调度困难。</li>
<li><strong>Go 的优势</strong>：在多个基准测试中内存使用低于 GCC，且性能接近或优于 GCC，体现其高效设计。</li>
<li><strong>CPython 的局限</strong>：虽内存效率尚可，但性能严重落后，尤其在计算密集型任务中。</li>
<li><strong>V8 的优化空间</strong>：在正则表达式等特定场景下，V8 可与 GCC 性能持平，得益于其高效的内置库实现。</li>
</ul>
</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.sections", "navigation.top", "navigation.indexes", "search.suggest", "search.highlight", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
        <script src="../../../javascripts/switcher.js"></script>
      
        <script src="../../../javascripts/smart_back.js"></script>
      
    
  </body>
</html>