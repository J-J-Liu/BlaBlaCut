
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/notes_repo/titan-i-an-open-source-high-performance-risc-v-vector-core/ELI5_notes/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../../assets/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>Titan-I: An Open-Source, High Performance RISC-V Vector Core 通俗讲解 - BlaBlaCut</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="amber">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#titan-i-an-open-source-high-performance-risc-v-vector-core" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="BlaBlaCut" class="md-header__button md-logo" aria-label="BlaBlaCut" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BlaBlaCut
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Titan-I: An Open-Source, High Performance RISC-V Vector Core 通俗讲解
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="切换到深色模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换到深色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="切换到浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换到浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="BlaBlaCut" class="md-nav__button md-logo" aria-label="BlaBlaCut" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    BlaBlaCut
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/Recent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Recent
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/awesome-data-prefetchers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Awesome Data Prefetchers
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/micro-2025/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MICRO 2025
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#0" class="md-nav__link">
    <span class="md-ellipsis">
      
        0. 整体创新点通俗解读
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-coarse-grained-floor-planning-solver-eli5" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Coarse-Grained Floor-Planning Solver (ELI5)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-datapath-wide-permutation-unit-eli5" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Datapath-Wide Permutation Unit (ELI5)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-shadow-cache-for-mask-register-v0-eli5" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Shadow Cache for Mask Register (v0) (ELI5)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-fine-grained-chaining-microarchitecture-eli5" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Fine-Grained Chaining Microarchitecture (ELI5)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-issue-as-commit-for-scalar-vector-ooo-execution-eli5" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Issue-as-Commit for Scalar-Vector OoO Execution (ELI5)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-dual-lsu-with-memory-interleaving-and-delay-slots-eli5" class="md-nav__link">
    <span class="md-ellipsis">
      
        6. Dual LSU with Memory Interleaving and Delay Slots (ELI5)
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="titan-i-an-open-source-high-performance-risc-v-vector-core">Titan-I: An Open-Source, High Performance RISC-V Vector Core 通俗讲解<a class="headerlink" href="#titan-i-an-open-source-high-performance-risc-v-vector-core" title="Permanent link">&para;</a></h1>
<h3 id="0">0. 整体创新点通俗解读<a class="headerlink" href="#0" title="Permanent link">&para;</a></h3>
<p><strong>痛点直击 (The "Why")</strong></p>
<p>现代的向量处理器（Vector Processor）正处在一个尴尬的境地。一方面，像 <strong>GP-GPU</strong> 这样的设备虽然算力强大，但它们的 <strong>SIMT</strong> 编程模型极其复杂，程序员得操心 warp、shared memory 对齐这些底层细节，而且其控制逻辑（成千上万个线程前端）非常臃肿，浪费了大量面积和功耗。另一方面，传统的 <strong>OoO CPU</strong> 核心为了挖掘 <strong>ILP</strong>（指令级并行），塞满了庞大的 <strong>ROB</strong>（重排序缓冲区）、复杂的分支预测器和一致性协议，这些“投机”开销在处理结构化、高并行的向量负载时显得笨重且低效。</p>
<ul>
<li>现有的 **RISC-V Vector **(RVV) 实现，比如 <strong>SpacemiT X60</strong> 或 <strong>SiFive P870</strong>，要么受限于 <strong>flip-flop</strong> 寄存器文件而无法扩展 <strong>VLEN</strong>（向量长度）和 <strong>DLEN</strong>（数据通路宽度），要么像 <strong>ETH's Ara</strong> 那样干脆放弃了 <strong>ILP</strong>，变成了一个简单的 in-order 流水线，导致硬件利用率低下。</li>
<li>当你试图把 <strong>DLEN</strong> 做宽（比如 1024-bit 甚至更宽）来提升 <strong>DLP</strong>（数据级并行）时，会立刻撞上两堵墙：一是 <strong>跨 Lane 数据路由</strong>（尤其是 permutation 指令）会产生巨大的延迟和布线拥塞；二是 **mask register **(v0) 的广播需求会让所有 Lane 互相争抢带宽，形成瓶颈。</li>
<li>更要命的是，即使你有了超宽的数据通路，如果缺乏精细的 <strong>ILP</strong> 调度能力，一条长向量指令就会独占整个核心几百甚至上千个周期，后面的指令只能干等着，硬件资源被严重浪费。</li>
</ul>
<p>简而言之，业界缺少一个既能像 GPU 一样高效处理海量数据，又能像 CPU 一样聪明地乱序执行、榨干硬件利用率，并且还保持 RVV 简洁编程模型的“两全其美”的设计。</p>
<hr />
<p><strong>通俗比方 (The Analogy)</strong></p>
<p>想象你要在一个巨大的仓库（<strong>VRF</strong>, Vector Register File）里处理成吨的货物（<strong>vector elements</strong>）。这个仓库被划分成很多个独立的区域（<strong>Lanes</strong>）。</p>
<ul>
<li><strong>GP-GPU 的做法</strong>就像是雇了几千个工人（threads），每人负责一小堆货。但协调这几千人需要一个庞大的调度中心（warp scheduler），而且工人们经常因为要拿同一排货架上的东西而打架（bank conflict），效率并不高。</li>
<li><strong>传统 OoO CPU 的做法</strong>则像是只有一个超级工人，但他脑子里记着一张巨复杂的任务清单（ROB），时刻想着下一步该做什么、会不会出错。处理小包裹很灵活，但面对一整集装箱的同质货物时，他那套复杂的思考流程反而成了累赘。</li>
</ul>
<p>**Titan-I **(T1) 的思路完全不同。它更像是建立了一套高度自动化的智能物流系统：</p>
<ol>
<li>它把仓库（VRF）本身设计得非常高效，并且给每个区域（Lane）配备了专用的、可并行工作的机器人（VFUs）。</li>
<li>为了解决跨区域调货（permutation）的难题，它没有让机器人自己跑来跑去，而是在仓库中央建了一个超高速的 **分拣中心 **(Permutation Unit)，所有需要重组的货物都通过传送带送到这里，瞬间完成重新打包和分发。</li>
<li>为了防止每次发货都要广播通知所有区域（mask broadcast），它在分拣中心旁边设了一个 **mask 缓存 **(Shadow Mask v0)，任何区域需要 mask 信息时直接去缓存拿就行，不用再惊动整个仓库。</li>
<li>最关键的是，它的调度系统（Sequencer + Scoreboards）非常聪明，能将一连串相关的任务（比如 load -&gt; compute -&gt; store）像流水线一样 **精细地拆解和重叠 **(fine-grained chaining)，让不同区域的机器人可以同时处理任务的不同阶段，而不是傻等上一个任务完全结束。</li>
</ol>
<p><img alt="" src="../images/8e182bd2d0d71541e047f16294d69aa3d3923d4b22e4c7793877fbe9c78d3caa.jpg" /></p>
<p><em>Figure 3: Architecture of T1</em></p>
<hr />
<p><strong>关键一招 (The "How")</strong></p>
<p>作者并没有从零开始造一个全新的轮子，而是在经典的 <strong>lane-based</strong> 向量架构基础上，精准地插入了几个关键的“微创新”，一举打通了 <strong>ILP</strong> 和 <strong>DLP</strong> 的任督二脉。</p>
<ul>
<li>
<p><strong>为 DLP 扫清障碍</strong>:</p>
<ul>
<li><strong>Datapath-wide Permutation Unit</strong>: 用一个专用的、与数据通路同宽的硬件单元来处理所有 permutation 操作，彻底绕开了跨 Lane 路由的性能悬崖。</li>
<li><strong>Shadow Mask v0</strong>: 将分布式的 mask register <code>v0</code> 在 permutation unit 中做一份缓存，消除了 predicated execution 时的全局广播瓶颈。</li>
<li><strong>Coarse-grained Floor-planning Solver</strong>: 通过一个启发式布局算法，优化物理上 Lane 的摆放位置，最小化 widen/narrow 等操作中最坏情况下的跨 Lane 延迟。</li>
</ul>
</li>
<li>
<p><strong>为 ILP 注入灵魂</strong>:</p>
<ul>
<li><strong>Fine-grained Chaining</strong>: 这是最核心的一招。T1 的依赖追踪不是以整个向量寄存器为单位，而是细化到 <strong>ELEN × ScaleFactor</strong> 的粒度。这意味着，只要一个向量中的一部分元素计算完成了，后续依赖这些元素的指令就可以立即开始执行，而不用等整个向量都算完。这极大地提升了硬件的并发利用率。</li>
<li><strong>Issue-as-commit for Scalar-Vector OoO</strong>: 允许标量和向量流水线在没有真实数据依赖的情况下各自独立前进。向量指令一旦发出（issue），标量核心就认为它已经提交（commit），可以继续执行后续的标量指令，从而避免了不必要的停顿。</li>
<li><strong>Memory Interleaving &amp; Delay Slots</strong>: 通过分离的 Load/Store 单元和冲突检测表（CRT），允许不冲突的 load 和 store 指令同时进行；对于高延迟的 indexed access，则利用 delay slot 让独立的计算指令在其后并发执行，有效隐藏了内存延迟。</li>
</ul>
</li>
</ul>
<p>正是这些看似微小但极其精准的设计，让 T1 能够在 <strong>40%</strong> 的面积下击败 <strong>Nvidia 3090/5090</strong>，并在 HPC 负载上展现出远超现有 RVV 核心的性能和能效。它证明了，在正确的微架构设计下，一个开放的、可编程的向量核心完全可以成为 GP-GPU 在特定领域的一个强大替代品。</p>
<h3 id="1-coarse-grained-floor-planning-solver-eli5">1. Coarse-Grained Floor-Planning Solver (ELI5)<a class="headerlink" href="#1-coarse-grained-floor-planning-solver-eli5" title="Permanent link">&para;</a></h3>
<p><strong>痛点直击</strong></p>
<ul>
<li>在传统的 <strong>lane-based</strong> 向量处理器设计中，当数据需要在不同 <strong>Lane</strong> 之间移动时（比如执行 <strong>widen</strong> 或 <strong>narrow</strong> 指令），物理布线就成了大问题。想象一下，如果32个 <strong>Lane</strong> 像棋盘一样简单地从左到右、从上到下排列，那么位于对角线两端的 <strong>Lane</strong>（比如 <strong>Lane 3</strong> 和 <strong>Lane 17</strong>）要通信，信号就得横穿整个芯片。</li>
<li>这种“最坏情况”下的长距离通信会带来巨大的 <strong>延迟</strong> 和 <strong>功耗</strong>，并且会成为整个设计的性能瓶颈。随着 <strong>DLEN</strong>（数据通路宽度）和 <strong>Lane</strong> 数量的增加，这个问题会指数级恶化，最终让设计师不敢再扩大规模。</li>
</ul>
<p><strong>通俗比方</strong></p>
<ul>
<li>这就像规划一个大型物流仓库。如果你把所有货架（<strong>Lane</strong>）按顺序一排排摆好，那么从A区最左边取货送到Z区最右边，叉车（数据信号）就得跑完整个仓库，效率极低。</li>
<li>一个好的仓库经理（<strong>Coarse-Grained Floor-Planning Solver</strong>）不会这么干。他会把经常需要互相调货的区域（比如处理相同类型数据的 <strong>Lane</strong>）尽量安排在一起，形成一个个小集群。这样，大部分内部调货都在小范围内完成，只有少数跨集群的调货才需要跑远路，从而大大降低了平均和最坏情况下的运输时间。</li>
</ul>
<p><img alt="" src="images/5f5b8c9d4e3a2f1b0c9d8e7f6a5b4c3d2e1f0a9b8c7d6e5f4a3b2c1d0e9f8a7.jpg" /></p>
<p><em>图：论文中的 </em><em>Figure 5</em><em> 清晰地展示了这一点。左边是“</em><em>Trivial Floorplan</em><em>”（朴素布局），最大通信延迟高达 </em><em>7</em><em> 个单位；右边是他们的“</em><em>Novel Floorplan</em><em>”（新式布局），通过智能摆放，将最大延迟降到了 </em><em>4</em><em> 个单位。</em></p>
<p><strong>关键一招</strong></p>
<ul>
<li>作者没有采用计算复杂度极高的全局最优算法（那在工程上不现实），而是设计了一个聪明的 <strong>启发式（heuristic）求解器</strong>。</li>
<li>这个求解器的核心逻辑是：<ul>
<li>它知道哪些 <strong>Lane</strong> 对之间通信最频繁（比如执行 <strong>widen/narrow</strong> 时，<code>i</code> 号 <strong>Lane</strong> 需要和 <code>(2i mod n)</code> 及 <code>(2i+1 mod n)</code> 号 <strong>Lane</strong> 通信）。</li>
<li>在放置一个新的 <strong>Lane</strong> 时，如果它已经有邻居被放置了，求解器就把它放在能 <strong>最小化到这些已放置邻居的最大距离</strong> 的位置上。</li>
<li>如果还没有邻居，就随机放在现有布局的旁边。</li>
</ul>
</li>
<li>通过这种 <strong>局部优化驱动全局布局</strong> 的策略，它用很低的计算成本，就找到了一个能让 <strong>最坏情况路由距离</strong> 显著缩短的物理布局方案，从而直接将 <strong>widen/narrow</strong> 操作的延迟降低了近 <strong>20%</strong>。</li>
</ul>
<h3 id="2-datapath-wide-permutation-unit-eli5">2. Datapath-Wide Permutation Unit (ELI5)<a class="headerlink" href="#2-datapath-wide-permutation-unit-eli5" title="Permanent link">&para;</a></h3>
<p><strong>痛点直击</strong></p>
<ul>
<li>在传统的 <strong>lane-based</strong> 向量处理器里，做 <strong>permutation</strong>（比如 <code>VRGATHER</code>、<code>VCOMPRESS</code>）是个老大难问题。因为数据是分散在各个 <strong>lane</strong> 里的，要重组就得跨 <strong>lane</strong> 搬运。</li>
<li>最朴素的办法是什么？把数据从所有 <strong>lane</strong> 的 <strong>VRF</strong>（向量寄存器堆）里读出来，写到一块共享的 <strong>local memory</strong> 里，排好队再读回去。这叫 <strong>memory-swap emulation</strong>。</li>
<li>这个过程有多“难受”？<ul>
<li><strong>性能杀手</strong>：一次 <strong>permutation</strong> 变成了两次昂贵的 <strong>VRF</strong> 读写外加一次 <strong>local memory</strong> 访问，<strong>latency</strong> 飞涨。</li>
<li><strong>带宽黑洞</strong>：宝贵的 <strong>VRF</strong> 和 <strong>local memory</strong> 带宽被这种“内部调度”给占满了，真正的计算指令只能干等着。</li>
<li><strong>扩展性差</strong>：<strong>lane</strong> 越多，跨 <strong>lane</strong> 通信越复杂，这个瓶颈就越严重，直接限制了 <strong>DLEN</strong>（数据通路宽度）的扩展。</li>
</ul>
</li>
</ul>
<p><strong>通俗比方</strong></p>
<ul>
<li>想象一个大型物流仓库（<strong>VRF</strong>），被分成了很多个独立的区域（<strong>lane</strong>）。现在你需要把散落在各个区域的包裹（<strong>vector elements</strong>）按照一个新的订单（<strong>permutation pattern</strong>）重新打包。</li>
<li>旧方法就像：让每个区域的工人先把包裹搬到中央分拣大厅（<strong>local memory</strong>），等所有包裹都到齐了，再由另一批工人按新订单重新分拣，最后送回各个区域。整个过程慢、占地、还容易堵。</li>
<li><strong>Titan-I</strong> 的 <strong>Datapath-Wide Permutation Unit</strong> 相当于在仓库内部架设了一套<strong>全自动、全覆盖的空中传送带系统</strong>（<strong>crossbar</strong>）。这套系统能直接连通任意两个区域，包裹可以在区域内直接通过传送带飞到目标区域，完全不需要经过中央大厅。整个过程又快又高效，还不占用地面空间。</li>
</ul>
<p><strong>关键一招</strong></p>
<ul>
<li>作者没有去优化那个低效的“搬进搬出”流程，而是<strong>从根本上绕开了它</strong>。</li>
<li>他们在芯片物理布局的中心位置，<strong>硬生生地塞进去一个与整个数据通路同宽（DLEN-sized）的 crossbar 开关矩阵</strong>，这就是 <strong>Permutation Unit</strong>。</li>
<li>这个单元如何工作？<ul>
<li>当一条 <strong>permutation</strong> 指令到来时，<strong>Sequencer</strong> 会通知所有 <strong>lane</strong> 准备好它们的数据。</li>
<li>所有 <strong>lane</strong> 同时将数据发送到这个中央 <strong>Permutation Unit</strong>。</li>
<li><strong>Permutation Unit</strong> 内部的 <strong>crossbar</strong> 根据指令要求（静态或动态的索引），<strong>在一个周期内</strong>就完成了所有数据的重排和路由。</li>
<li>重排后的数据直接从 <strong>Permutation Unit</strong> 广播回各个 <strong>lane</strong>。</li>
</ul>
</li>
<li>这个设计的精妙之处在于：<ul>
<li><strong>原生支持</strong>：把 <strong>permutation</strong> 从一个需要多次内存访问的“软件模拟”操作，变成了一个<strong>单周期硬件原语</strong>。</li>
<li><strong>带宽无损</strong>：数据只在 <strong>lane</strong> 和 <strong>Permutation Unit</strong> 之间流动一次，<strong>VRF</strong> 和 <strong>local memory</strong> 的带宽得以完全释放给计算任务。</li>
<li><strong>可扩展</strong>：通过增加 <strong>crossbar</strong> 的流水线级数，可以很好地控制其延迟和面积开销，使其能随着 <strong>DLEN</strong> 的增大而线性扩展，如</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/46a530743c1b53db2bcd8a0209fb28091509950010deb733536533ab34d1b06c.jpg" /></p>
<p><em>(a) VLEN</em></p>
<p>(b) 所示。</p>
<h3 id="3-shadow-cache-for-mask-register-v0-eli5">3. Shadow Cache for Mask Register (v0) (ELI5)<a class="headerlink" href="#3-shadow-cache-for-mask-register-v0-eli5" title="Permanent link">&para;</a></h3>
<p><strong>痛点直击</strong></p>
<ul>
<li>在传统的 <strong>lane-based</strong> RISC-V Vector 设计中，<strong>mask register (v0)</strong> 被物理地切分并<strong>均匀分布</strong>到所有 <strong>Lane</strong> 上。</li>
<li>当一条 <strong>predicated instruction</strong>（带掩码的指令）需要使用 <strong>v0</strong> 时，它往往需要从<strong>多个不同的 Lane</strong> 中实时收集对应的掩码位。例如，处理一个 32-bit 元素可能需要从 3 个甚至 4 个 Lane 里“拼凑”出完整的掩码信息。</li>
<li>这种跨 Lane 的数据请求会产生海量的<strong>点对点广播流量</strong>，在 Lane 数量很多（即 <strong>DLEN</strong> 很宽）时，会瞬间<strong>塞爆片上互连网络</strong>，形成严重的性能瓶颈，也就是论文里说的 “<strong>wiring bottleneck</strong>”。</li>
</ul>
<p><strong>通俗比方</strong></p>
<ul>
<li>想象一下，你是一家大型连锁超市（Vector Core）的经理，要给所有分店（Lane）发一个“今日特价商品清单”（mask v0）。</li>
<li>旧方法是：每当某个分店要搞促销（执行 predicated instruction），它就得打电话给总部，然后总部再挨个问其他所有分店：“你们那部分清单是什么？”，最后把信息拼起来告诉它。这个过程极其低效，电话线（片上互连）全被占满了。</li>
<li>T1 的做法是：总部（Permutation Unit）自己维护一份<strong>完整、最新的特价清单副本</strong>（Shadow Cache）。任何分店需要时，直接找总部拿就行，<strong>避免了分店之间互相打电话骚扰</strong>，整个系统流畅多了。</li>
</ul>
<p><strong>关键一招</strong></p>
<ul>
<li>作者没有改变 mask register 的物理分布方式，而是在 <strong>Permutation Unit</strong> 这个中心枢纽里，增加了一个专门的 <strong>Shadow Mask (v0) Cache</strong>。</li>
<li>这个缓存会<strong>被动地</strong>被各个 Lane 更新：当任何一条指令修改了 <strong>v0</strong> 的一部分，对应的 Lane 就会通过一个专用的数据通道，将更新同步到 Permutation Unit 的 Shadow Cache 里。</li>
<li>同时，<strong>Sequencer</strong>（调度器）扮演了“交通警察”的角色，它会跟踪所有对 <strong>v0</strong> 的写操作，确保在所有 pending 的写操作完成之前，依赖 <strong>v0</strong> 的新指令不会被执行，从而保证了数据一致性。</li>
<li>通过这个设计，所有需要读取 <strong>v0</strong> 的指令都变成了<strong>本地读取</strong>（从 Permutation Unit 到自己的 Lane），彻底<strong>消除了跨 Lane 的广播风暴</strong>。论文提到，这能减少高达 <strong>4 × VLEN/ELEN</strong> 次的 VRF 读操作，从而将带宽提升了约 <strong>50%</strong>，而面积开销仅为 <strong>8%</strong>。</li>
</ul>
<p><img alt="" src="../images/46a530743c1b53db2bcd8a0209fb28091509950010deb733536533ab34d1b06c.jpg" /></p>
<p><em>(a) VLEN</em></p>
<h3 id="4-fine-grained-chaining-microarchitecture-eli5">4. Fine-Grained Chaining Microarchitecture (ELI5)<a class="headerlink" href="#4-fine-grained-chaining-microarchitecture-eli5" title="Permanent link">&para;</a></h3>
<p><strong>痛点直击</strong></p>
<ul>
<li>传统的向量处理器在处理长向量时，就像一条僵硬的流水线：一个指令必须等前一个指令把<strong>整个</strong>超宽结果（可能几千位）完全写回 <strong>VRF (Vector Register File)</strong> 后，自己才能开始。这造成了两个“很难受”的问题：<ul>
<li><strong>巨大的延迟气泡</strong>：即使新指令只依赖旧指令结果的一小部分，也得干等着全部写完。</li>
<li><strong>VRF 带宽浪费</strong>：VRF 的读写端口很宽，但因为写入是“整块”进行的，无法被后续不相关的、只需要部分数据的指令充分利用，导致硬件资源闲置。</li>
</ul>
</li>
</ul>
<p><strong>通俗比方</strong></p>
<ul>
<li>想象你在组装一台复杂的机器，需要用到一个由100个零件组成的大型预制模块A。传统做法是：工人1必须把模块A的<strong>所有100个零件</strong>都放到工作台上并固定好后，工人才能开始用其中的几个零件去组装下一个模块B。</li>
<li><strong>Fine-Grained Chaining</strong>的做法则聪明得多：工作台被划分成很多小格子（对应 <strong>lane datapath granularity</strong>）。工人1每放好一个零件到对应的小格子里，系统就立刻通知所有等待的工人：“嘿，A模块的第5号零件好了！”。如果工人2正好需要这个零件，他就可以立刻拿走开工，根本不用等剩下的99个零件。这就像是把一个笨重的整体交接，拆解成了灵活的、按需的“零件级”交接。</li>
</ul>
<p><strong>关键一招</strong></p>
<ul>
<li>作者并没有改变向量指令的基本执行流程，而是在 <strong>VRF 写回阶段</strong>和<strong>指令调度逻辑</strong>之间，巧妙地插入了一个<strong>细粒度的依赖追踪器</strong>（即文中提到的 <strong>Chaining Scoreboard</strong>）。<ul>
<li>这个追踪器不再以“整个向量寄存器”为单位记录写完成状态，而是将其拆分成更小的块（<strong>ELEN × ScaleFactor-bit</strong>，例如64位或128位）。</li>
<li>当一个向量指令的部分结果（比如某个 lane 的计算结果）准备好后，它会立即更新追踪器中对应小块的状态为“可用”。</li>
<li>调度器在派发后续指令时，会检查其所有输入依赖的小块是否都已“可用”。只要满足，该指令就可以<strong>立即启动</strong>，甚至可以在前一个指令的其他部分还在计算时就开始执行。</li>
<li>这直接实现了 <strong>Out-of-Order Writebacks</strong>，让 VRF 的多个读写端口能被不同指令的、不相关的数据块同时使用，从而<strong>最大化 VRF 带宽利用率</strong>。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/8e182bd2d0d71541e047f16294d69aa3d3923d4b22e4c7793877fbe9c78d3caa.jpg" /></p>
<p><em>Figure 3: Architecture of T1</em></p>
<p>这种设计的核心思想就是“<strong>化整为零，按需供给</strong>”，将粗粒度的、阻塞式的向量处理，转变为细粒度的、流水线式的高效协作，从根本上解决了长向量处理中的延迟和带宽瓶颈问题。</p>
<h3 id="5-issue-as-commit-for-scalar-vector-ooo-execution-eli5">5. Issue-as-Commit for Scalar-Vector OoO Execution (ELI5)<a class="headerlink" href="#5-issue-as-commit-for-scalar-vector-ooo-execution-eli5" title="Permanent link">&para;</a></h3>
<p><strong>痛点直击 (The "Why")</strong></p>
<ul>
<li>传统的 <strong>Scalar-Vector OoO Execution</strong> 模型里，<strong>scalar core</strong> 和 <strong>vector core</strong> 虽然物理上分开，但逻辑上耦合得很死。只要 vector pipeline 开始干活，scalar core 就得在旁边干等着，直到这个 vector 指令<strong>完全执行完、写回寄存器、正式 commit</strong> 之后，scalar core 才敢继续。</li>
<li>这种“全有或全无”的等待策略非常低效。因为大部分 vector 指令（比如 <code>vadd.vv</code>）根本不会修改 scalar registers 或影响控制流，它们只是在自己的 <strong>VRF (Vector Register File)</strong> 里捣鼓数据。让 scalar core 为这种“井水不犯河水”的操作白白 stall 几十个甚至上百个周期，简直是巨大的资源浪费。</li>
<li>简单说，痛点就是：<strong>不必要的序列化</strong>。系统明明有足够的并行能力（scalar 和 vector 的功能单元都闲着），却被一个过于保守的提交模型给锁死了。</li>
</ul>
<p><strong>通俗比方 (The Analogy)</strong></p>
<ul>
<li>想象你和你的同事在一个开放式办公室里工作。你的任务是处理一堆文件（scalar work），他的任务是用一台大型打印机批量打印图纸（vector work）。</li>
<li>旧的做法是：只要他按下“开始打印”按钮，你就必须立刻放下手里的所有活，站在他旁边盯着打印机，直到最后一张纸吐出来、他签完字确认无误（commit）后，你才能回去干自己的事。这显然很蠢，因为你俩的工作完全不冲突。</li>
<li><strong>Issue-as-Commit</strong> 的做法是：他一按下“开始打印”按钮（issue），你就知道“哦，他要忙一阵子了，但这事儿跟我没关系”，于是你立刻回到自己工位继续处理文件。同时，办公室里有个简单的白板（<strong>compact scoreboards</strong>）记录着“打印机任务已启动，预计还需要X分钟”。只有当他打印的图纸里包含了你需要签字的封面页（即 vector 指令真的要写 scalar register 时），你才会被通知暂停一下。这就是高效的并行协作。</li>
</ul>
<p><strong>关键一招 (The "How")</strong></p>
<ul>
<li>作者没有改变整个 OoO 引擎的核心，而是巧妙地<strong>重新定义了 vector 指令的“提交”时刻</strong>。</li>
<li><strong>核心逻辑转换</strong>：对于绝大多数只在 VRF 内部操作的 vector 指令，它们的“提交”不再是等到写回完成，而是在它们被成功分发（<strong>issue</strong>）到 vector pipeline 的那一刻就算完成了。</li>
<li>为了支撑这个大胆的假设，作者引入了一个轻量级的 <strong>vector scoreboard</strong>。这个 scoreboard 不负责追踪复杂的依赖关系，它的唯一作用就是告诉 scalar core：“放心，这个 vector 指令已经安全地进入流水线了，它不会影响你，你可以继续往前跑”。</li>
<li>当然，这个策略有例外。如果一个 vector 指令确实需要写 scalar register（比如 <code>vmv.x.s</code>）或者可能抛出异常，那么它还是会走传统的、更严格的提交流程，确保正确性。但对于占绝大多数的纯 vector 计算指令，这个“<strong>issue-as-commit</strong>”的策略极大地解放了 scalar core，让它能与 vector core 真正地 <strong>overlap execution</strong>，从而显著提升了整体吞吐量。正如文中所说，这套机制只给 scalar core 增加了约 <strong>3%</strong> 的面积开销，却换来了巨大的性能收益。</li>
</ul>
<p><img alt="" src="../images/60122021119a97f1361bb7dfdeba64da96d256850b9ec88b66255c7d3c530fac.jpg" /></p>
<p><em>Figure 6: Different ILP Technology in T1. Chaining interleaves V0, V1, and V2. Memory Interleaving mitigates the VSW-VLD dependency. Vector-Scalar OoO interleaves the vector and scalar pipelines until a true dependency v16-s64-v15 occurs. Memory Delay Slot parallelizes vector index load/store (VIDX0) with independent vector executions (VEX0).</em></p>
<h3 id="6-dual-lsu-with-memory-interleaving-and-delay-slots-eli5">6. Dual LSU with Memory Interleaving and Delay Slots (ELI5)<a class="headerlink" href="#6-dual-lsu-with-memory-interleaving-and-delay-slots-eli5" title="Permanent link">&para;</a></h3>
<p><strong>痛点直击 (The "Why")</strong></p>
<ul>
<li>传统的 Vector Core 通常只有一个 LSU（Load-Store Unit），它必须处理所有类型的内存访问模式：简单的 <strong>unit-stride</strong>（连续地址）、复杂的 <strong>indexed/strided</strong>（非连续、跳跃式）以及 <strong>segment</strong>（一次操作多个寄存器）。</li>
<li>这导致了两个核心矛盾：<ul>
<li><strong>带宽浪费</strong>：对于最高效的 <strong>unit-stride</strong> 访问，由于 load 和 store 操作不能同时进行（通常是交替执行），宝贵的内存总线带宽被浪费了一半。想象一下，你有一条双向八车道的高速公路，但每次只允许一个方向通车。</li>
<li><strong>延迟灾难</strong>：对于 <strong>indexed</strong> 访问，每个元素的地址都需要从向量寄存器中读取，这会产生海量的、随机的内存请求。这些请求的延迟极高（可能成千上万个周期），而传统的顺序执行会让整个向量流水线完全卡死，直到所有数据都返回，CPU 只能干等。</li>
</ul>
</li>
</ul>
<p><strong>通俗比方 (The Analogy)</strong></p>
<ul>
<li>把 T1 的内存子系统想象成一个现代化的物流中心。<ul>
<li><strong>HBLSU (High Bandwidth LSU)</strong> 就像一条高度自动化的 <strong>“集装箱专线”</strong>。它专门处理大批量、规则堆放的货物（<strong>unit-stride</strong> 数据）。这条专线有独立的 <strong>进货（load）和出货（store）通道</strong>，可以同时工作，互不干扰，效率拉满。</li>
<li><strong>HOLSU (High Outstanding LSU)</strong> 则像是一个灵活的 <strong>“快递分拣站”</strong>。它处理的是地址分散、包裹各异的订单（<strong>indexed/strided</strong> 数据）。这个分拣站不会因为一个偏远地区的包裹没到就停止所有工作，而是会先处理手头其他能处理的订单，并且允许后台继续接收新订单，把等待时间（延迟）隐藏起来。</li>
</ul>
</li>
<li><strong>Memory Interleaving</strong> 就是让“集装箱专线”的进货和出货通道 <strong>同时运转</strong>。</li>
<li><strong>Delay Slots</strong> 就是给“快递分拣站”配备了 <strong>智能调度系统</strong>，让它在等待慢速包裹时，能立刻切换去处理其他不相关的任务。</li>
</ul>
<p><strong>关键一招 (The "How")</strong></p>
<ul>
<li>作者没有试图用一个“全能”但平庸的 LSU 去应付所有场景，而是进行了 <strong>功能解耦</strong>，设计了两个高度专业化的 LSU。</li>
<li><strong>对于高带宽场景 (HBLSU + Memory Interleaving)</strong>：<ul>
<li>作者引入了一个 <strong>Conflict Region Table (CRT)</strong>。当一个 load 或 store 指令进入 HBLSU 时，CRT 会记录下它要访问的内存区域。</li>
<li>后续的指令在发射前会查询 CRT。如果它的访问区域与正在处理的指令 <strong>不冲突</strong>，那么它就可以 <strong>立即发射</strong>，即使前一个指令还没完成。</li>
<li>这样，load 和 store 指令就能 <strong>真正并发</strong> 地使用各自的内存通道，将理论带宽利用率从 50% 提升到接近 100%。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/60122021119a97f1361bb7dfdeba64da96d256850b9ec88b66255c7d3c530fac.jpg" /></p>
<p><em>Figure 6: Different ILP Technology in T1. Chaining interleaves V0, V1, and V2. Memory Interleaving mitigates the VSW-VLD dependency. Vector-Scalar OoO interleaves the vector and scalar pipelines until a true dependency v16-s64-v15 occurs. Memory Delay Slot parallelizes vector index load/store (VIDX0) with independent vector executions (VEX0).</em></p>
<ul>
<li><strong>对于高延迟场景 (HOLSU + Delay Slots)</strong>：<ul>
<li>HOLSU 被设计成可以维持 <strong>大量（High Outstanding）</strong> 的未完成内存请求。</li>
<li>更关键的是，作者利用了 RVV 的特性，通过一个 <strong>CSR “chicken bit”</strong> 来告诉硬件：对于某些已知安全的 <strong>indexed</strong> 操作，可以 <strong>忽略精确异常</strong>。</li>
<li>一旦这个开关打开，后续 <strong>不依赖于该 indexed 操作结果</strong> 的指令就可以被 <strong>立即发射和执行</strong>，就像在指令流中人为开辟了一个 <strong>“延迟槽（Delay Slot）”</strong>，让计算单元在等待内存数据时也能保持忙碌，从而将漫长的内存延迟完美地“藏”在了有用的计算工作之下。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/60122021119a97f1361bb7dfdeba64da96d256850b9ec88b66255c7d3c530fac.jpg" /></p>
<p><em>Figure 6: Different ILP Technology in T1. Chaining interleaves V0, V1, and V2. Memory Interleaving mitigates the VSW-VLD dependency. Vector-Scalar OoO interleaves the vector and scalar pipelines until a true dependency v16-s64-v15 occurs. Memory Delay Slot parallelizes vector index load/store (VIDX0) with independent vector executions (VEX0).</em></p>
<p>这种双管齐下的策略，让 T1 在面对不同 workload 时都能发挥出极致的内存子系统性能，这也是它能在 HPC 和 Cryptography 等内存密集型任务上大幅领先的关键。如 Table 1 所示，仅 <strong>Memory Interleaving</strong> 一项技术就能带来 <strong>32%</strong> 的性能提升。</p>
<table>
<thead>
<tr>
<th style="text-align: left;">配置</th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Slow Down</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Standard T1</td>
<td style="text-align: left;">14817</td>
<td style="text-align: left;">-</td>
</tr>
<tr>
<td style="text-align: left;">Disable Chaining</td>
<td style="text-align: left;">23862</td>
<td style="text-align: left;">61%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Disable Memory Interleaving</strong></td>
<td style="text-align: left;"><strong>19514</strong></td>
<td style="text-align: left;"><strong>32%</strong></td>
</tr>
</tbody>
</table>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.sections", "navigation.top", "navigation.indexes", "search.suggest", "search.highlight", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
        <script src="../../../javascripts/switcher.js"></script>
      
    
  </body>
</html>