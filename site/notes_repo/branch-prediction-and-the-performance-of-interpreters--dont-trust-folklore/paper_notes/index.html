
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/notes_repo/branch-prediction-and-the-performance-of-interpreters--dont-trust-folklore/paper_notes/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../../assets/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>Branch Prediction and the Performance of Interpreters – Don’t Trust Folklore 论文解析 - BlaBlaCut</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="amber">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#branch-prediction-and-the-performance-of-interpreters-dont-trust-folklore" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="BlaBlaCut" class="md-header__button md-logo" aria-label="BlaBlaCut" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BlaBlaCut
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Branch Prediction and the Performance of Interpreters – Don’t Trust Folklore 论文解析
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="切换到深色模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换到深色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="切换到浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换到浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="BlaBlaCut" class="md-nav__button md-logo" aria-label="BlaBlaCut" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    BlaBlaCut
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/Recent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Recent
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/awesome-data-prefetchers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Awesome Data Prefetchers
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/micro-2025/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MICRO 2025
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../collections/dyn-lang-acc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Dynamic Language Acceleration
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#0" class="md-nav__link">
    <span class="md-ellipsis">
      
        0. 论文基本信息
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. 摘要
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. 背景知识与核心贡献
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. 核心技术和实现细节
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. 核心技术和实现细节">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#0_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        0. 技术架构概览
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1-indirect-branch-prediction-with-ittage" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Indirect Branch Prediction with ITTAGE
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-switch-based-interpreter-dispatch-loop" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Switch-Based Interpreter Dispatch Loop
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-jump-threading-token-threading" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Jump Threading (Token Threading)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-hardware-performance-counter-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Hardware Performance Counter Analysis
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-pin-based-trace-simulation" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Pin-based Trace Simulation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. 实验方法与实验结果
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="branch-prediction-and-the-performance-of-interpreters-dont-trust-folklore">Branch Prediction and the Performance of Interpreters – Don’t Trust Folklore 论文解析<a class="headerlink" href="#branch-prediction-and-the-performance-of-interpreters-dont-trust-folklore" title="Permanent link">&para;</a></h1>
<h2 id="0">0. 论文基本信息<a class="headerlink" href="#0" title="Permanent link">&para;</a></h2>
<p><strong>作者 (Authors)</strong>: Erven Rohou, Bharath Narasimha Swamy, Andre Seznec</p>
<p><strong>发表期刊/会议 (Journal/Conference)</strong>: CGO</p>
<p><strong>发表年份 (Publication Year)</strong>: 2015</p>
<p><strong>研究机构 (Affiliations)</strong>: Inria, France</p>
<hr />
<h2 id="1">1. 摘要<a class="headerlink" href="#1" title="Permanent link">&para;</a></h2>
<p><strong>目的</strong></p>
<ul>
<li>重新审视关于解释器性能的“民间传说”（folklore），即认为解释器主循环中的<strong>间接分支</strong>（indirect branch）由于<strong>高误预测率</strong>（high misprediction rate）是导致其性能低下的主要原因。</li>
<li>评估在<strong>现代处理器</strong>（特别是Intel近三代架构：Nehalem, Sandy Bridge, Haswell）和<strong>先进分支预测器</strong>（如ITTAGE）上，该间接分支对解释器性能的实际影响是否依然关键。</li>
</ul>
<p><strong>方法</strong></p>
<ul>
<li><strong>实验平台</strong>：在真实的<strong>Nehalem</strong>、<strong>Sandy Bridge</strong>和<strong>Haswell</strong>处理器上，使用硬件性能计数器（PMU）收集分支预测数据。</li>
<li><strong>模拟验证</strong>：通过Pin工具生成执行轨迹，并在<strong>TAGE/ITTAGE</strong>（当前文献中最先进的条件/间接分支预测器）上进行模拟，以对比真实硬件与理想预测器的表现。</li>
<li><strong>研究对象</strong>：选取三种主流语言的<strong>switch-based解释器</strong>（无jump threading优化）作为基准：<strong>Python</strong>、**Javascript **(SpiderMonkey) 和 **CLI **(.NET)。</li>
<li><strong>核心指标</strong>：主要使用**MPKI **(Mispredictions Per Kilo Instructions)，即每千条指令的分支误预测次数，来衡量分支预测开销。</li>
</ul>
<p><strong>结果</strong></p>
<ul>
<li><strong>分支预测准确率大幅提升</strong>：在<strong>Haswell</strong>架构上，解释器的整体分支误预测率（MPKI）已从<strong>Nehalem</strong>时代的<strong>12-20 MPKI</strong>显著下降至<strong>0.5-2 MPKI</strong>的极低水平。</li>
<li><strong>现代硬件与先进预测器表现相当</strong>：<strong>Haswell</strong>处理器上的实测MPKI与<strong>TAGE+ITTAGE</strong>模拟器的结果处于<strong>同一数量级</strong>，表明现代硬件的间接分支预测能力已非常强大。
    <img alt="" src="../images/6938ddca3607b874b68eea2a7185d637042a438ad615d4c43da8f087b6956ac2.jpg" /> <em>Figure 4. Python MPKI for all predictors</em>
    <img alt="" src="../images/d17bf9fe709aa074e11a144b931ddfc3a15681bafed637ae6b05056b80c35e51.jpg" /> <em>Figure 5. Javascript MPKI for all predictors</em>
    <img alt="" src="../images/362e2e3d9b54feba7bff51cfac333157507f03db85089ae8da64b81060f68f65.jpg" /> <em>Figure 6. CLI MPKI for all predictors</em></li>
<li><strong>Jump Threading优化收益递减</strong>：在<strong>Nehalem</strong>上，jump threading能带来约<strong>10.1%</strong>的平均性能提升，但在<strong>Haswell</strong>上该收益已降至仅<strong>2.8%</strong>，证明其重要性随硬件进步而减弱。
    <img alt="" src="../images/c33473af79f2628363612d9fe4db98aac0fca59cc4a70c57b403df0efcdc5d29.jpg" /> <em>Figure 3. Speedups in Python</em></li>
<li><strong>“难以预测”的分支并非固有难题</strong>：仿真结果显示，解释器主循环中的间接分支本身<strong>并非天生不可预测</strong>。当使用足够大的<strong>ITTAGE</strong>预测器（如50KB）时，其预测准确率可以变得非常高。过去预测不佳主要是因为预测器资源（footprint）不足，而非模式本身随机。</li>
<li><strong>前端瓶颈转移</strong>：在<strong>Haswell</strong>上，由分支误预测导致的<strong>前端流水线槽浪费</strong>（wasted issue slots）平均仅为<strong>7.8%</strong>，远低于<strong>Sandy Bridge</strong>的<strong>14.5%</strong>，确认了分支预测已不再是主要性能瓶颈。
    <img alt="" src="../images/8c1b82375d550953f02680f4f8504df67ceb87f3574ce7092ef705dc3e01952b.jpg" /> <em>Figure 7. Correlation between MPKI and lost slots</em></li>
</ul>
<p><strong>结论</strong></p>
<ul>
<li><strong>推翻传统认知</strong>：对于现代处理器（如Haswell）和当前主流解释器（Python, Javascript, CLI），<strong>间接分支的预测准确率已不再是影响性能的关键因素</strong>。将解释器慢的原因主要归咎于“难以预测的间接跳转”这一<strong>民间传说已经过时</strong>。</li>
<li><strong>硬件演进的影响</strong>：<strong>分支预测技术的巨大进步</strong>是导致这一现象的根本原因，使得软件层面为优化间接分支预测而采用的复杂技术（如jump threading）的收益大幅降低。</li>
<li><strong>未来优化方向</strong>：解释器的性能优化工作应更多地关注其他方面，例如<strong>减少每条字节码所需的原生指令数</strong>、<strong>优化求值栈的内存访问</strong>以及<strong>改进动态类型检查</strong>等，而非过度关注分支预测问题。</li>
</ul>
<hr />
<h2 id="2">2. 背景知识与核心贡献<a class="headerlink" href="#2" title="Permanent link">&para;</a></h2>
<p><strong>研究背景</strong></p>
<ul>
<li><strong>Interpreters</strong>（解释器）因其<strong>portability</strong>（可移植性）和开发便捷性被广泛应用，尤其是在<strong>Python</strong>、<strong>Javascript</strong>和<strong>R</strong>等动态语言中，但其性能远低于<strong>JIT</strong>（Just-In-Time）编译。</li>
<li>解释器的核心是一个<strong>dispatch loop</strong>（分发循环），通常通过一个大型的<code>switch</code>语句实现，该语句在底层会被编译为一个<strong>indirect branch</strong>（间接跳转）指令。</li>
<li><strong>Folklore</strong>（传统观点/业界共识）认为，这个间接跳转由于目标地址众多且难以预测，会导致<strong>high misprediction rate</strong>（高误预测率），从而在现代深度流水线处理器上造成严重的<strong>performance penalty</strong>（性能惩罚），这在过去（如Core2时代）的研究中已被证实。</li>
</ul>
<p><strong>研究动机</strong></p>
<ul>
<li>过去十年间，<strong>branch predictor</strong>（分支预测器）技术取得了巨大进步，尤其是<strong>Intel</strong>的<strong>Nehalem</strong>、<strong>Sandy Bridge</strong>到<strong>Haswell</strong>等微架构。</li>
<li>作者质疑：在当前最先进的处理器上，上述关于间接跳转是解释器性能瓶颈的“<strong>folklore</strong>”是否依然成立？</li>
<li>现有解释器（如Python、Javascript）普遍实现了<strong>jump threading</strong>（跳转线索化）等复杂优化来规避间接跳转，如果该问题已不复存在，则这些优化的必要性值得重新评估。</li>
</ul>
<p><strong>核心贡献</strong></p>
<ul>
<li><strong>颠覆性发现</strong>：通过在<strong>Nehalem</strong>、<strong>Sandy Bridge</strong>和<strong>Haswell</strong>处理器上使用<strong>hardware performance counters</strong>（硬件性能计数器）进行实测，并结合<strong>ITTAGE</strong>（state-of-the-art indirect branch predictor）的模拟，证明了<strong>indirect branch prediction accuracy is no longer critical for interpreters</strong>。<ul>
<li><strong>关键数据</strong>：解释器执行时的<strong>global branch misprediction rate</strong>（全局分支误预测率）从<strong>Nehalem</strong>上的 <strong>12-20 MPKI</strong>（每千条指令的误预测数）大幅下降到<strong>Haswell</strong>上的 <strong>0.5-2 MPKI</strong>。</li>
</ul>
</li>
<li><strong>性能影响分析</strong>：<strong>Haswell</strong>处理器上的分支预测性能与文献中的顶级预测器<strong>ITTAGE</strong>相当，表明现代硬件已能有效处理解释器的间接跳转模式。</li>
<li><strong>对优化策略的启示</strong>：<strong>Jump threading</strong>等旨在改善间接跳转预测的优化技术，在现代硬件上的收益已<strong>显著降低</strong>（例如，在Python上，从Nehalem的平均10.1%速度提升降至Haswell的2.8%），部分收益甚至源于减少了指令数而非改善了预测。</li>
<li><strong>根本原因探究</strong>：现代<strong>TAGE/ITTAGE</strong>类预测器能够利用<strong>long global history</strong>（长全局历史）有效捕捉字节码序列中的<strong>repetitive patterns</strong>（重复模式），从而准确“预测”下一个<strong>opcode</strong>（操作码），使得主间接跳转变得高度可预测。</li>
</ul>
<p><img alt="" src="../images/c33473af79f2628363612d9fe4db98aac0fca59cc4a70c57b403df0efcdc5d29.jpg" /> <em>Figure 3. Speedups in Python</em></p>
<table>
<thead>
<tr>
<th style="text-align: left;">微架构</th>
<th style="text-align: center;">Python-3 Jump Threading 平均加速比</th>
<th style="text-align: center;">Python-2 Pair Threading 平均加速比</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Nehalem</strong></td>
<td style="text-align: center;">10.1%</td>
<td style="text-align: center;">2.8%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Sandy Bridge</strong></td>
<td style="text-align: center;">4.2%</td>
<td style="text-align: center;">3.2%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Haswell</strong></td>
<td style="text-align: center;">2.8%</td>
<td style="text-align: center;">1.8%</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="3">3. 核心技术和实现细节<a class="headerlink" href="#3" title="Permanent link">&para;</a></h2>
<h3 id="0_1">0. 技术架构概览<a class="headerlink" href="#0_1" title="Permanent link">&para;</a></h3>
<p><strong>研究目标与核心论点</strong></p>
<ul>
<li>本文旨在<strong>挑战并验证</strong>一个在解释器性能优化领域长期存在的<strong>folklore（传统观念）</strong>：即，基于 <code>switch</code> 语句实现的解释器主循环中的<strong>间接分支（indirect branch）</strong> 指令因其<strong>高误预测率（high misprediction rate）</strong> 而成为性能瓶颈。</li>
<li>核心论点是，在<strong>现代处理器</strong>（特别是 Intel Haswell 及之后的架构）和<strong>先进的分支预测器</strong>（如 ITTAGE）上，该间接分支的预测准确率已大幅提升，其对整体性能的影响已<strong>不再是关键问题</strong>。</li>
</ul>
<p><strong>实验方法论与技术栈</strong></p>
<ul>
<li><strong>硬件平台</strong>：在三代 Intel 处理器上进行真实硬件测量，分别是 <strong>Nehalem</strong>、<strong>Sandy Bridge</strong> 和 <strong>Haswell</strong>。通过 <strong>PMU </strong>(Performance Monitoring Unit) 收集<strong>硬件性能计数器</strong>数据。</li>
<li><strong>软件模拟</strong>：使用 <strong>Pin</strong> 工具生成指令执行轨迹，并在<strong>模拟器</strong>中运行<strong>最先进的分支预测器模型</strong> <strong>TAGE/ITTAGE</strong>，以评估理论上的预测上限。</li>
<li><strong>一致性验证</strong>：通过对比 PMU 和 Pin 的测量结果（如指令数、指令混合比例），确认两种方法的数据具有高度一致性，保证了实验结论的可靠性。</li>
<li><strong>测试对象</strong>：选取了三种主流语言的解释器作为研究对象：<ul>
<li><strong>Python</strong> (版本 3.3.2)</li>
<li><strong>Javascript</strong> (SpiderMonkey 1.8.5，禁用 JIT)</li>
<li>**CLI **(Common Language Infrastructure)</li>
</ul>
</li>
</ul>
<p><strong>关键发现与数据分析</strong></p>
<ul>
<li><strong>误预测率</strong>（MPKI）<ul>
<li>在 <strong>Nehalem</strong> 上，解释器的全局分支误预测率高达 <strong>12-20 MPKI</strong>。</li>
<li>在 <strong>Sandy Bridge</strong> 上，该指标显著下降。</li>
<li>在 <strong>Haswell</strong> 上，误预测率进一步降至 <strong>0.5-2 MPKI</strong> 的极低水平。</li>
<li><strong>ITTAGE</strong> 模拟器的结果与 <strong>Haswell</strong> 的实测结果处于<strong>同一数量级</strong>，表明 Haswell 的硬件预测器性能已接近学术界的先进水平。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">微架构</th>
<th style="text-align: left;">典型 MPKI 范围</th>
<th style="text-align: left;">性能影响</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Nehalem</td>
<td style="text-align: left;">12 - 20</td>
<td style="text-align: left;"><strong>重大瓶颈</strong></td>
</tr>
<tr>
<td style="text-align: left;">Sandy Bridge</td>
<td style="text-align: left;">4 - 8</td>
<td style="text-align: left;"><strong>显著改善</strong></td>
</tr>
<tr>
<td style="text-align: left;">Haswell</td>
<td style="text-align: left;">0.5 - 2</td>
<td style="text-align: left;"><strong>影响微小</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>跳转线程</strong>（Jump Threading）<ul>
<li>实验复现了 <strong>jump threading</strong>（利用 GCC 的 "Labels as Values" 扩展）优化。</li>
<li>结果显示，该优化带来的<strong>性能提升随微架构代际递减</strong>：在 Nehalem 上平均提升 <strong>10.1%</strong>，在 Haswell 上仅剩 <strong>2.8%</strong>。</li>
<li>这证明了<strong>分支预测的改进</strong>是性能差距缩小的主要原因，而非其他因素。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/c33473af79f2628363612d9fe4db98aac0fca59cc4a70c57b403df0efcdc5d29.jpg" /> <em>Figure 3. Speedups in Python</em></p>
<ul>
<li><strong>“难以预测”分支的再审视</strong><ul>
<li>通过模拟器追踪特定分支指令，发现主循环中的<strong>间接跳转</strong>本身在现代预测器下<strong>并非天生不可预测</strong>。</li>
<li>预测失败的案例（如 CLI 解释器在 <code>vpr</code> 和 <code>crafty</code> 基准上）主要是因为解释器的<strong>巨大操作码空间</strong>（如 CLI 有 478 个 opcode）导致了<strong>预测器资源</strong>（footprint）。当使用更大容量的 ITTAGE（如 50KB）时，预测准确率得以恢复。</li>
</ul>
</li>
</ul>
<p><strong>整体架构总结</strong></p>
<ul>
<li>本文构建了一个<strong>横跨硬件、模拟器和真实软件栈</strong>的综合性分析框架。</li>
<li>通过<strong>对比不同代际的商业处理器</strong>与<strong>前沿的学术预测器模型</strong>，系统性地<strong>证伪</strong>了关于解释器间接分支开销过大的传统观点。</li>
<li>其技术架构的核心在于利用<strong>硬件性能计数器</strong>和<strong>精确的模拟</strong>作为“显微镜”，深入剖析现代 CPU 微架构与解释器工作负载之间的真实交互，从而为解释器设计和优化提供了基于实证的新方向。</li>
</ul>
<h3 id="1-indirect-branch-prediction-with-ittage">1. Indirect Branch Prediction with ITTAGE<a class="headerlink" href="#1-indirect-branch-prediction-with-ittage" title="Permanent link">&para;</a></h3>
<p><strong>ITTAGE 间接分支预测器的核心原理</strong></p>
<ul>
<li>ITTAGE (Indirect TAgged GEometric history length) 是从 <strong>TAGE</strong> 条件分支预测器衍生而来的<strong>state-of-the-art</strong>间接分支预测器。</li>
<li>其核心思想是利用<strong>全局历史信息</strong>（Global History）来预测间接跳转的<strong>完整目标地址</strong>（complete target），而非仅仅预测方向。</li>
<li>它通过一组<strong>部分标记的预测表</strong>（partially tagged predictor tables）来实现，这些表的关键特性在于其索引方式：<ul>
<li>每个表使用<strong>不同长度</strong>的全局分支历史进行索引。</li>
<li>这些历史长度构成一个<strong>几何级数</strong>（geometric series），例如 4, 8, 16, 32... 这样可以高效地覆盖从短到极长的相关性模式。</li>
</ul>
</li>
<li>预测时，系统会并行查询所有表格。最终的预测结果由<strong>历史长度最长且命中</strong>（hitting）的表格提供。这种机制使其能够捕捉跨越数百甚至数千条指令的复杂、长距离相关性。</li>
</ul>
<p><strong>在解释器场景下的工作流程与作用</strong></p>
<ul>
<li>在基于 <strong>switch</strong> 的解释器中，主循环包含一个<strong>间接跳转</strong>（indirect jump），该跳转的目标地址由当前 <strong>opcode</strong> 决定。</li>
<li>ITTAGE 将这个间接跳转视为一个需要预测的目标。其输入是<strong>全局历史寄存器</strong>（GHR），该寄存器记录了最近执行过的分支（包括条件和间接分支）的历史。</li>
<li>对于解释器而言，这个全局历史在很大程度上等同于最近执行的 <strong>opcode 序列</strong>。因此，一个特定的 opcode 历史序列（如 <code>load, load, add</code>）就构成了一个独特的“签名”。</li>
<li>ITTAGE 利用这个“签名”作为索引，在其表格中查找下一个最可能的跳转目标（即下一个 opcode 的处理代码地址）。</li>
<li><strong>输出</strong>是预测的<strong>目标地址</strong>。如果预测正确，处理器流水线可以无缝地继续取指和执行，避免了因<strong>分支误预测</strong>（misprediction）导致的流水线冲刷和性能惩罚。</li>
<li>在整体系统中，ITTAGE 的作用是<strong>极大地降低解释器主循环中关键间接跳转的误预测率</strong>，从而将原本被认为是主要性能瓶颈的因素变得不再重要。</li>
</ul>
<p><strong>论文中的参数设置与实验配置</strong></p>
<p>论文在模拟实验中使用了两种 ITTAGE 配置，以评估不同资源预算下的性能。其参数设置如下：</p>
<table>
<thead>
<tr>
<th style="text-align: left;">组件</th>
<th style="text-align: left;">TAGE1 配置</th>
<th style="text-align: left;">TAGE2 配置</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>TAGE</strong> (条件分支预测器)</td>
<td style="text-align: left;">8 KB</td>
<td style="text-align: left;">8 KB</td>
</tr>
<tr>
<td style="text-align: left;"><strong>ITTAGE</strong> (间接分支预测器)</td>
<td style="text-align: left;"><strong>12.62 KB</strong></td>
<td style="text-align: left;"><strong>6.31 KB</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>为了进一步验证<strong>预测器容量</strong>（footprint）对性能的影响，论文还引入了 <strong>TAGE3</strong> 配置，其 ITTAGE 大小为 <strong>50 KB</strong>。</li>
<li>实验发现，对于像 <strong>CLI</strong> 这样拥有 <strong>478</strong> 个不同 <strong>opcode</strong> 的解释器，较小的 ITTAGE（如 6.31 KB 或 12.62 KB）在某些基准测试（如 <code>vpr</code>, <code>crafty</code>）上表现不佳，误预测率较高。</li>
<li>而当使用 <strong>50 KB</strong> 的 ITTAGE 时，这些基准的误预测率显著下降，证明了<strong>预测器容量不足</strong>是导致性能不佳的原因，而非 ITTAGE 算法本身无法处理解释器的分支模式。</li>
</ul>
<p><strong>关键结论与数据支撑</strong></p>
<ul>
<li>论文通过硬件计数器和模拟，展示了现代处理器（特别是 <strong>Haswell</strong>）的间接分支预测精度已经非常高。</li>
<li><strong>MPKI</strong>（Mispredictions Per Kilo Instructions）是衡量预测精度的关键指标。在 <strong>Nehalem</strong> 上，解释器的 MPKI 高达 <strong>12-20</strong>，而在 <strong>Haswell</strong> 上则降至 <strong>0.5-2</strong>。</li>
<li>ITTAGE 模拟的结果与 <strong>Haswell</strong> 的实测结果处于<strong>同一数量级</strong>，这表明 Haswell 内部很可能采用了类似 ITTAGE 的先进预测技术。</li>
<li><img alt="" src="../images/6938ddca3607b874b68eea2a7185d637042a438ad615d4c43da8f087b6956ac2.jpg" /> <em>Figure 4. Python MPKI for all predictors</em></li>
<li><img alt="" src="../images/d17bf9fe709aa074e11a144b931ddfc3a15681bafed637ae6b05056b80c35e51.jpg" /> <em>Figure 5. Javascript MPKI for all predictors</em></li>
<li><img alt="" src="../images/362e2e3d9b54feba7bff51cfac333157507f03db85089ae8da64b81060f68f65.jpg" /> <em>Figure 6. CLI MPKI for all predictors</em></li>
<li>论文最终得出结论：<strong>“hard to predict”</strong> 分支的<strong>民间说法</strong>（folklore）已经过时。只要拥有足够大的高效间接跳转预测器（如 ITTAGE），解释器主循环中的间接分支实际上是<strong>高度可预测的</strong>。</li>
</ul>
<h3 id="2-switch-based-interpreter-dispatch-loop">2. Switch-Based Interpreter Dispatch Loop<a class="headerlink" href="#2-switch-based-interpreter-dispatch-loop" title="Permanent link">&para;</a></h3>
<p><strong>核心实现原理与算法流程</strong></p>
<ul>
<li><strong>Switch-Based Interpreter</strong> 的核心是一个无限循环，其主逻辑是通过一个巨大的 <strong>C 语言 switch 语句</strong>来实现的。该循环负责 <strong>fetch（取指）</strong>、<strong>decode（译码）</strong> 和 <strong>execute（执行）</strong> 三个步骤。</li>
<li>在 <strong>fetch</strong> 阶段，解释器从 <strong>virtual program counter (vpc)</strong> 指向的内存位置读取下一个 <strong>bytecode</strong>（字节码），并递增 vpc。</li>
<li>在 <strong>decode</strong> 阶段，读取到的 <strong>opcode</strong>（操作码，即 bytecode 的数值）被用作 switch 语句的条件变量。</li>
<li>编译器（如 GCC, icc, LLVM）在处理这种大型 switch 时，通常会将其优化为一个 <strong>jump table（跳转表）</strong>。这个跳转表是一个地址数组，每个索引对应一个 opcode，存储着该 opcode 对应处理代码块（<strong>payload</strong>）的入口地址。</li>
<li>执行流程最终会通过一条 <strong>indirect jump instruction（间接跳转指令）</strong> 跳转到 jump table 中指定的地址，从而执行相应的 payload 代码。</li>
<li>Payload 执行完毕后，控制流会回到循环顶部，开始下一次迭代。</li>
</ul>
<p><img alt="" src="../images/7313c63f2fd4694f4167936cd19dfd9afd723c4f2df88180ff84a11edc2dcaef.jpg" /> <em>Figure 1. Main loop of naive interpreter</em></p>
<p><strong>关键特性与性能开销</strong></p>
<ul>
<li><strong>主要开销来源</strong>：整个 <strong>dispatch loop（分派循环）</strong> 是解释器性能瓶颈的主要来源。论文测量表明，仅分派循环本身在 x86 上就需要大约 <strong>10 条 native instructions（原生指令）</strong>。</li>
<li><strong>间接跳转的“传统”问题</strong>：该间接跳转指令有数百个潜在目标（每个 opcode 对应一个），<strong>folklore（传统观点）</strong> 认为其 <strong>branch misprediction rate（分支误预测率）</strong> 极高，在旧式处理器上会带来约 <strong>20 cycle penalty（周期惩罚）</strong>。</li>
<li><strong>次要开销</strong>：在访问 jump table 前，编译器通常会生成两条指令来检查 opcode 是否在有效范围内。但由于解释器的正确性保证了 opcode 总是有效的，这个边界检查分支很容易被预测，开销很小。</li>
<li><strong>数据访问开销</strong>：操作数通常从内存中的 <strong>evaluation stack（求值栈）</strong> 中加载，结果也存回栈中，这比 JIT 编译代码直接使用寄存器要慢得多。</li>
</ul>
<p><strong>现代硬件上的性能演变</strong></p>
<ul>
<li>论文的核心发现是，随着 <strong>state-of-the-art branch predictors（先进分支预测器）</strong> 的发展，间接跳转的预测问题在现代处理器上已大大缓解。</li>
<li>通过在 <strong>Nehalem</strong>、<strong>Sandy Bridge</strong> 和 <strong>Haswell</strong> 三代 Intel 处理器上进行实验，全局分支误预测率（<strong>MPKI, Mispredictions Per Kilo Instructions</strong>）从 Nehalem 上的 <strong>12-20 MPKI</strong> 剧降至 Haswell 上的 <strong>0.5-2 MPKI</strong>。</li>
<li>这意味着分支误预测带来的性能损失已从主要因素变为次要因素。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">Microarchitecture</th>
<th style="text-align: center;">Avg. Python Speedup from Threading</th>
<th style="text-align: center;">Global Misprediction Rate (MPKI)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Nehalem</td>
<td style="text-align: center;">10.1%</td>
<td style="text-align: center;">12 - 20</td>
</tr>
<tr>
<td style="text-align: left;">Sandy Bridge</td>
<td style="text-align: center;">4.2%</td>
<td style="text-align: center;">4 - 8</td>
</tr>
<tr>
<td style="text-align: left;">Haswell</td>
<td style="text-align: center;">2.8%</td>
<td style="text-align: center;">0.5 - 2</td>
</tr>
</tbody>
</table>
<p><strong>与先进预测器 ITTAGE 的对比</strong></p>
<ul>
<li>论文还使用了文献中的 <strong>state-of-the-art indirect branch predictor ITTAGE</strong> 进行模拟。</li>
<li>ITTAGE 能够利用长距离的全局历史信息来预测间接跳转的目标，在运行解释器时，其预测准确率与 <strong>Haswell</strong> 硬件实测结果处于<strong>同一量级</strong>。</li>
<li>这表明 <strong>Haswell</strong> 的硬件间接分支预测器已经非常强大，能够有效处理解释器 dispatch loop 中的模式。</li>
<li>在少数预测不佳的案例中（如 CLI 解释器的 <code>vpr</code> 和 <code>crafty</code> 基准测试），模拟显示这是因为解释器的 <strong>footprint（足迹）</strong> 过大，超出了较小 ITTAGE 表的容量。增大 ITTAGE 的大小可以显著改善预测准确率，证明问题在于<strong>资源限制</strong>而非<strong>预测方案本身</strong>。</li>
</ul>
<p><strong>在整体系统中的作用</strong></p>
<ul>
<li><strong>输入</strong>：<strong>Bytecode stream（字节码流）</strong>，由前端编译器或解析器生成。</li>
<li><strong>输出</strong>：程序的执行效果，通过操作 <strong>evaluation stack</strong> 和与外部环境交互来体现。</li>
<li><strong>作用</strong>：作为解释器的<strong>核心引擎</strong>，它提供了一种简单、可移植的方式来执行高级语言。虽然牺牲了性能，但其<strong>实现简单</strong>、<strong>易于调试和移植</strong>的特性使其在许多场景（如科学计算、嵌入式系统、动态语言）中仍然不可或缺。该分派循环的设计直接决定了基础解释执行的效率上限。</li>
</ul>
<h3 id="3-jump-threading-token-threading">3. Jump Threading (Token Threading)<a class="headerlink" href="#3-jump-threading-token-threading" title="Permanent link">&para;</a></h3>
<p><strong>核心原理与实现机制</strong></p>
<ul>
<li><strong>Jump Threading</strong>（在文中特指 <strong>Token Threading</strong>）是一种用于优化解释器 <strong>dispatch loop</strong>（分发循环）的软件技术。</li>
<li>其核心思想是<strong>绕过</strong>传统的、基于 <code>switch</code> 语句的分发机制。传统 <code>switch</code> 会被编译器翻译成一个包含<strong>间接跳转</strong>（indirect jump）指令的跳转表，该指令因目标地址多变而难以预测。</li>
<li>该技术依赖于 <strong>GNU C 扩展 'Labels as Values'</strong>，此扩展允许将代码标签（label）的地址作为值存储在变量中，并通过 <code>goto *variable</code> 进行间接跳转。</li>
<li>在实现上，每个字节码（bytecode）操作码（opcode）的处理代码块末尾，不再无条件地跳回主循环顶部，而是直接获取并跳转到<strong>下一个待执行字节码</strong>对应的处理代码块入口。</li>
<li>如图所示，<code>NEXT()</code> 宏被定义为 <code>goto *next_instr++</code>，其中 <code>next_instr</code> 是一个指向标签地址数组（<code>oplabels</code>）的指针。这实现了从一个 opcode 的 payload 直接“线程化”到下一个 opcode 的 payload。</li>
</ul>
<p><img alt="" src="../images/f37fa0abcff31d3e993f00ac0c1a6629a39efb99648c17845dba502394c3004b.jpg" /> <em>Figure 2. Token threading, using a GNU extension</em></p>
<p><strong>算法流程与输入输出关系</strong></p>
<ul>
<li><strong>输入</strong>：一个由字节码组成的程序流。</li>
<li><strong>初始化</strong>：<ul>
<li>构建一个静态的 <strong><code>oplabels</code> 数组</strong>，该数组的每个元素是对应 opcode 处理代码块入口标签的地址。</li>
<li>将解释器的虚拟程序计数器（<strong>virtual program counter</strong>, vpc）或等效的指令指针初始化为程序入口。</li>
</ul>
</li>
<li><strong>主执行循环</strong>（已内联到各 opcode 末尾）：<ul>
<li><strong>Fetch</strong>（取指）：从当前指令指针位置读取下一个 opcode。</li>
<li><strong>Decode &amp; Dispatch</strong>（解码与分发）：使用该 opcode 作为索引，从 <code>oplabels</code> 数组中取出目标地址，并通过 <code>goto *address</code> 直接跳转。</li>
</ul>
</li>
<li><strong>输出</strong>：字节码程序的执行结果，其语义与传统 switch-based 解释器完全一致。</li>
<li><strong>在整体中的作用</strong>：它重构了控制流，将一个中心化的、高扇出的间接分支，替换为一系列分布式的、通常具有更高局部性和可预测性的直接跳转，从而成为解释器性能的关键优化点。</li>
</ul>
<p><strong>性能优势与量化分析</strong></p>
<ul>
<li><strong>减少分支误预测</strong>（Mispredictions）：通过将一个难以预测的间接跳转分解为多个更容易预测的跳转（因为相邻字节码间存在强相关性，如 <code>compare</code> 后常跟 <code>branch</code>），显著降低了分支预测失败率。</li>
<li><strong>降低指令开销</strong>（Instruction Count）：直接跳转到下一个 payload 避免了每次循环迭代都需执行完整的 dispatch loop 开销（如重新加载 opcode、访问跳转表等）。论文测量表明，在 Python-3 上，该技术平均减少了 <strong>3.3%</strong> 的指令数。</li>
<li><strong>性能提升随硬件演进而减弱</strong>：由于现代处理器（如 Haswell）的<strong>间接分支预测器</strong>（如 ITTAGE）已变得极为强大，Jump Threading 带来的性能增益已大幅缩小。论文数据显示，其在 <strong>Nehalem</strong> 上的平均加速比为 <strong>10.1%</strong>，而在 <strong>Haswell</strong> 上仅为 <strong>2.8%</strong>。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">微架构 (Microarchitecture)</th>
<th style="text-align: center;">Python-3 平均加速比</th>
<th style="text-align: center;">Python-2 平均加速比</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Nehalem</td>
<td style="text-align: center;">10.1%</td>
<td style="text-align: center;">2.8%</td>
</tr>
<tr>
<td style="text-align: left;">Sandy Bridge</td>
<td style="text-align: center;">4.2%</td>
<td style="text-align: center;">3.2%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Haswell</strong></td>
<td style="text-align: center;"><strong>2.8%</strong></td>
<td style="text-align: center;"><strong>1.8%</strong></td>
</tr>
</tbody>
</table>
<p><img alt="" src="../images/c33473af79f2628363612d9fe4db98aac0fca59cc4a70c57b403df0efcdc5d29.jpg" /> <em>Figure 3. Speedups in Python</em></p>
<p><strong>工程实践与局限性</strong></p>
<ul>
<li><strong>非标准 C 特性</strong>：依赖 GNU 'Labels as Values' 扩展，牺牲了 ANSI C 的可移植性。解释器（如 Python, Javascript）通常会通过 <code>#ifdef</code> 提供两套实现（threaded 和 switch-based），根据编译器支持情况自动选择。</li>
<li><strong>代码复杂性增加</strong>：双实现策略导致源代码臃肿，并且需要禁用某些编译器优化（如全局公共子表达式消除、cross-jumping），以防破坏精心设计的控制流。</li>
<li><strong>收益递减</strong>：随着硬件分支预测能力的飞速发展，这项曾被视为关键的优化技术，其重要性已<strong>显著降低</strong>。论文的核心结论之一就是，在现代处理器上，<strong>间接分支预测的准确性已不再是解释器性能的瓶颈</strong>。</li>
</ul>
<h3 id="4-hardware-performance-counter-analysis">4. Hardware Performance Counter Analysis<a class="headerlink" href="#4-hardware-performance-counter-analysis" title="Permanent link">&para;</a></h3>
<p><strong>硬件性能计数器分析的实现原理与流程</strong></p>
<ul>
<li>该研究利用 Intel 处理器内置的 <strong>PMU (Performance Monitoring Unit)</strong> 来收集真实硬件上的性能数据。</li>
<li>实验覆盖了三代 Intel 微架构：<strong>Nehalem</strong>、<strong>Sandy Bridge</strong> 和 <strong>Haswell</strong>，以追踪分支预测技术的演进对解释器性能的影响。</li>
<li>数据收集工具为 <strong>Tiptop</strong>，它能从 PMU 中读取特定的硬件事件计数器。</li>
<li>为确保测量纯净，实验在空闲工作站上进行，并且 <strong>仅收集用户态 (user-land) 事件</strong>，排除了内核活动的干扰。</li>
</ul>
<p><strong>关键性能指标与数据收集</strong></p>
<ul>
<li>核心度量指标是 <strong>MPKI (Mispredictions Per Kilo Instructions)</strong>，即每千条已执行指令中的分支误预测次数。这是一个能直观反映分支预测惩罚的指标。</li>
<li>PMU 提供了以下关键事件计数器：<ul>
<li><strong>cycles</strong>: CPU 周期数。</li>
<li><strong>retired instructions</strong>: 已执行（退休）的指令数。</li>
<li><strong>retired branch instructions</strong>: 已执行的分支指令数。</li>
<li><strong>mispredicted branch instructions</strong>: 被误预测的分支指令数。</li>
</ul>
</li>
<li>一个主要挑战是，Intel PMU <strong>没有直接提供“已执行的间接跳转”计数器</strong>。研究者使用了名为 “speculative and retired indirect branches” 的计数器作为代理。</li>
<li>研究通过理论和实证确认了该代理计数器的有效性：<ul>
<li>理论下限：已执行的间接分支数 ≥ 执行的字节码数 (<code>nbytecodes</code>)。</li>
<li>理论上限：已执行的间接分支数 ≤ 投机性间接分支计数器的值 (<code>nspeculative</code>)。</li>
<li>在绝大多数情况下，<code>nspeculative / nbytecodes</code> 的比值非常接近 <strong>1</strong>，证明非退休的间接分支可以忽略不计。</li>
<li>对于少数例外情况，研究者使用 <strong>Pin</strong> 工具进行动态插桩计数，验证了 PMU 计数器的准确性。</li>
</ul>
</li>
</ul>
<p><strong>输入输出关系及在整体研究中的作用</strong></p>
<ul>
<li><strong>输入</strong>: 运行在目标处理器（Nehalem/SB/Haswell）上的解释器程序（Python, Javascript, CLI）及其基准测试套件。</li>
<li><strong>处理</strong>: Tiptop 工具在程序运行期间，通过 PMU 持续累加上述硬件事件。</li>
<li><strong>输出</strong>: 一组精确的硬件事件计数，用于计算 <strong>MPKI</strong>、<strong>IPC (Instructions Per Cycle)</strong> 等关键性能指标。</li>
<li><strong>核心作用</strong>:<ul>
<li><strong>提供真实世界基线</strong>: PMU 数据代表了在商用最新硬件上解释器的实际运行状况，是验证“传统观点”（即间接跳转难以预测）是否过时的最直接证据。</li>
<li><strong>量化代际改进</strong>: 通过对比三代处理器的 MPKI 数据，清晰地展示了分支预测准确率的巨大提升。数据显示，MPKI 从 Nehalem 上的 <strong>12-20</strong> 范围急剧下降到 Haswell 上的 <strong>0.5-2</strong> 范围。</li>
<li><strong>验证模拟器结果</strong>: PMU 收集的真实数据被用来与 <strong>ITTAGE</strong> 分支预测器的模拟结果进行对比，以证明模拟的有效性和结论的普适性。</li>
</ul>
</li>
</ul>
<p><strong>与其他方法的协同与一致性验证</strong></p>
<ul>
<li>为了确保 PMU 测量结果与基于 <strong>Pin</strong> 的模拟结果具有可比性，研究者进行了严谨的一致性检查。</li>
<li>潜在的差异来源包括：PMU 的非确定性、<code>rep</code> 指令的计数差异、内核事件、以及 Pin 加载时的额外开销（如符号重定位）。</li>
<li>通过配置 PMU 也只统计用户态事件，并对比两者报告的指令数和指令混合比例，研究发现差异均在 <strong>1%</strong> 以内，证明了两种方法的数据是高度一致的。</li>
<li>此外，研究还利用 <strong>pmu-tools</strong> 提供的前端流水线槽浪费模型，将 <strong>MPKI</strong> 与实际的 <strong>wasted issue slots</strong> 关联起来，进一步证实了分支误预测是前端性能损失的主要原因，并且 Haswell 因其优秀的预测器，其槽浪费率（<strong>7.8%</strong>）比 Sandy Bridge（<strong>14.5%</strong>）降低了近一半。</li>
</ul>
<p><img alt="" src="../images/6938ddca3607b874b68eea2a7185d637042a438ad615d4c43da8f087b6956ac2.jpg" /> <em>Figure 4. Python MPKI for all predictors</em>
<img alt="" src="../images/d17bf9fe709aa074e11a144b931ddfc3a15681bafed637ae6b05056b80c35e51.jpg" /> <em>Figure 5. Javascript MPKI for all predictors</em>
<img alt="" src="../images/362e2e3d9b54feba7bff51cfac333157507f03db85089ae8da64b81060f68f65.jpg" /> <em>Figure 6. CLI MPKI for all predictors</em>
<img alt="" src="../images/8c1b82375d550953f02680f4f8504df67ceb87f3574ce7092ef705dc3e01952b.jpg" /> <em>Figure 7. Correlation between MPKI and lost slots</em></p>
<h3 id="5-pin-based-trace-simulation">5. Pin-based Trace Simulation<a class="headerlink" href="#5-pin-based-trace-simulation" title="Permanent link">&para;</a></h3>
<p><strong>Pin-based Trace Simulation 的实现原理与流程</strong></p>
<ul>
<li>论文采用 <strong>Pin</strong>（一个动态二进制插桩框架）来生成程序执行的详细指令轨迹（execution trace）。</li>
<li>该轨迹捕获了用户态（user-mode）下所有指令的执行流，特别是所有 <strong>branch instructions</strong>（分支指令）的地址、类型（conditional/indirect）和结果（taken/not-taken, target address）。</li>
<li>这些轨迹被用作离线 <strong>simulator</strong> 的输入，该模拟器实现了 <strong>TAGE</strong>（用于条件分支预测）和 <strong>ITTAGE</strong>（用于间接分支预测）的精确模型。</li>
<li>模拟器遍历轨迹中的每条分支指令，利用其内部的预测器状态（如历史寄存器、预测表）进行预测，并将预测结果与轨迹中记录的真实结果进行比较，从而计算出 <strong>misprediction rate</strong>（误预测率）。</li>
</ul>
<p><strong>参数设置与配置</strong></p>
<ul>
<li>论文使用了两种不同的 <strong>(TAGE+ITTAGE)</strong> 配置来进行模拟，以评估不同硬件资源预算下的性能：<ul>
<li><strong>TAGE1</strong>: 8 KB TAGE + <strong>12.62 KB ITTAGE</strong></li>
<li><strong>TAGE2</strong>: 8 KB TAGE + <strong>6.31 KB ITTAGE</strong></li>
</ul>
</li>
<li>这些配置的详细参数在论文的 <strong>Table 2</strong> 中给出，包括历史长度、表项数量等关键设计指标。</li>
</ul>
<p><img alt="" src="../images/bb2bc6ce7bc772acd82002bd7af8cff61bfec2bc3cc409be03ecfc9a836bf6ff.jpg" /> <em>Table 2. Branch predictor parameters</em></p>
<p><strong>输入输出关系及在整体研究中的作用</strong></p>
<ul>
<li><strong>输入</strong>: 由 <strong>Pin</strong> 工具从真实运行的 <strong>interpreter</strong>（Python, Javascript, CLI）上采集的完整用户态指令执行轨迹。</li>
<li><strong>输出</strong>: 在给定 <strong>TAGE/ITTAGE</strong> 配置下，对每个 benchmark 的 <strong>MPKI</strong>（Mispredictions Per Kilo Instructions，每千条指令的误预测次数）等性能指标。</li>
<li><strong>核心作用</strong>:<ul>
<li><strong>验证硬件测量</strong>: 通过将 <strong>Haswell</strong> 硬件实测的 MPKI 与 <strong>TAGE+ITTAGE</strong> 模拟结果进行对比（见 Figures 4, 5, 6），证明了现代处理器（如 Haswell）的间接分支预测器性能已经非常接近学术界最先进的 <strong>ITTAGE</strong> 设计，从而支撑了论文的核心论点——“间接跳转不再是一个主要性能瓶颈”。</li>
<li><strong>探索理想化场景</strong>: 硬件性能计数器（PMU）无法提供对特定分支指令（如 dispatch loop 中的间接跳转）的独立分析。而基于 <strong>Pin</strong> 的模拟允许作者深入分析这些“folklore”中被认为难以预测的特定分支（见 Section 5.3 和 Table 6），揭示了其可预测性实际上取决于预测器的 <strong>footprint</strong>（资源占用）是否足够大。</li>
<li><strong>解耦分析</strong>: 通过控制模拟器中的预测器配置（如 TAGE1 vs TAGE2 vs TAGE3 with 50KB ITTAGE），可以清晰地分离出 <strong>predictor size</strong> 对性能的影响，这在真实硬件上是无法做到的。</li>
</ul>
</li>
</ul>
<p><strong>与硬件测量的一致性保障</strong></p>
<ul>
<li>作者在 <strong>Section 4.2.3</strong> 中专门论证了 <strong>Pin</strong> 轨迹与 <strong>PMU</strong>（Performance Monitoring Unit）硬件计数器数据的一致性。</li>
<li>他们通过多种手段确保了两种方法的可比性：<ul>
<li>将 <strong>PMU</strong> 配置为仅收集 <strong>user-land events</strong>，以匹配 <strong>Pin</strong> 的行为。</li>
<li>量化了 <strong>kernel-mode</strong> 事件、<strong>non-determinism</strong> 以及 <strong>Pin</strong> 自身开销带来的影响，确认这些因素造成的指令计数差异均在 <strong>1%</strong> 以内。</li>
<li>这种严谨的校准保证了模拟结果能够有效地补充和解释硬件实验数据。</li>
</ul>
</li>
</ul>
<hr />
<h2 id="4">4. 实验方法与实验结果<a class="headerlink" href="#4" title="Permanent link">&para;</a></h2>
<p><strong>实验设置</strong></p>
<ul>
<li><strong>研究对象</strong>: 论文聚焦于三种主流的 <strong>switch-based interpreters</strong>（无 jump threading 优化），分别用于 <strong>Python (3.3.2)</strong>、<strong>Javascript (SpiderMonkey 1.8.5)</strong> 和 <strong>Common Language Infrastructure (CLI)</strong>。</li>
<li><strong>基准测试集</strong>:<ul>
<li><strong>Python</strong>: 使用 Unladen Swallow 基准套件（排除了部分不兼容项）。</li>
<li><strong>Javascript</strong>: 使用 Google Octane (2014年2月版) 和 Mozilla Kraken 套件。</li>
<li><strong>CLI</strong>: 使用 SPEC 2000 的 train 输入集子集（因编译器限制，排除了部分基准）。</li>
</ul>
</li>
<li><strong>硬件平台</strong>: 在三款真实的 Intel 处理器上进行测量：<strong>Nehalem</strong>、<strong>Sandy Bridge</strong> 和 <strong>Haswell</strong>。使用 <strong>Tiptop</strong> 工具通过 <strong>PMU (Performance Monitoring Unit)</strong> 收集性能计数器数据，包括周期、指令数、分支指令数和<strong>分支误预测</strong>（mispredicted branches）数。</li>
<li><strong>模拟平台</strong>: 为了与硬件结果对比并探究前沿预测器的性能，使用 <strong>Pin</strong> 工具生成执行轨迹，并在模拟器中运行 <strong>TAGE</strong>（用于条件分支）和 <strong>ITTAGE</strong>（用于间接分支）预测器。论文使用了两种 ITTAGE 配置：<strong>TAGE1</strong> (12.62 KB) 和 <strong>TAGE2</strong> (6.31 KB)，其参数详见下表。</li>
</ul>
<p><img alt="" src="../images/bb2bc6ce7bc772acd82002bd7af8cff61bfec2bc3cc409be03ecfc9a836bf6ff.jpg" /> <em>Table 2. Branch predictor parameters</em></p>
<ul>
<li><strong>一致性验证</strong>: 论文专门验证了 PMU 硬件计数与 Pin 模拟轨迹在指令计数上的一致性，确认差异在 <strong>1%</strong> 以内，保证了实验数据的可比性。</li>
</ul>
<p><strong>结果数据分析</strong></p>
<ul>
<li><strong>核心发现</strong>: <strong>分支误预测率</strong>（MPKI, Mispredictions Per Kilo Instructions）在三代 Intel 处理器上呈现<strong>戏剧性下降</strong>。<ul>
<li><strong>Nehalem</strong>: MPKI 范围在 <strong>12-20</strong>，意味着每千条指令因分支误预测损失约 <strong>240-400</strong> 个周期（假设平均惩罚为20周期）。</li>
<li><strong>Sandy Bridge</strong>: MPKI 显著降低至 <strong>4-8</strong> 左右。</li>
<li><strong>Haswell</strong>: MPKI 进一步降至 <strong>0.5-2</strong> 的极低水平，表明分支误预测已不再是性能瓶颈。</li>
</ul>
</li>
<li><strong>模拟器 vs 硬件</strong>: <strong>Haswell</strong> 上测得的 MPKI 与 <strong>TAGE+ITTAGE</strong> 模拟器的结果处于<strong>同一数量级</strong>，这表明 Haswell 的间接分支预测器性能已经非常接近学术界的最先进水平（SOTA）。</li>
<li><strong>前端浪费槽位分析</strong>: 通过 Intel 的 <strong>pmu-tools</strong> 分析处理器前端的<strong>浪费指令发射槽位</strong>（wasted issue slots），发现这些浪费几乎完全由<strong>分支误预测</strong>导致。Haswell 平均仅浪费 <strong>7.8%</strong> 的槽位，而 Sandy Bridge 浪费 <strong>14.5%</strong>，再次印证了 Haswell 分支预测的巨大改进。</li>
</ul>
<p><img alt="" src="../images/8c1b82375d550953f02680f4f8504df67ceb87f3574ce7092ef705dc3e01952b.jpg" /> <em>Figure 7. Correlation between MPKI and lost slots</em></p>
<ul>
<li><strong>各解释器详细表现</strong>:<ul>
<li><strong>Python</strong>: 在 Haswell 上 IPC（Instructions Per Cycle）中位数达到 <strong>2.4</strong>。每个字节码平均消耗 <strong>120-150</strong> 条原生指令，主要开销来自动态类型检查。当负载（payload）简单且间接分支少时，TAGE+ITTAGE 几乎可以完美预测。</li>
<li><strong>Javascript</strong>: 其 dispatch loop 更短（16条指令），每个字节码平均消耗约 <strong>60</strong> 条指令。同样观察到从 Nehalem 到 Haswell 的 MPKI 急剧下降。</li>
<li><strong>CLI</strong>: 作为低抽象级别解释器，其 dispatch loop 极短（7条指令），每个字节码仅需 <strong>21</strong> 条指令。但在 <strong>vpr</strong> 和 <strong>crafty</strong> 等基准上，即使 Haswell 和 TAGE1 也表现出相对较高的 MPKI，论文将其归因于解释器巨大的<strong>预测器足迹</strong>（predictor footprint）——其 switch 语句有 <strong>478</strong> 个目标，对预测器容量要求极高。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/6938ddca3607b874b68eea2a7185d637042a438ad615d4c43da8f087b6956ac2.jpg" /> <em>Figure 4. Python MPKI for all predictors</em>
<img alt="" src="../images/d17bf9fe709aa074e11a144b931ddfc3a15681bafed637ae6b05056b80c35e51.jpg" /> <em>Figure 5. Javascript MPKI for all predictors</em>
<img alt="" src="../images/362e2e3d9b54feba7bff51cfac333157507f03db85089ae8da64b81060f68f65.jpg" /> <em>Figure 6. CLI MPKI for all predictors</em></p>
<p><strong>消融实验</strong></p>
<ul>
<li><strong>Jump Threading 性能增益分析</strong>: 论文通过在 <strong>Python</strong> 上启用和禁用 <strong>jump threading</strong>（利用 GNU 的 Labels as Values 扩展）来进行消融实验。<ul>
<li><strong>性能提升递减</strong>: 实验显示，jump threading 带来的性能提升在新架构上<strong>显著减弱</strong>。在 Nehalem 上平均提升 <strong>10.1%</strong>，在 Sandy Bridge 上降至 <strong>4.2%</strong>，而在 Haswell 上仅为 <strong>2.8%</strong>。</li>
<li><strong>原因剖析</strong>: 论文指出，性能提升并非完全来自<strong>更好的分支预测</strong>。通过指令计数发现，threaded code 版本平均减少了 <strong>3.3%</strong> 的指令数，这是因为部分 dispatch loop 逻辑被绕过。这表明，在现代处理器上，jump threading 的收益更多来自于<strong>减少指令开销</strong>，而非解决分支误预测问题。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/c33473af79f2628363612d9fe4db98aac0fca59cc4a70c57b403df0efcdc5d29.jpg" /> <em>Figure 3. Speedups in Python</em></p>
<ul>
<li><strong>“难以预测”分支的针对性分析</strong>: 论文直接挑战了关于 dispatch loop 中间接跳转“天生难以预测”的<strong>民间传说</strong>（folklore）。通过模拟器，他们单独追踪了该间接分支的误预测率。<ul>
<li><strong>结论</strong>: 该分支<strong>并非内在不可预测</strong>。在大多数情况下，即使是较小的 ITTAGE（6KB）也能很好地预测它。</li>
<li><strong>失败案例分析</strong>: 对于少数预测不佳的案例（如 Python 的 <code>go</code>，CLI 的 <code>vpr</code> 和 <code>crafty</code>），增大 ITTAGE 容量（至 12KB 或 50KB）后，预测准确率<strong>显著提升</strong>。这证明问题根源在于<strong>预测器容量不足</strong>（footprint issue），而非预测模式本身无效。</li>
<li><strong>额外发现</strong>: Python 源码中提到的另一个“难以预测”的条件分支（<code>HAS_ARG</code> 宏）实际上也非常容易被 TAGE 预测准确。</li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/3f0ccf20363e5cbd44387d22e95a22512402e90b795ca7302758eb34796325fb.jpg" /> <em>Table 6. (IT)TAGE misprediction results for “hard to predict” branch, TAGE 1, TAGE 2 and TAGE 3 (all numbers in %)</em></p>
<hr />












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.sections", "navigation.top", "navigation.indexes", "search.suggest", "search.highlight", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
        <script src="../../../javascripts/switcher.js"></script>
      
        <script src="../../../javascripts/smart_back.js"></script>
      
    
  </body>
</html>